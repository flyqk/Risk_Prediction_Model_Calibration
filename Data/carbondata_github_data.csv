"application","csha","cwhen","message","branch","email","application-2","csha-2","basic","emptycode","cloneimplementation","comments","codesize","stringandstringbuffer","naming","strictexceptions","optimization","design","securitycodeguidelines","braces","typeresolution","coupling","finalizer","importstatements","unusedcode","unnecessary","application-3","csha-3","classes","comment_lines_density","vulnerabilities","lines","ncloc","complexity","security_rating","major_violations","duplicated_blocks","code_smells","file_complexity","functions","duplicated_files","duplicated_lines_density","reliability_rating","critical_violations","violations","statements","blocker_violations","reliability_remediation_effort","duplicated_lines","bugs","security_remediation_effort","directories","info_violations","sqale_index","sqale_debt_ratio","minor_violations","files","sqale_rating"
"apache-carbondata","ceac8abf619faff911c64f45d9de2386c6cfb91a","2018-04-09 04:40:13","[CARBONDATA-2325]Page level uncompress and Improve query performance for unsafe no-dictionary columns

Page Level Decoder for query
Added page level on demand decoding, in current code, all pages of blocklet is getting uncompressed, because of this memory footprint is too high and cause OOM, Now added code to support page level decoding, one page will be decoding when all the records are processed next page data will be decoded. It will improve query performance for example limit query.
Unsafe No Dictionary(Unsafe variable length)
Optimized getRow(for Vector processing) And putArray method

This closes #2149
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","ceac8abf619faff911c64f45d9de2386c6cfb91a","31","14","2","6107","723","139","5966","216","10098","1678","315","39","52","7284","0","83","42","552","apache-carbondata","ceac8abf619faff911c64f45d9de2386c6cfb91a","677","15.9","171","97798","57330","13154","5","1920","198","2490","21.3","4446","82","4.6","5","297","2720","25508","32","1000","4464","59","3385","126","67","22590","1.3","404","619","1"
"apache-carbondata","e26cccc41df9c86879558d2d3721d7048004f638","2018-04-02 05:38:17","[CARBONDATA-2304][Compaction] Prefetch rowbatch during compaction

Add a configuration to enable prefetch during compaction.

During compaction, carbondata will query on the segments and retrieve a row， then it will sort the rows and produce the final carbondata file.

Currently we find the poor performance in retrieving the rows, so adding prefetch for the rows will surely improve the compaction performance.

This closes #2133
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","e26cccc41df9c86879558d2d3721d7048004f638","31","12","2","6100","724","139","5968","216","10088","1676","315","39","52","7298","0","83","42","552","apache-carbondata","e26cccc41df9c86879558d2d3721d7048004f638","677","15.9","171","97769","57347","13156","5","1918","198","2489","21.3","4442","82","4.6","5","297","2719","25513","32","1000","4464","59","3385","126","67","22598","1.3","405","619","1"
"apache-carbondata","cf1e4d4ca7cef8bc49b4eb7b811af5c1bd787cba","2018-04-06 01:40:38","Blockletsize and Blocksize issue fix in sdk writer and other unmanaged table fixes

*Decimal dataype issue fix in sdk writer
*Drop unmanaged table issue in cluster
*Added comment for SDK writer API methods
*Query two writer's output at same path issue fix
*Block alter table rename for unmanged table

This closes #2141
","refs/heads/master","ajanthabhat@gmail.com","apache-carbondata","cf1e4d4ca7cef8bc49b4eb7b811af5c1bd787cba","31","12","2","6087","723","139","5966","210","10090","1672","317","39","51","7295","0","83","42","552","apache-carbondata","cf1e4d4ca7cef8bc49b4eb7b811af5c1bd787cba","676","15.9","168","97721","57306","13156","5","1920","200","2495","21.3","4435","83","4.6","5","296","2722","25508","32","1000","4487","59","3325","126","67","22728","1.3","407","619","1"
"apache-carbondata","ecd6c0c54405c91434d1cbca2894b635318f7e4a","2018-04-15 19:55:10","[CARBONDATA-2350][DataMap] Fix bugs in minmax datamap example

Fix bugs in minmax datamap example

This closes #2174
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","ecd6c0c54405c91434d1cbca2894b635318f7e4a","31","12","2","6083","723","139","5964","210","10083","1671","317","39","51","7292","0","83","42","548","apache-carbondata","ecd6c0c54405c91434d1cbca2894b635318f7e4a","676","15.9","168","97675","57277","13147","5","1919","200","2493","21.2","4433","83","4.6","5","296","2720","25496","32","1000","4487","59","3325","126","66","22727","1.3","407","619","1"
"apache-carbondata","4c9bed8bc6a8b9a517fa7bbe1635bc3da209c45b","2018-04-03 03:48:51","[CARBONDATA-2307] Fix OOM issue when using DataFrame.coalesce

Fix OOM issue when using DataFrame.coalesce

This closes #2136
","refs/heads/master","xaprice@yeah.net","apache-carbondata","4c9bed8bc6a8b9a517fa7bbe1635bc3da209c45b","31","12","2","6083","720","138","5964","209","10080","1671","317","39","51","7292","0","72","42","548","apache-carbondata","4c9bed8bc6a8b9a517fa7bbe1635bc3da209c45b","676","15.9","167","97618","57230","13116","5","1918","200","2491","21.2","4431","83","4.6","5","295","2717","25459","32","1000","4487","59","3305","126","66","22695","1.3","406","619","1"
"apache-carbondata","9ee74fe0708afead309540777c315e0d13abc010","2018-04-13 00:14:25","[CARBONDATA-2343][DataMap]Improper filter resolver cause more filter scan on data that could be skipped

Currently DataMapChooser will choose and combine datamap for
expressions and it will wrap the expression in a
TrueConditionalResolverImpl. However the executor TrueFilterExecutor
will always cause scanning the blocklet which could be skipped.

This closes #2168
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","9ee74fe0708afead309540777c315e0d13abc010","31","12","2","6082","720","138","5964","209","10080","1671","317","39","51","7292","0","72","42","548","apache-carbondata","9ee74fe0708afead309540777c315e0d13abc010","676","15.9","167","97598","57210","13113","5","1918","200","2491","21.2","4430","83","4.6","5","295","2717","25444","32","1000","4487","59","3305","126","66","22695","1.3","406","619","1"
"apache-carbondata","5204818380b43366b2a2545b0969fa736e59f660","2018-04-08 04:44:22","[CARBONDATA-2324] Support config ExecutorService in search mode

Make scan thread configurable in search mode

This closes #2150
","refs/heads/master","kevinjmh@qq.com","apache-carbondata","5204818380b43366b2a2545b0969fa736e59f660","31","12","2","6082","720","138","5962","209","10079","1671","317","39","51","7292","0","72","42","548","apache-carbondata","5204818380b43366b2a2545b0969fa736e59f660","676","15.9","167","97599","57211","13113","5","1918","200","2491","21.2","4430","83","4.6","5","295","2717","25444","32","1000","4489","59","3305","126","66","22695","1.3","406","619","1"
"apache-carbondata","cfb8ed9f5ec932911ddefe8fc2dcd07269411396","2018-04-01 01:30:22","[CARBONDATA-2301][SDK] CarbonStore interface and two implementations (Spark and Local)

User should be able to query carbondata using CarbonStore interface.

Get API: It can be used for filter query. It accepts projection column names and filter expression, and returns matched rows.
SQL API: it accepts SQL statement and return query result set.

This closes #2127
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","cfb8ed9f5ec932911ddefe8fc2dcd07269411396","31","12","2","6080","720","138","5962","209","10079","1671","317","39","51","7292","0","72","42","548","apache-carbondata","cfb8ed9f5ec932911ddefe8fc2dcd07269411396","676","15.9","167","97592","57207","13112","5","1918","200","2491","21.2","4430","83","4.6","5","295","2717","25442","32","1000","4489","59","3305","126","66","22695","1.3","406","619","1"
"apache-carbondata","13cdeb9f4f9e3252a9fe4e419c1e7b10e827e390","2018-04-01 05:08:51","[CARBONDATA-2303] clean files issue resolved for partition folder

This closes #2128
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","13cdeb9f4f9e3252a9fe4e419c1e7b10e827e390","31","12","2","6080","720","138","5962","209","10079","1671","317","39","51","7292","0","72","42","548","apache-carbondata","13cdeb9f4f9e3252a9fe4e419c1e7b10e827e390","676","15.9","167","97590","57205","13111","5","1918","200","2491","21.2","4430","83","4.6","5","295","2717","25441","32","1000","4489","59","3305","126","66","22695","1.3","406","619","1"
"apache-carbondata","359f6e6b22cca44a344545470720c02d07bbb4f4","2018-04-10 07:12:30","[CARBONDATA-2329] Non Serializable extra info in session is overwritten from stale thread

Problem:
1. Non Serializable extra info is copied from thread which causes stale data from old session when the thread is reused by spark.
2. CarboSessionInfo clone is not copying Non serializable info to new object which can damage session level values if local query thread updates values.

Solution: Remove logic to copy Non Serializable extra info and fix clone logic

This closes #2154
","refs/heads/master","kanaka.avvaru@huawei.com","apache-carbondata","359f6e6b22cca44a344545470720c02d07bbb4f4","31","12","2","6073","720","134","5962","209","10056","1671","317","39","51","7285","0","72","42","548","apache-carbondata","359f6e6b22cca44a344545470720c02d07bbb4f4","676","15.9","167","97496","57126","13091","5","1912","200","2481","21.1","4422","83","4.6","5","295","2707","25405","32","1000","4490","59","3305","126","66","22651","1.3","402","619","1"
"apache-carbondata","df8f06739d752d39863846eacb8947e667ce5a55","2018-04-08 03:05:19","[CARBONDATA-2321] Fix for selection of partion column after concurrent load fails randomly

Fix selection of partition column after concurrent load fails randomly

This closes #2146
","refs/heads/master","jatin.demla@knoldus.in","apache-carbondata","df8f06739d752d39863846eacb8947e667ce5a55","31","12","2","6073","720","134","5964","209","10057","1671","317","39","51","7285","0","72","42","548","apache-carbondata","df8f06739d752d39863846eacb8947e667ce5a55","676","15.9","167","97498","57128","13091","5","1913","200","2482","21.1","4422","83","4.6","5","295","2708","25407","32","1000","4490","59","3305","126","66","22656","1.3","402","619","1"
"apache-carbondata","b439b00f6afafedc7a73daa24c799c69c8cd5574","2018-03-13 23:31:43","[CARBONDATA-2238][DataLoad] Merge and spill in-memory pages if memory is not enough

Currently in carbondata, pages will be added to memory. If memory is not enough, newly incoming pages will be spilled to disk directly. This implementation will merge&spill the in-memory pages and make room for the newly incoming pages.

As a result, carbondata will spill less than before and spill bigger files instead of smaller files and the merge&sort of the pages is in-memory instead of spilled-file.

This closes #2056
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","b439b00f6afafedc7a73daa24c799c69c8cd5574","31","12","2","6073","720","134","5962","209","10055","1672","317","39","51","7285","0","72","42","548","apache-carbondata","b439b00f6afafedc7a73daa24c799c69c8cd5574","676","15.9","167","97498","57127","13091","5","1913","200","2481","21.1","4422","83","4.6","5","295","2707","25407","32","1000","4490","59","3305","126","66","22654","1.3","401","619","1"
"apache-carbondata","f6990d62293d7f1fc0ab449e812aeca0d7e1d130","2018-04-07 20:01:00","[CARBONDATA-2319][Profiler] Fix carbon_scan_time and carbon_IO_time in task statistics

carbon_scan_time and carbon_IO_time are incorrect in task statistics. This PR fix it

This closes #2144
","refs/heads/master","qiangcai@qq.com","apache-carbondata","f6990d62293d7f1fc0ab449e812aeca0d7e1d130","31","12","2","6069","720","134","5958","209","10055","1672","317","39","51","7285","0","72","42","548","apache-carbondata","f6990d62293d7f1fc0ab449e812aeca0d7e1d130","676","15.9","167","97478","57120","13091","5","1913","200","2481","21.1","4422","83","4.6","5","295","2707","25406","32","1000","4490","59","3305","126","66","22654","1.3","401","619","1"
"apache-carbondata","638ed1fa7094d4a139a9a1cb08b123dfde31dd87","2018-03-29 04:50:39","[CARBONDATA-2297] Support SEARCH_MODE for basic filter query

1. Add a new spark schedule type.
2.Add a new Query Executor

This closes #2123
","refs/heads/master","kevinjmh@qq.com","apache-carbondata","638ed1fa7094d4a139a9a1cb08b123dfde31dd87","31","12","2","6069","720","134","5958","209","10055","1672","317","39","51","7285","0","72","42","548","apache-carbondata","638ed1fa7094d4a139a9a1cb08b123dfde31dd87","676","15.9","167","97478","57120","13091","5","1913","200","2481","21.1","4422","83","4.6","5","295","2707","25406","32","1000","4490","59","3305","126","66","22654","1.3","401","619","1"
"apache-carbondata","b52f1571da554cb375b3fcd9b9fb6fff0fd7d9d6","2018-03-25 01:15:24","[CARBONDATA-2277] Fix for filter of default values on all datatypes

1. Added solution to handle filter keys for the direct dictionary on default values.
2. For no dictionary columns changes code to get correct bytes value of default values.

This closes #2102
","refs/heads/master","jatin.demla@knoldus.in","apache-carbondata","b52f1571da554cb375b3fcd9b9fb6fff0fd7d9d6","31","12","2","6034","720","134","5926","206","10029","1666","317","39","48","7268","0","72","42","548","apache-carbondata","b52f1571da554cb375b3fcd9b9fb6fff0fd7d9d6","673","15.9","165","97155","56891","13053","5","1909","198","2477","21.2","4410","81","4.6","5","293","2701","25326","32","1000","4422","59","3265","126","66","22591","1.3","401","616","1"
"apache-carbondata","280a4003a6b68b286beac6dc31ff84772d5b5b84","2018-04-05 02:54:36","[CARBONDATA-2313] Support unmanaged carbon table read and write

Carbon SDK writer will take the input data and write back the carbondata
and carbonindex files in the path specified.
This output doesn't have metadata folder. So, it is called unmanaged
carbon table.

This can be read by creating external table in the location of sdk
writer output path.

Please refer, TestUnmanagedCarbonTable.scla for the example scenario.

Load, insert, compaction, alter, IUD etc features are blocked for
unmanaged table

Co-authored-by: sounakr <sounakr@gmail.com>

This closes #2131
","refs/heads/master","ajanthabhat@gmail.com","apache-carbondata","280a4003a6b68b286beac6dc31ff84772d5b5b84","31","12","2","6033","720","134","5910","206","10012","1665","317","39","48","7262","0","72","42","548","apache-carbondata","280a4003a6b68b286beac6dc31ff84772d5b5b84","673","15.9","165","97102","56849","13048","5","1907","198","2475","21.2","4408","81","4.6","5","293","2699","25310","32","1000","4422","59","3265","126","66","22579","1.3","401","616","1"
"apache-carbondata","55084602917aec5a2ff5c29e6e7ac501d7830d14","2018-03-22 23:42:05","[CARBONDATA-2294] Partition preaggregate support

1. Allow creation of aggregate table on partition and non-partition columns
2. Support to load data into aggregate table after insertion into parent table is complete.
3. Support to compact aggregate tables if parent table is compacted.
4. If parent table partition is dropped then drop the same partition in child tables also.

This closes #2109
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","55084602917aec5a2ff5c29e6e7ac501d7830d14","31","12","2","5997","720","129","5844","205","9968","1658","315","39","48","7220","0","72","39","548","apache-carbondata","55084602917aec5a2ff5c29e6e7ac501d7830d14","669","16","164","96696","56604","13010","5","1902","196","2460","21.3","4393","79","4.5","5","292","2683","25223","32","1000","4396","59","3245","125","63","22490","1.3","394","612","1"
"apache-carbondata","fb1516c0008da73be86b31f82df0178caa748f5d","2018-03-18 19:23:15","[CARBONDATA-2269]Support Query On PreAggregate table created on streaming table

Support Query On Pre Aggregate table created on Streaming table
For querying the data on PreAggregate table on streaming table change the query plan to apply union of agg table and streaming segment of actual table to get the current data.
Query Example for streaming table:
User Query:
SELECT name, sum(Salary) as totalSalary
FROM maintable
Updated Query:
SELECT name, sum(totalSalary) FROM(
SELECT name, sum(Salary) as totalSalary
FROM maintable
GROUP BY name
UNION ALL
SELECT maintable_name,sum(maintable_salary) as totalSalary
FROM maintable_agg
GROUP BY maintable_name)
GROUP BY name)

User Query:
SELECT name, AVG(Salary) as avgSalary
FROM maintable.
Updated Query:
SELECT name, Divide(sum(sumSalary)/sum(countsalary))
FROM(
SELECT name, sum(Salary) as sumSalary,count(salary) countsalary
FROM maintable
GROUP BY name
UNION ALL
SELECT maintable_name,sum(maintable_salary) as sumSalary, count(maintable_salary) countsalary
FROM maintable_agg
GROUP BY maintable_name)
GROUP BY name)

User Query:
SELECT name, count(Salary) as countSalary
FROM maintable.
Updated Query:
SELECT name, sum(countsalary)
FROM(
SELECT name, count(Salary) as countSalary
FROM maintable
GROUP BY name
UNION ALL
SELECT maintable_name,sum(maintable_count)
FROM maintable_agg
GROUP BY maintable_name)
GROUP BY name)

This closes #2083
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","fb1516c0008da73be86b31f82df0178caa748f5d","31","12","1","5996","720","129","5844","205","9967","1658","315","39","48","7218","0","72","39","548","apache-carbondata","fb1516c0008da73be86b31f82df0178caa748f5d","669","16","164","96699","56606","13013","5","1900","196","2460","21.3","4392","79","4.5","5","294","2683","25225","32","1000","4396","59","3245","125","63","22475","1.3","394","612","1"
"apache-carbondata","6374d361b563470ce162788ff5377a323b57dde2","2018-03-31 07:42:36","[CARBONDATA-2298]Delete segment lock files before update metadata

If there are some COMPACTED segments and their last modified time is within one hour, the segment lock files deletion operation will not be executed.

This closes #2124
","refs/heads/master","441586683@qq.com","apache-carbondata","6374d361b563470ce162788ff5377a323b57dde2","31","12","1","5994","720","129","5842","205","9967","1657","315","39","48","7218","0","72","39","548","apache-carbondata","6374d361b563470ce162788ff5377a323b57dde2","668","16","164","96668","56599","13012","5","1900","196","2459","21.3","4392","79","4.5","5","294","2682","25223","32","1000","4396","59","3245","125","63","22464","1.3","393","611","1"
"apache-carbondata","0992b3b2357235784b0c1d7d59990525fb174670","2018-04-01 10:09:52","[CARBONDATA-2302]Fix some bugs when separate visible and invisible segments info into two files

There are some bugs when separate visible and invisible segments info into two files:

1.It will not delete physical data of history segments after separating
2.Generate duplicated segment id

This closes #2130
","refs/heads/master","441586683@qq.com","apache-carbondata","0992b3b2357235784b0c1d7d59990525fb174670","31","12","1","5994","720","129","5842","205","9967","1657","315","39","48","7218","0","72","39","548","apache-carbondata","0992b3b2357235784b0c1d7d59990525fb174670","668","16","164","96668","56599","13012","5","1900","196","2459","21.3","4392","79","4.5","5","294","2682","25223","32","1000","4396","59","3245","125","63","22464","1.3","393","611","1"
"apache-carbondata","f910cfa98d1d558779736e13e534bfff6c981172","2018-03-24 07:38:20","[CARBONDATA-2276][SDK] Support API to read schema in data file and schema file

This closes #2099
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","f910cfa98d1d558779736e13e534bfff6c981172","31","12","1","5993","719","129","5834","205","9958","1657","315","39","48","7215","0","72","39","548","apache-carbondata","f910cfa98d1d558779736e13e534bfff6c981172","668","16","164","96623","56565","13006","5","1900","196","2459","21.3","4390","79","4.5","5","294","2682","25215","32","1000","4396","59","3245","125","63","22464","1.3","393","611","1"
"apache-carbondata","cd509d5dbee1311ce14374b79b7c30d400826702","2018-03-30 19:42:44","[CARBONDATA-2296] Fix create datamap command with out on table syntax and correct the target location of test framework

Problem
1 Create datamap command fails if user does not mention on table
2 Test framework try to create metastore and store location in integration/spark-common location but if it runs from other modules like datamap it creates target location in wrong place.
Solution
Check the null for parent table if not present and always take the present module target location as store path location if it not under integration module.

This closes #2122
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","cd509d5dbee1311ce14374b79b7c30d400826702","31","12","1","5994","719","129","5834","205","9960","1658","315","39","48","7218","0","73","39","548","apache-carbondata","cd509d5dbee1311ce14374b79b7c30d400826702","668","16","164","96630","56574","13009","5","1901","196","2461","21.3","4389","79","4.5","5","294","2684","25220","32","1000","4396","59","3245","125","63","22467","1.3","394","611","1"
"apache-carbondata","e8da880021586aea0301b5b457d481da34bd9bb6","2018-02-05 01:10:27","[CARBONDATA-2130] Fix some spelling error in CarbonData

Fix some spelling error in CarbonData:

cloumn => column
realtion => relation
parition=>partition
Dimesion =>Dimension
dictionay=>dictionary

This closes #1930
","refs/heads/master","601450868@qq.com","apache-carbondata","e8da880021586aea0301b5b457d481da34bd9bb6","31","12","1","5994","719","129","5834","205","9960","1658","315","39","48","7218","0","73","39","548","apache-carbondata","e8da880021586aea0301b5b457d481da34bd9bb6","668","16","164","96626","56570","13007","5","1901","196","2461","21.3","4389","79","4.5","5","294","2684","25218","32","1000","4396","59","3245","125","63","22467","1.3","394","611","1"
"apache-carbondata","9fba6845443a8370fba3b9dd86888c83dbc57f06","2018-03-26 03:17:16","[CARBONDATA-2291] Added datamap status and refresh command to sync data manually to datamaps

In order maintain the data consistency we require to enable or disable datamaps when data is not synchronized between fact and datamap. So added the new status called datamapstatus file under the system folder. whenever the data is out of sync between parent tables and datamap it just updates the status as disabled in datamapstatus file. After user manually refreshes the datamap it will update the status to enable.
Only the enabled datamaps are considered during query.

This closes #2106
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9fba6845443a8370fba3b9dd86888c83dbc57f06","31","12","1","5994","719","129","5834","205","9960","1658","315","39","48","7218","0","73","39","548","apache-carbondata","9fba6845443a8370fba3b9dd86888c83dbc57f06","668","16","164","96626","56570","13007","5","1901","196","2461","21.3","4389","79","4.5","5","294","2684","25218","32","1000","4396","59","3245","125","63","22467","1.3","394","611","1"
"apache-carbondata","5daae951500967a910b863e4e57742b51f63f591","2018-03-28 04:08:21","[CARBONDATA-2289] If carbon merge index is enabled then after IUD operation

if some blocks of a segment is deleted, then during query and IUD operation the driver is throwing FileNotFoundException while preparing BlockMetaInfo.
Solution:
Skiping the invalid(deleted) blocks and logig the same as warning.

This closes #2110
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","5daae951500967a910b863e4e57742b51f63f591","31","12","1","5963","717","129","5820","204","9917","1653","315","39","47","7196","0","73","39","548","apache-carbondata","5daae951500967a910b863e4e57742b51f63f591","663","16","163","96180","56319","12958","5","1893","196","2451","21.4","4372","79","4.6","5","293","2673","25105","32","1000","4396","59","3225","124","62","22382","1.3","393","606","1"
"apache-carbondata","7e0803fec02f5872569e7680ce4d3ab02507285b","2018-03-22 21:13:11","[CARBONDATA-2270] Write segment file in loading for non-partition table

Currently when loading into partition table, carbon is writing a segment file to record the segment and index file location mapping.
This can avoid frequent listFile operation when querying. The same should be done for non-partition table also.

This closes #2092
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","7e0803fec02f5872569e7680ce4d3ab02507285b","31","12","1","5963","717","129","5820","204","9917","1653","315","39","47","7194","0","73","39","548","apache-carbondata","7e0803fec02f5872569e7680ce4d3ab02507285b","663","16","163","96174","56313","12957","5","1893","196","2451","21.4","4372","79","4.6","5","293","2673","25103","32","1000","4396","59","3225","124","62","22382","1.3","393","606","1"
"apache-carbondata","0c200d83476c97742b999e456617950c0bd49acf","2018-03-26 04:06:29","[CARBONDATA-2285] Spark integration code refactor

This closes #2104
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","0c200d83476c97742b999e456617950c0bd49acf","30","10","1","5967","717","129","5800","205","9880","1650","315","39","47","7184","0","73","39","548","apache-carbondata","0c200d83476c97742b999e456617950c0bd49acf","663","16","164","95983","56177","12935","5","1889","196","2444","21.3","4366","79","4.6","5","295","2667","25033","32","1000","4396","59","3245","124","62","22350","1.3","389","606","1"
"apache-carbondata","877eabdd6080c514e23a9cbfbaef9f78acc0d39f","2018-03-26 23:50:04","[CARBONDATA-2287] Events added for alter hive partition table

Events added for alter hive partition table

This closes #2107
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","877eabdd6080c514e23a9cbfbaef9f78acc0d39f","30","10","1","5967","717","129","5798","205","9880","1650","315","39","47","7184","0","73","39","548","apache-carbondata","877eabdd6080c514e23a9cbfbaef9f78acc0d39f","663","16","164","95977","56175","12935","5","1889","196","2444","21.3","4366","79","4.6","5","295","2667","25033","32","1000","4396","59","3245","124","62","22350","1.3","389","606","1"
"apache-carbondata","05086e5367b3ba9888825b5b1388059ef987fc26","2018-03-24 19:21:21","[CARBONDATA-2278] Save the datamaps to system folder of warehouse.

Make the datamap schema independent of main table schema. And store the schema under _system folder location. This location is configurable by using carbon property carbon.system.folder.location , by default, it stores under the store location.
Created datamap schema in JSON format for better readability. And has the interfaces to store it in database but not given any implementation to it in this PR.
Made on table <tablename> for datamap DDL as optional , so now user can create/drop or show datamaps without on table option.

This closes #2100
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","05086e5367b3ba9888825b5b1388059ef987fc26","30","10","1","5966","717","129","5798","205","9878","1650","315","39","47","7184","0","73","39","548","apache-carbondata","05086e5367b3ba9888825b5b1388059ef987fc26","663","16","164","95950","56156","12932","5","1889","196","2444","21.3","4365","79","4.6","5","295","2667","25023","32","1000","4396","59","3245","124","62","22350","1.3","389","606","1"
"apache-carbondata","c723947a79332c66175f5a33cf57f08fe70fe1a9","2018-03-17 03:13:08","[CARBONDATA-2165]Remove spark in carbon-hadoop module

1. Streaming relation RecordReader is moved to carbon-streaming module.
2. RDD related class is moved to carbon-spark2 module

This closes #2074
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","c723947a79332c66175f5a33cf57f08fe70fe1a9","30","10","1","5915","717","127","5794","202","9818","1641","315","39","47","7162","0","72","39","548","apache-carbondata","c723947a79332c66175f5a33cf57f08fe70fe1a9","658","15.9","161","95300","55827","12862","5","1886","196","2435","21.4","4317","79","4.6","5","292","2654","24903","30","970","4396","58","3185","124","59","22283","1.3","387","601","1"
"apache-carbondata","72f50b507dcc405e41904bbddada1e51976d0669","2018-03-22 10:39:36","[CARBONDATA-2258] Separate visible and invisible segments info into two files to reduce the size of tablestatus file.

The size of the tablestatus file is getting larger, there are many places will scan this file and it will impact the performance of reading this file.
According to the discussion on thread, it can append the
invisible segment list to the file called 'tablestatus.history' when execute
command 'CLEAN FILES FOR TABLE' (in method 'SegmentStatusManager.deleteLoadsAndUpdateMetadata') every time, separate visible and invisible segments into two files(tablestatus file and tablestatus.history file).

This closes #2091
","refs/heads/master","441586683@qq.com","apache-carbondata","72f50b507dcc405e41904bbddada1e51976d0669","30","10","1","5913","717","127","5794","202","9817","1639","315","39","47","7162","0","72","39","548","apache-carbondata","72f50b507dcc405e41904bbddada1e51976d0669","658","15.9","161","95292","55820","12860","5","1886","196","2435","21.4","4315","79","4.6","5","292","2654","24902","30","970","4396","58","3185","124","59","22283","1.3","387","601","1"
"apache-carbondata","d5bec4dd7eb9b40fe3f6618093ba28e886e56b25","2018-03-19 04:49:47","[CARBONDATA-2271] Collect SQL execution information to driver side

This PR add support for collecting SQL execution information for profiling purpose. See CarbonSessionExample.scala, it will generate a separated log file containing profiling information

This closes #2087
","refs/heads/master","qiangcai@qq.com","apache-carbondata","d5bec4dd7eb9b40fe3f6618093ba28e886e56b25","30","10","1","5904","717","126","5762","202","9790","1635","313","39","47","7151","0","72","39","546","apache-carbondata","d5bec4dd7eb9b40fe3f6618093ba28e886e56b25","657","15.9","161","95124","55693","12837","5","1883","196","2430","21.4","4308","79","4.6","5","291","2649","24838","30","970","4396","58","3185","124","59","22231","1.3","386","601","1"
"apache-carbondata","df5d7a99eabc951eed0d3cf4aec8985d83b74160","2018-03-17 02:18:24","[CARBONDATA-1998][SDK] Support CarbonReader to read carbondata files

Support CarbonReader to read carbondata files

This closes #2072
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","df5d7a99eabc951eed0d3cf4aec8985d83b74160","30","10","1","5855","722","147","5776","202","9738","1632","309","39","47","7157","0","72","38","546","apache-carbondata","df5d7a99eabc951eed0d3cf4aec8985d83b74160","655","16","161","94772","55416","12782","5","1883","196","2439","21.3","4272","79","4.6","5","291","2658","24771","30","970","4390","58","3185","124","59","22237","1.3","395","600","1"
"apache-carbondata","c09ef99895c9ed6e9279aba2b420aa43095b6e50","2018-03-16 03:36:04","[CARBONDATA-2224][File Level Reader Support] Refactoring of #2055

Review comment fixes and refactoring of #2055

This closes #2069
","refs/heads/master","ajanthabhat@gmail.com","apache-carbondata","c09ef99895c9ed6e9279aba2b420aa43095b6e50","30","10","1","5840","722","147","5756","200","9686","1629","309","39","47","7127","0","72","38","546","apache-carbondata","c09ef99895c9ed6e9279aba2b420aa43095b6e50","653","16","160","94503","55231","12753","5","1882","196","2435","21.3","4258","79","4.6","5","290","2653","24693","30","970","4390","58","3165","124","58","22197","1.3","393","598","1"
"apache-carbondata","9a25dc6af4901fdc3951259a3a08bd089aeb9e36","2018-02-23 18:25:14","[CARBONDATA-2224][File Level Reader Support] External File level reader support

File level reader reads any carbondata file placed in any external file path.

This closes #2055
","refs/heads/master","sounakr@gmail.com","apache-carbondata","9a25dc6af4901fdc3951259a3a08bd089aeb9e36","30","10","1","5840","722","147","5756","200","9686","1629","309","39","47","7127","0","72","38","546","apache-carbondata","9a25dc6af4901fdc3951259a3a08bd089aeb9e36","653","16","160","94503","55231","12753","5","1882","196","2435","21.3","4258","79","4.6","5","290","2653","24693","30","970","4390","58","3165","124","58","22197","1.3","393","598","1"
"apache-carbondata","982d03fea2a3b0869b81ce1a0f896b522a25af64","2018-03-18 09:11:49","[CARBONDATA-2163][CARBONDATA-2164] Remove spark dependency in core and processing modules

This closes #2070
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","982d03fea2a3b0869b81ce1a0f896b522a25af64","29","10","1","5835","720","146","5728","199","9643","1628","309","39","47","7108","0","72","38","546","apache-carbondata","982d03fea2a3b0869b81ce1a0f896b522a25af64","653","16.1","160","94290","55039","12693","5","1876","191","2426","21.2","4251","79","4.6","5","289","2644","24583","30","970","4307","58","3165","124","58","22078","1.3","391","598","1"
"apache-carbondata","873c3ded04738fa9cbef9a5f0d37902fc758a88b","2018-03-01 23:40:27","[CARBONDATA-2220] Reduce unnecessary audit log

This closes #2020
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","873c3ded04738fa9cbef9a5f0d37902fc758a88b","29","10","1","5829","718","146","5728","199","9639","1627","309","39","47","7102","0","72","38","546","apache-carbondata","873c3ded04738fa9cbef9a5f0d37902fc758a88b","653","16.1","160","94299","55043","12700","5","1876","189","2426","21.2","4246","78","4.5","5","289","2644","24589","30","970","4271","58","3165","124","58","22062","1.3","391","598","1"
"apache-carbondata","f5cdd5ca9dcf22984ed300fe1d2d36939755e947","2018-03-05 01:47:13","[CARBONDATA-2223] Adding Listener Support for Partition

Adding Listener Support for Partition

This closes #2031
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","f5cdd5ca9dcf22984ed300fe1d2d36939755e947","29","10","1","5829","718","146","5728","199","9639","1627","309","39","47","7102","0","72","38","546","apache-carbondata","f5cdd5ca9dcf22984ed300fe1d2d36939755e947","653","16.1","160","94297","55041","12700","5","1876","189","2426","21.2","4246","78","4.5","5","289","2644","24589","30","970","4271","58","3165","124","58","22062","1.3","391","598","1"
"apache-carbondata","0609fc52cdb472121aa93350925674cec194b068","2018-03-07 23:18:09","[CARBONDATA-2230]Add a path into table path to store lock files and delete useless segment lock files before loading

This closes #2045
","refs/heads/master","441586683@qq.com","apache-carbondata","0609fc52cdb472121aa93350925674cec194b068","29","10","1","5828","718","146","5726","199","9631","1626","309","39","47","7098","0","72","38","546","apache-carbondata","0609fc52cdb472121aa93350925674cec194b068","653","16.1","160","94274","55020","12697","5","1875","189","2425","21.2","4246","78","4.5","5","289","2643","24577","30","970","4271","58","3165","124","58","22052","1.3","391","598","1"
"apache-carbondata","04ff36764c797264f5396fa3cbf1d6fe883737e0","2018-03-15 04:49:07","[HOTFIX] Fix CI random failure

This closes #2068
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","04ff36764c797264f5396fa3cbf1d6fe883737e0","28","10","1","5826","718","146","5718","199","9618","1626","309","39","47","7096","0","72","39","546","apache-carbondata","04ff36764c797264f5396fa3cbf1d6fe883737e0","653","16.1","160","94172","54961","12682","5","1873","187","2423","21.2","4239","76","4.5","5","289","2641","24555","30","970","4248","58","3165","124","58","22012","1.3","391","598","1"
"apache-carbondata","6cb6f8380d8195bb8dd9848ea262ca66cd8cdf9f","2018-03-12 04:38:08","[CARBONDATA-2247][SDK] Support write Index file in CarbonWriter

This closes #2053
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","6cb6f8380d8195bb8dd9848ea262ca66cd8cdf9f","28","10","1","5824","718","146","5718","199","9613","1626","308","39","47","7096","0","72","39","546","apache-carbondata","6cb6f8380d8195bb8dd9848ea262ca66cd8cdf9f","652","16.1","160","94156","54943","12679","5","1873","187","2423","21.2","4238","76","4.5","5","289","2641","24549","30","970","4248","58","3165","124","58","22012","1.3","391","598","1"
"apache-carbondata","5ab30995f85dcde080033a63aab257367e8b36a4","2018-02-22 00:31:12","[CARBONDATA-2194] Exception is improper when use incorrect bad record action type

This closes #1989
","refs/heads/master","601450868@qq.com","apache-carbondata","5ab30995f85dcde080033a63aab257367e8b36a4","28","10","1","5822","718","146","5716","199","9611","1626","308","39","47","7096","0","72","39","546","apache-carbondata","5ab30995f85dcde080033a63aab257367e8b36a4","652","16.1","160","94129","54918","12672","5","1873","187","2423","21.2","4237","76","4.5","5","289","2641","24537","30","970","4248","58","3165","124","58","22012","1.3","391","598","1"
"apache-carbondata","41190629e76f104447ee0320f8b2a69a40054369","2018-03-08 17:50:55","[CARBONDATA-2032][DataLoad] directly write carbon data files to HDFS

Currently in data loading, carbondata write the final data files to local disk and then copy it to HDFS.
For saving disk IO, carbondata can skip this procedure and directly write these files to HDFS.

This closes #1825
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","41190629e76f104447ee0320f8b2a69a40054369","28","10","1","5822","718","146","5716","199","9611","1626","308","39","47","7096","0","72","39","546","apache-carbondata","41190629e76f104447ee0320f8b2a69a40054369","652","16.1","160","94129","54918","12672","5","1873","187","2423","21.2","4237","76","4.5","5","289","2641","24537","30","970","4248","58","3165","124","58","22012","1.3","391","598","1"
"apache-carbondata","18380a6b4747f6b7a77da057a829426191fae2a9","2018-03-10 07:26:22","[HOTFIX] Fix unsafe load in test case

Unsafe Load fails for dictionary columns because of refactoring

This closes #2051
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","18380a6b4747f6b7a77da057a829426191fae2a9","28","10","1","5811","718","146","5706","199","9576","1623","308","39","47","7092","0","72","39","546","apache-carbondata","18380a6b4747f6b7a77da057a829426191fae2a9","652","16.1","160","93978","54836","12657","5","1868","187","2418","21.2","4224","76","4.5","5","289","2636","24509","30","970","4248","58","3165","124","58","21985","1.3","391","598","1"
"apache-carbondata","be600bc907dbd6051b7ef51452c7a4fe044f4786","2018-01-18 03:24:15","[CARBONDATA-1993] Carbon properties default values fix and corresponding template and document correction

This closes #1831
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","be600bc907dbd6051b7ef51452c7a4fe044f4786","28","10","1","5811","718","146","5706","199","9577","1622","308","39","47","7094","0","72","39","546","apache-carbondata","be600bc907dbd6051b7ef51452c7a4fe044f4786","652","16.1","160","93991","54847","12660","5","1869","187","2419","21.2","4224","76","4.5","5","289","2637","24515","30","970","4248","58","3165","124","58","21990","1.3","391","598","1"
"apache-carbondata","d23f7fad1f7db029d1dd0cc8e3db7a5b79463179","2018-02-28 23:40:01","[CARBONDATA-2172][Lucene] Add text_columns property for Lucene DataMap

Add text_columns property for Lucene DataMap

This closes #2019
","refs/heads/master","qiangcai@qq.com","apache-carbondata","d23f7fad1f7db029d1dd0cc8e3db7a5b79463179","28","10","1","5811","718","146","5722","199","9577","1627","308","39","47","7094","0","72","39","546","apache-carbondata","d23f7fad1f7db029d1dd0cc8e3db7a5b79463179","652","16.1","160","94035","54861","12660","5","1869","187","2419","21.2","4224","76","4.5","5","289","2637","24515","30","970","4248","58","3165","124","58","21996","1.3","391","598","1"
"apache-carbondata","f9291cdb3b480d3ad46f963b5c772b8fa3185034","2018-02-28 00:02:55","[CARBONDATA-2216][Test] Fix bugs in sdv tests

This closes #2012
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","f9291cdb3b480d3ad46f963b5c772b8fa3185034","28","10","1","5812","718","146","5722","199","9574","1626","308","39","47","7093","0","72","39","546","apache-carbondata","f9291cdb3b480d3ad46f963b5c772b8fa3185034","652","16.1","160","93987","54834","12651","5","1869","187","2417","21.2","4223","76","4.5","5","289","2635","24503","30","970","4248","58","3165","124","57","21994","1.3","390","598","1"
"apache-carbondata","5eb476f5c27c721ceb6950000fe6f0471a833f27","2018-02-27 05:44:15","[CARBONDATA-2206] Fixed lucene datamap evaluation issue in executor

In case of MatchExpression it should return same bitset from RowLevelFilterExecuterImpl

This closes #2010
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","5eb476f5c27c721ceb6950000fe6f0471a833f27","28","10","1","5812","718","146","5722","199","9574","1626","308","39","47","7093","0","72","39","546","apache-carbondata","5eb476f5c27c721ceb6950000fe6f0471a833f27","652","16.1","160","93987","54834","12651","5","1869","187","2417","21.2","4223","76","4.5","5","289","2635","24503","30","970","4248","58","3165","124","57","21994","1.3","390","598","1"
"apache-carbondata","bbb10922b3ed7ddf12881dae339848f1d88b0984","2018-02-26 00:30:38","[CARBONDATA-2206] support lucene index datamap

This PR is an initial effort to integrate lucene as an index datamap into carbondata.
A new module called carbondata-lucene is added to support lucene datamap:

1.Add LuceneFineGrainDataMap, implement FineGrainDataMap interface.
2.Add LuceneCoarseGrainDataMap, implement CoarseGrainDataMap interface.
3.Support writing lucene index via LuceneDataMapWriter.
4.Implement LuceneDataMapFactory
5.A UDF called TEXT_MATCH is added, use it to do filtering on string column by lucene

This closes #2003
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","bbb10922b3ed7ddf12881dae339848f1d88b0984","28","10","1","5804","718","146","5722","199","9570","1624","308","39","47","7093","0","70","39","546","apache-carbondata","bbb10922b3ed7ddf12881dae339848f1d88b0984","651","16.1","160","93924","54797","12644","5","1868","187","2415","21.2","4219","76","4.5","5","289","2633","24497","30","970","4248","58","3165","124","57","21982","1.3","389","597","1"
"apache-carbondata","fc2a7eb36c06aaced9f0dddcaefefddad1f2b331","2018-02-25 18:04:51","[HOTFIX] Add dava doc for datamap interface

1. Rename some of the datamap interface
2. Add more java doc for all public class of datamap interface

This closes #1998
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","fc2a7eb36c06aaced9f0dddcaefefddad1f2b331","28","10","1","5804","718","146","5722","199","9570","1624","308","39","47","7092","0","70","39","546","apache-carbondata","fc2a7eb36c06aaced9f0dddcaefefddad1f2b331","651","16.1","160","93916","54791","12642","5","1868","187","2414","21.2","4219","76","4.5","5","289","2632","24495","30","970","4248","58","3165","124","56","21982","1.3","389","597","1"
"apache-carbondata","89a12af5aba17f12c4e695971982abfeff256fc1","2018-02-22 04:59:59","[CARBONDATA-2189] Add DataMapProvider developer interface

Add developer interface for 2 types of DataMap:

1.IndexDataMap: DataMap that leveraging index to accelerate filter query
2.MVDataMap: DataMap that leveraging Materialized View to accelerate olap style query, like SPJG query (select, predicate, join, groupby)
This PR adds support for following logic when creating and dropping the DataMap

This closes #1987
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","89a12af5aba17f12c4e695971982abfeff256fc1","28","10","1","5805","718","146","5720","199","9570","1624","308","39","47","7092","0","70","39","546","apache-carbondata","89a12af5aba17f12c4e695971982abfeff256fc1","651","16","160","93819","54745","12642","5","1868","187","2414","21.2","4219","76","4.5","5","289","2632","24495","30","970","4248","58","3165","124","56","21982","1.3","389","597","1"
"apache-carbondata","56330ae2fec2a47823e2584a2166bf27f3849c3f","2017-11-21 02:19:11","[CARBONDATA-1543] Supported DataMap chooser and expression for supporting multiple datamaps in single query

This PR supports 3 features.

1.Load datamaps from the DataMapSchema which are created through DDL.
2.DataMap Chooser: It chooses the datamap out of available datamaps based on simple logic. Like if there is filter condition on column1 then for supposing 2 datamaps(1. column1 2. column1+column2) are supporting this column then we choose the datamap which has fewer columns that is the first datamap.
3.Expression support: Based on the filter expressions we convert them to the possible DataMap expressions and do apply expression on it.
For example, there are 2 datamaps available on table1
Datamap1 : column1
Datamap2 : column2
Query: select * from table1 where column1 ='a' and column2 =b
For the above query, we create datamap expression as AndDataMapExpression(Datamap1, DataMap2). So for the above query both the datamaps are included and the output of them will be applied AND condition to improve the performance

This closes #1510
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","56330ae2fec2a47823e2584a2166bf27f3849c3f","28","10","1","5798","718","146","5712","199","9564","1623","308","39","48","7090","0","71","39","546","apache-carbondata","56330ae2fec2a47823e2584a2166bf27f3849c3f","650","16","160","93772","54727","12639","5","1866","187","2413","21.2","4215","76","4.5","5","289","2631","24488","30","970","4248","58","3165","124","56","21944","1.3","390","596","1"
"apache-carbondata","859d71c1737b6287c4f1a06f7cd9055d32ff8a99","2018-02-24 05:18:17","[CARBONDATA-1114][Tests] Fix bugs in tests in windows env

Fix bugs in tests that will cause failure under windows env

This closes #1994
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","859d71c1737b6287c4f1a06f7cd9055d32ff8a99","27","10","1","5711","711","146","5690","199","9438","1592","308","32","47","7044","0","70","38","540","apache-carbondata","859d71c1737b6287c4f1a06f7cd9055d32ff8a99","641","16.1","160","92859","54126","12490","5","1848","181","2384","21.2","4164","71","4.4","5","289","2602","24213","29","970","4123","58","3165","123","57","21718","1.3","379","589","1"
"apache-carbondata","d5396b154433dc3e24e7b95666375f7f2981fea1","2018-02-12 18:58:06","[CARBONDATA-2091][DataLoad] Support specifying sort column bounds in data loading

Enhance data loading performance by specifying sort column bounds
1. Add row range number during convert-process-step
2. Dispatch rows to each sorter by range number
3. Sort/Write process step can be done concurrently in each range
4. Since all sorttemp files will be written in one folders, we add range
number to the file name to distingush them

Tests added and docs updated

This closes #1953
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","d5396b154433dc3e24e7b95666375f7f2981fea1","27","10","1","5709","711","146","5690","199","9434","1594","308","32","48","7043","0","71","38","540","apache-carbondata","d5396b154433dc3e24e7b95666375f7f2981fea1","641","16.1","160","92865","54117","12488","5","1847","181","2386","21.2","4163","71","4.4","5","290","2604","24210","29","970","4123","58","3165","123","57","21735","1.3","381","590","1"
"apache-carbondata","9a423c241b01d6e0b3f1946c052230adb47f4538","2018-02-07 22:42:39","[CARBONDATA-2023][DataLoad] Add size base block allocation in data loading

Carbondata assign blocks to nodes at the beginning of data loading.
Previous block allocation strategy is block number based and it will
suffer skewed data problem if the size of input files differs a lot.

We introduced a size based block allocation strategy to optimize data
loading performance in skewed data scenario.

This closes #1808
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","9a423c241b01d6e0b3f1946c052230adb47f4538","27","10","1","5690","711","138","5676","199","9429","1589","302","32","48","7043","0","71","38","540","apache-carbondata","9a423c241b01d6e0b3f1946c052230adb47f4538","639","16.1","160","92733","54052","12486","5","1847","181","2386","21.2","4160","71","4.4","5","290","2604","24190","29","970","4123","58","3165","123","57","21743","1.3","381","588","1"
"apache-carbondata","2b41f140229c1799178313b257f3779908e69010","2018-02-07 22:35:14","[CARBONDATA-2018][DataLoad] Optimization in reading/writing for sort temp row

Pick up the no-sort fields in the row and pack them as bytes array and skip parsing them during merge sort to reduce CPU consumption

This closes #1792
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","2b41f140229c1799178313b257f3779908e69010","27","10","1","5684","711","125","5664","199","9425","1588","302","32","48","7040","0","71","38","538","apache-carbondata","2b41f140229c1799178313b257f3779908e69010","639","16.1","160","92683","54020","12481","5","1845","181","2384","21.2","4158","71","4.4","5","290","2602","24177","29","970","4123","58","3165","123","57","21726","1.3","381","588","1"
"apache-carbondata","89cfd8e06e783c610ff8cf28e86c8501b450da37","2018-02-11 05:37:04","[CARBONDATA-2159] Remove carbon-spark dependency in store-sdk module

To make assembling JAR of store-sdk module, it should not depend on carbon-spark module

This closes #1970
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","89cfd8e06e783c610ff8cf28e86c8501b450da37","27","10","1","5687","711","125","5666","199","9427","1588","302","32","48","7042","0","71","38","542","apache-carbondata","89cfd8e06e783c610ff8cf28e86c8501b450da37","639","16.1","160","92724","54040","12484","5","1848","181","2387","21.2","4159","71","4.4","5","290","2605","24190","29","970","4123","58","3165","123","57","21771","1.3","381","588","1"
"apache-carbondata","1d827c7b515a21d936769424c282d2aafb1ef6b7","2018-02-10 03:44:23","[CARBONDATA-1997] Add CarbonWriter SDK API

Added a new module called store-sdk, and added a CarbonWriter API, it can be used to write Carbondata files to a specified folder, without Spark and Hadoop dependency. User can use this API in any environment.

This closes #1967
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","1d827c7b515a21d936769424c282d2aafb1ef6b7","26","10","1","5675","704","125","5654","198","9364","1585","302","32","48","7013","0","71","38","536","apache-carbondata","1d827c7b515a21d936769424c282d2aafb1ef6b7","637","16.2","160","92337","53764","12414","5","1833","181","2370","21.2","4145","71","4.5","5","288","2588","24066","29","970","4123","58","3165","123","57","21631","1.3","381","586","1"
"apache-carbondata","8d8b589e78a9db1ddc101d20c1e3feb500acce19","2018-02-07 22:42:39","[CARBONDATA-2023][DataLoad] Add size base block allocation in data loading

Carbondata assign blocks to nodes at the beginning of data loading.
Previous block allocation strategy is block number based and it will
suffer skewed data problem if the size of input files differs a lot.

We introduced a size based block allocation strategy to optimize data
loading performance in skewed data scenario.

This closes #1808
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","8d8b589e78a9db1ddc101d20c1e3feb500acce19","26","10","1","5659","704","125","5646","198","9346","1583","302","32","48","7007","0","71","38","536","apache-carbondata","8d8b589e78a9db1ddc101d20c1e3feb500acce19","635","16.2","160","92142","53643","12392","5","1833","181","2370","21.2","4134","71","4.5","5","288","2588","24000","29","970","4123","58","3165","123","57","21631","1.3","381","584","1"
"apache-carbondata","21704cf747712b86bac03d777891c77a5d75dfd0","2018-02-07 22:35:14","[CARBONDATA-2018][DataLoad] Optimization in reading/writing for sort temp row

Pick up the no-sort fields in the row and pack them as bytes array and skip parsing them during merge sort to reduce CPU consumption

This closes #1792
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","21704cf747712b86bac03d777891c77a5d75dfd0","26","10","1","5656","704","125","5640","198","9343","1583","302","32","48","7005","0","71","38","532","apache-carbondata","21704cf747712b86bac03d777891c77a5d75dfd0","635","16.2","160","92107","53622","12389","5","1830","181","2367","21.2","4133","71","4.5","5","288","2585","23987","29","970","4123","58","3165","123","57","21586","1.3","381","584","1"
"apache-carbondata","4589ac53029bd4741f95c768200f9b8202481ce8","2018-02-07 23:39:45","[HotFix][CheckStyle] Fix import related checkstyle

This closes #1952
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","4589ac53029bd4741f95c768200f9b8202481ce8","26","10","1","5659","704","125","5642","198","9346","1583","302","32","48","7007","0","71","38","536","apache-carbondata","4589ac53029bd4741f95c768200f9b8202481ce8","635","16.2","160","92153","53642","12393","5","1833","181","2370","21.2","4135","71","4.5","5","288","2588","24001","29","970","4123","58","3165","123","57","21631","1.3","381","584","1"
"apache-carbondata","d35fbaf19e7b67f1baf804068d3ce0f05f14710a","2017-11-15 06:18:40","[CARBONDATA-1544][Datamap] Datamap FineGrain implementation

Implemented interfaces for FG datamap and integrated to filterscanner to use the pruned bitset from FG datamap.
FG Query flow as follows.
1.The user can add FG datamap to any table and implement there interfaces.
2. Any filter query which hits the table with datamap will call prune method of FGdatamap.
3. The prune method of FGDatamap return list FineGrainBlocklet , these blocklets contain the information of block, blocklet, page and rowids information as well.
4. The pruned blocklets are internally wriitten to file and returns only the block , blocklet and filepath information as part of Splits.
5. Based on the splits scanrdd schedule the tasks.
6. In filterscanner we check the datamapwriterpath from split and reNoteads the bitset if exists. And pass this bitset as input to it.

This closes #1471
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","d35fbaf19e7b67f1baf804068d3ce0f05f14710a","26","10","1","5659","704","125","5642","198","9346","1583","302","32","48","7007","0","71","38","536","apache-carbondata","d35fbaf19e7b67f1baf804068d3ce0f05f14710a","635","16.2","160","92153","53642","12393","5","1833","181","2370","21.2","4135","71","4.5","5","288","2588","24001","29","970","4123","58","3165","123","57","21631","1.3","381","584","1"
"apache-carbondata","ca7e2e3da305978295eb1b607b1a9449ef76496e","2017-09-28 03:51:05","[CARBONDATA-1480]Min Max Index Example for DataMap

Datamap Example. Implementation of Min Max Index through Datamap. And Using the Index while prunning.

This closes #1359
","refs/heads/master","sounakr@gmail.com","apache-carbondata","ca7e2e3da305978295eb1b607b1a9449ef76496e","26","10","1","5598","703","124","5626","198","9280","1573","301","32","49","6982","0","72","38","532","apache-carbondata","ca7e2e3da305978295eb1b607b1a9449ef76496e","628","16.2","160","91545","53294","12332","5","1823","181","2357","21.3","4105","71","4.5","5","287","2576","23864","30","985","4123","59","3165","121","56","21565","1.3","380","578","1"
"apache-carbondata","bf6c471d5d3592ed3611f73c19fa3988c6fb667f","2018-01-31 00:14:27","[CARBONDATA-2025] Unify all path construction through CarbonTablePath static method

Refactory CarbonTablePath:

1.Remove CarbonStorePath and use CarbonTablePath only.
2.Make CarbonTablePath an utility without object creation, it can avoid creating object before using it, thus code is cleaner and GC is less.

This closes #1768
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","bf6c471d5d3592ed3611f73c19fa3988c6fb667f","26","10","1","5594","703","124","5614","198","9271","1571","301","32","48","6971","0","71","38","530","apache-carbondata","bf6c471d5d3592ed3611f73c19fa3988c6fb667f","627","16.2","160","91473","53247","12326","5","1820","181","2354","21.4","4104","71","4.5","5","287","2573","23845","30","985","4123","59","3165","121","57","21536","1.3","379","577","1"
"apache-carbondata","daa646503ce9ddc5d581b23cbec5494ad8e0be08","2018-01-30 05:24:04","[CARBONDATA-2099] Refactor query scan process to improve readability

Unified concepts in scan process flow:

1.QueryModel contains all parameter for scan, it is created by API in CarbonTable. (In future, CarbonTable will be the entry point for various table operations)
2.Use term ColumnChunk to represent one column in one blocklet, and use ChunkIndex in reader to read specified column chunk
3.Use term ColumnPage to represent one page in one ColumnChunk
4.QueryColumn => ProjectionColumn, indicating it is for projection

This closes #1874
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","daa646503ce9ddc5d581b23cbec5494ad8e0be08","26","10","1","5620","703","124","5662","198","9306","1578","301","32","47","6994","0","70","38","530","apache-carbondata","daa646503ce9ddc5d581b23cbec5494ad8e0be08","632","16.3","160","91924","53471","12362","5","1829","181","2362","21.3","4126","71","4.5","5","287","2581","23923","30","985","4123","59","3165","121","57","21641","1.3","378","581","1"
"apache-carbondata","5ab095704f5d4fbf56563aa9dc6e01bf5896b508","2017-09-21 02:26:26","[CARBONDATA-1827] S3 Carbon Implementation

1.Provide support for s3 in carbondata.
2.Added S3Example to create carbon table on s3.
3.Added S3CSVExample to load carbon table using csv from s3.

This closes #1805
","refs/heads/master","sangeeta.gulia@knoldus.in","apache-carbondata","5ab095704f5d4fbf56563aa9dc6e01bf5896b508","26","10","1","5727","703","124","5668","202","9433","1581","306","32","51","7078","0","69","49","532","apache-carbondata","5ab095704f5d4fbf56563aa9dc6e01bf5896b508","637","16.4","161","93167","54040","12464","5","1867","182","2436","21.3","4178","73","4.4","5","291","2656","24192","30","985","4092","59","3185","122","59","22000","1.4","409","586","1"
"apache-carbondata","b752b6dde963dd5dc0b12cbac1f02cf513168f67","2018-01-02 07:46:14","[CARBONDATA-1968] Add external table support

This PR adds support for creating external table with existing carbondata files, using Hive syntax.
CREATE EXTERNAL TABLE tableName STORED BY 'carbondata' LOCATION 'path'

This closes #1749
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","b752b6dde963dd5dc0b12cbac1f02cf513168f67","26","10","1","5721","702","124","5668","202","9423","1581","306","32","51","7060","0","69","49","532","apache-carbondata","b752b6dde963dd5dc0b12cbac1f02cf513168f67","636","16.4","161","93005","53943","12439","5","1868","182","2436","21.3","4174","73","4.4","5","290","2655","24144","29","970","4092","58","3185","122","59","21994","1.4","409","585","1"
"apache-carbondata","5bedd77b0128e69f0853ce779de40e0105f7c801","2018-01-06 04:28:44","[CARBONDATA-1992] Remove partitionId in CarbonTablePath

In CarbonTablePath, there is a deprecated partition id which is always 0, it should be removed to avoid confusion.

This closes #1765
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","5bedd77b0128e69f0853ce779de40e0105f7c801","26","10","1","5720","701","124","5668","202","9422","1581","306","32","51","7057","0","69","49","532","apache-carbondata","5bedd77b0128e69f0853ce779de40e0105f7c801","636","16.4","161","92996","53939","12437","5","1867","182","2435","21.3","4173","73","4.4","5","290","2654","24142","29","970","4092","58","3185","122","59","21984","1.4","409","585","1"
"apache-carbondata","c125f0caa58f1e7cfa7d10b52ab53364f1895c35","2018-02-26 05:06:03","[CARBONDATA-2204] Optimized number of reads of tablestatus file while querying

This PR avoid reading status file multiple times. For first time query, it reads 2 times(Needed for datamap refresher) and 1 time for second query onwards.

This closes #1999
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","c125f0caa58f1e7cfa7d10b52ab53364f1895c35","26","10","1","5721","701","124","5666","202","9429","1580","306","32","51","7057","0","69","49","532","apache-carbondata","c125f0caa58f1e7cfa7d10b52ab53364f1895c35","636","16.4","161","92999","53939","12437","5","1866","182","2431","21.3","4173","73","4.4","5","290","2650","24143","29","970","4092","58","3185","122","58","21954","1.4","407","584","1"
"apache-carbondata","74f5d67c0f79ba2a45ed97339179333a7cd37279","2018-02-27 03:08:09","[CARBONDATA-2209] Fixed rename table with partitions not working issue and batch_sort and no_sort with partition table issue

This closes #2006
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","74f5d67c0f79ba2a45ed97339179333a7cd37279","26","10","1","5719","701","124","5668","202","9434","1576","305","32","51","7054","0","69","49","532","apache-carbondata","74f5d67c0f79ba2a45ed97339179333a7cd37279","636","16.4","161","92990","53936","12431","5","1865","182","2429","21.3","4170","73","4.4","5","289","2648","24146","29","970","4092","58","3185","122","58","21940","1.4","407","584","1"
"apache-carbondata","7bfe4afe4610ac51170883cc3660acb6b2700e75","2018-02-28 22:34:53","[CARBONDATA-2219] Added validation for external partition location to use same schema.

This closes #2018
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7bfe4afe4610ac51170883cc3660acb6b2700e75","26","10","1","5712","699","124","5658","202","9380","1571","305","32","51","7016","0","69","49","532","apache-carbondata","7bfe4afe4610ac51170883cc3660acb6b2700e75","635","16.5","161","92817","53794","12400","5","1864","182","2428","21.2","4163","73","4.4","5","289","2647","24064","29","970","4092","58","3185","122","58","21926","1.4","407","584","1"
"apache-carbondata","ac30e3e721ab7a772a1010847aa90b33c0ebd2f6","2018-02-28 04:08:50","[CARBONDATA-2103]Make show datamaps configurable in show tables command

Make the show datamaps in show tables configurable:

a new carbon property is added called carbon.query.show.datamaps, by default is it true, show show tables will list all the table including main table and datamaps.
if we want to filter datamaps in show tables, configure this as false

This closes #2015
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","ac30e3e721ab7a772a1010847aa90b33c0ebd2f6","26","10","1","5712","699","124","5656","202","9371","1570","305","32","51","7010","0","69","49","532","apache-carbondata","ac30e3e721ab7a772a1010847aa90b33c0ebd2f6","635","16.5","161","92793","53775","12395","5","1863","182","2427","21.2","4162","73","4.4","5","289","2646","24051","29","970","4092","58","3185","122","58","21924","1.4","407","584","1"
"apache-carbondata","aa910ddb2460d7fa18ff594859391eb888b585b9","2018-02-28 03:58:43","[CARBONDATA-2217]fix drop partition for non existing partition and set FactTimeStamp during compaction for partition table

Problem:
1)when drop partition is fired for a column which does not exists , it throws null pointer exception
2)select * is not working when clean files operation is fired after second level of compaction, it throws exception sometimes
3)new segment is getting created for all the segments if any one partition is dropped

Solution:
1)have a null check , if column does not exists
2)give different timestamp for fact files during compaction to avoid deletion of files during clean files
3)for the partition which is dropped, only for that new segment file should be written and not for all the partition
4) This PR also contains fix for creating a pre aggregate table with same name which has already created in other database

This closes #2017
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","aa910ddb2460d7fa18ff594859391eb888b585b9","26","10","1","5710","699","124","5652","202","9371","1569","305","32","51","7010","0","69","49","532","apache-carbondata","aa910ddb2460d7fa18ff594859391eb888b585b9","635","16.5","161","92788","53772","12395","5","1863","182","2427","21.2","4162","73","4.4","5","289","2646","24051","29","970","4092","58","3185","122","58","21924","1.4","407","584","1"
"apache-carbondata","65471f2c8a9eda8c9f26d78d4640de0f1aa49b4c","2018-02-22 04:59:57","[CARBONDATA-2196] Take CarbonTable from loadmodel during streaming ingestion

This closes #1991
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","65471f2c8a9eda8c9f26d78d4640de0f1aa49b4c","26","10","1","5710","693","124","5652","202","9371","1569","305","32","51","7010","0","69","49","532","apache-carbondata","65471f2c8a9eda8c9f26d78d4640de0f1aa49b4c","635","16.5","161","92784","53768","12393","5","1861","182","2425","21.2","4162","73","4.4","5","289","2644","24049","29","970","4092","58","3185","122","58","21903","1.4","407","584","1"
"apache-carbondata","5da6433dbe5ba810b631da267159dc7ddf4f3064","2018-02-23 03:26:17","[CARBONDATA-2199] Fixed Dimension column after restructure getting wrong block datatype

Problem: Changing datatype of measure having sort_columns calls for restructure and after having restructure it changes the datatype to actual datatype for which accessing the data with changed datatype gives exception of incorrect length.

Solution: Store the datatype in DimensionInfo while restructuring and access the same datatype to get the block data type.

This closes #1993
","refs/heads/master","jatin.demla@knoldus.in","apache-carbondata","5da6433dbe5ba810b631da267159dc7ddf4f3064","26","10","1","5710","693","124","5652","202","9371","1569","305","32","51","7010","0","69","49","532","apache-carbondata","5da6433dbe5ba810b631da267159dc7ddf4f3064","635","16.5","161","92784","53768","12393","5","1861","182","2425","21.2","4162","73","4.4","5","289","2644","24049","29","970","4092","58","3185","122","58","21903","1.4","407","584","1"
"apache-carbondata","4ba51e229a27b8fa30e54583716489ecf71dae8d","2018-02-27 02:31:06","[CARBONDATA-2208]Pre aggregate datamap creation is failing when count(*) present in query

create datamap agg on table maintable using 'preaggregate' as select name, count(*) from maintable group by name

This closes #2004
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","4ba51e229a27b8fa30e54583716489ecf71dae8d","26","10","1","5710","693","124","5652","202","9370","1569","305","32","51","7000","0","69","49","532","apache-carbondata","4ba51e229a27b8fa30e54583716489ecf71dae8d","635","16.5","161","92770","53758","12393","5","1860","182","2424","21.2","4162","73","4.4","5","289","2643","24045","29","970","4092","58","3185","122","58","21893","1.4","407","584","1"
"apache-carbondata","d0858b73ee3c552020f6bbdaa876d810b1c324ba","2018-02-17 08:55:04","[CARBONDATA-2184]Improve memory reuse for heap memory in `HeapMemoryAllocator`

The description in [SPARK-21860|https://issues.apache.org/jira/browse/SPARK-21860]:
In `HeapMemoryAllocator`, when allocating memory from pool, and the key of pool is memory size.
Actually some size of memory ,such as 1025bytes,1026bytes,......1032bytes, we can think they are the same，because we allocate memory in multiples of 8 bytes.
In this case, we can improve memory reuse.

This closes #1982
","refs/heads/master","441586683@qq.com","apache-carbondata","d0858b73ee3c552020f6bbdaa876d810b1c324ba","26","10","1","5710","693","124","5652","202","9370","1569","305","32","51","7000","0","69","49","532","apache-carbondata","d0858b73ee3c552020f6bbdaa876d810b1c324ba","635","16.5","161","92765","53754","12392","5","1860","182","2424","21.2","4162","73","4.4","5","289","2643","24042","29","970","4092","58","3185","122","58","21893","1.4","407","584","1"
"apache-carbondata","8d3c77400cd6abc30c6914084268d9ecd3d18751","2018-02-14 11:01:56","[CARBONDATA-2187][PARTITION] Partition restructure for new folder structure and supporting partition location feature

This closes #1984
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","8d3c77400cd6abc30c6914084268d9ecd3d18751","26","10","1","5705","693","124","5648","202","9364","1567","305","32","51","7001","0","69","49","528","apache-carbondata","8d3c77400cd6abc30c6914084268d9ecd3d18751","635","16.5","161","92712","53720","12387","5","1860","182","2424","21.2","4160","73","4.4","5","289","2643","24026","29","970","4092","58","3185","122","58","21897","1.4","407","584","1"
"apache-carbondata","dded5d5d54d8617796ded23dee0840997f212a0d","2018-02-08 20:07:02","[CARBONDATA-2168] Support global sort for standard hive partitioning

This closes #1972
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","dded5d5d54d8617796ded23dee0840997f212a0d","28","10","1","5648","702","123","5640","201","9229","1561","305","28","49","6903","0","69","49","528","apache-carbondata","dded5d5d54d8617796ded23dee0840997f212a0d","632","16.5","160","92013","53241","12284","5","1873","184","2428","21.1","4127","74","4.5","5","289","2646","23786","28","985","4116","58","3165","122","58","21967","1.4","398","582","1"
"apache-carbondata","7269c0627656e2752bd35c0830cfb134da0aa848","2018-02-25 02:53:41","[CARBONDATA-2200] Fix bug of LIKE operation on streaming table

Fix bug of LIKE operation on streaming table,
LIKE operation will be converted to StartsWith / EndsWith / Contains expression.
Carbon will use RowLevelFilterExecuterImpl to evaluate this expression.
Streaming table also should implement RowLevelFilterExecuterImpl.

This closes #1996
","refs/heads/master","qiangcai@qq.com","apache-carbondata","7269c0627656e2752bd35c0830cfb134da0aa848","28","10","1","5646","701","123","5640","201","9218","1561","305","28","49","6899","0","69","49","528","apache-carbondata","7269c0627656e2752bd35c0830cfb134da0aa848","632","16.5","160","91914","53152","12232","5","1870","182","2425","21","4124","73","4.5","5","289","2643","23722","28","985","4092","58","3165","122","58","21881","1.4","398","582","1"
"apache-carbondata","e9430312d61c0770f402e3475178addba3c37e5e","2018-02-12 11:23:31","[CARBONDATA-2142] [CARBONDATA-1763] Fixed issues while creation concurrent datamaps

Analysis:
1. GenerateTableSchemaString in CarbonMetastore did not have any specific implementation for hive metastore due to which carbontables were being
cached in MetaData. As there is no way to refresh table in hivemetastore therefore this is wrong. All queries should get the latest carbon table
from metastore and not from cache.
2. If updating the main table status fails then revertMainTableChanges method is called to revert the changes. The logic to revert was wrong which led
to wrong entry getting deleted from the schema.
3. Moved the force remove logic before taking locks as deletion from metastore should happen even if the lock if not present as the table is in
stale state(Entry is not there in parent but available in metastore).

This closes #1975
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","e9430312d61c0770f402e3475178addba3c37e5e","28","10","1","5645","698","123","5636","201","9207","1559","305","28","49","6870","0","69","49","528","apache-carbondata","e9430312d61c0770f402e3475178addba3c37e5e","632","16.5","160","91834","53091","12217","5","1867","182","2422","21","4123","73","4.5","5","289","2640","23683","28","985","4092","58","3165","122","58","21847","1.4","398","582","1"
"apache-carbondata","93603705601257a5947f2eca36e3566352748548","2018-02-11 00:06:01","[CARBONDATA-2151][Streaming] Fix filter query issue on streaming table

1.Fix filter query issue for timestamp, date, decimal
2.Add more test case
dataType: int, streaming, float, double, decimal, timestamp, date, complex
operation: =, <>, >=, >, <, <=, in, like, between, is null, is not null

This closes #1969
","refs/heads/master","qiangcai@qq.com","apache-carbondata","93603705601257a5947f2eca36e3566352748548","28","10","1","5644","698","123","5636","201","9207","1559","305","28","49","6870","0","69","49","528","apache-carbondata","93603705601257a5947f2eca36e3566352748548","632","16.5","160","91827","53086","12216","5","1866","182","2421","21","4122","73","4.5","5","289","2639","23682","28","985","4092","58","3165","122","58","21842","1.4","398","582","1"
"apache-carbondata","ceaddeacb6264a0ed92bc3c0c6cd874333d1fc51","2018-02-14 02:15:04","[CARBONDATA-2183] Fix compaction when segment is delete during compaction and remove unnecessary parameters in functions

Problem:
when compaction is started and job is running, and parallelly the segment involved in the compaction is deleted using DeleteSegmentByID, then
compaction is success.

Solution:
when compaction is started and job is running, and parallelly the segment involved in the compaction is deleted using DeleteSegmentByID, then
compaction should be aborted and failed. and proper error message should thrown to user. THis PR also removes the unnecessary parameters in functions.

This closes #1979
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","ceaddeacb6264a0ed92bc3c0c6cd874333d1fc51","28","10","1","5641","698","123","5636","201","9187","1559","305","28","49","6822","0","69","49","528","apache-carbondata","ceaddeacb6264a0ed92bc3c0c6cd874333d1fc51","632","16.5","160","91717","52996","12187","5","1866","178","2421","20.9","4117","73","4.4","5","289","2639","23640","28","985","4056","58","3165","122","58","21802","1.4","398","582","1"
"apache-carbondata","e16e878189baa82bee5ca8af8d1229b7733b454a","2018-02-02 03:03:45","[CARBONDATA-1454]false expression handling and block pruning

Issue :- In case of wrong value/invalid for time-stamp and date data type. all blocks are identified for scan .

Solution :- Add False Expression handling and False Filter Executor. it can be used to handle invalid Filter value.

This closes #1915
","refs/heads/master","babulaljangir111@gmail.com","apache-carbondata","e16e878189baa82bee5ca8af8d1229b7733b454a","28","10","1","5635","696","123","5622","200","9189","1562","305","28","49","6810","0","69","49","528","apache-carbondata","e16e878189baa82bee5ca8af8d1229b7733b454a","632","16.5","159","91646","52943","12173","5","1867","178","2420","20.9","4118","73","4.4","5","287","2637","23603","27","985","4056","58","3145","122","58","21788","1.4","398","582","1"
"apache-carbondata","cc4bc810005003130f66d8021a06bbc8e3f87bbd","2018-02-06 00:03:39","[CARBONDATA-2133] Fixed Exception displays after performing select query on newly added Boolean Type

Problem : In Restructure util and RestructureBasedVectorResultCollector to get the default value of a measure type the case for boolean data type was
missing,and in DataTypeUtil to store default value in bytes case of boolean data type was missing

Solution: Add the Boolean data type case

This closes #1934
","refs/heads/master","anubhav.tarar@knoldus.in","apache-carbondata","cc4bc810005003130f66d8021a06bbc8e3f87bbd","28","10","1","5645","698","123","5636","201","9199","1562","305","28","49","6823","0","69","49","528","apache-carbondata","cc4bc810005003130f66d8021a06bbc8e3f87bbd","632","16.5","160","91735","53010","12190","5","1867","178","2422","20.9","4121","73","4.4","5","289","2640","23641","28","985","4056","58","3165","122","58","21807","1.4","398","582","1"
"apache-carbondata","ab11a484e2a2d7425472980ef72c9a4a0d2c1d8b","2018-02-14 05:37:15","[CARBONDATA-2182] Added one more params called extraParams in SessionParams and add carbonSessionInfo to CarbonEnvInitPreEvent

Add one more param called ExtraParmas in SessionParams for session Level operations and pass the carbonSessionInfo to event, so that user can
save information in that at session level in carbonSessionInfo

This closes #1978
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","ab11a484e2a2d7425472980ef72c9a4a0d2c1d8b","28","10","1","5645","696","123","5636","201","9199","1562","305","28","49","6822","0","69","49","528","apache-carbondata","ab11a484e2a2d7425472980ef72c9a4a0d2c1d8b","632","16.5","160","91728","53002","12187","5","1868","178","2423","20.9","4121","73","4.4","5","289","2641","23633","28","985","4056","58","3165","122","58","21822","1.4","398","582","1"
"apache-carbondata","7c05f5f18a815fdf23de4a703888f9962071fad7","2018-02-06 05:11:35","[CARBONDATA-2137] Delete query performance improved

Following is the configuration used :

SPARK_EXECUTOR_MEMORY : 200G
SPARK_DRIVER_MEMORY : 20G
SPARK_EXECUTOR_CORES : 32
SPARK_EXECUTOR_INSTANCEs : 3

Earlier it was taking 20 minute now it is taking approx 5 minute

This closes #1937
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","7c05f5f18a815fdf23de4a703888f9962071fad7","28","10","1","5641","696","123","5630","201","9196","1562","305","28","49","6820","0","69","49","528","apache-carbondata","7c05f5f18a815fdf23de4a703888f9962071fad7","632","16.5","160","91705","52985","12184","5","1867","178","2422","20.9","4120","73","4.4","5","289","2640","23624","28","985","4056","58","3165","122","58","21817","1.4","398","582","1"
"apache-carbondata","11a795ceca80e74de8264cba3571ca78ce03fae4","2018-02-05 03:40:18","[CARBONDATA-2134] Prevent implicit column filter list from getting serialized while submitting task to executor

Problem
In the current store blocklet pruning in driver and no further pruning takes place in the executor side. But still the implicit column filter list being sent to executor. As the size of list grows the cost of serializing and deserializing the list is increasing which can impact the query performance.

Solution
Remove the list from the filter expression before submitting the task to executor.

This closes #1935
","refs/heads/master","manish.gupta@huawei.com","apache-carbondata","11a795ceca80e74de8264cba3571ca78ce03fae4","28","10","1","5641","696","123","5624","201","9194","1562","305","28","49","6817","0","69","49","528","apache-carbondata","11a795ceca80e74de8264cba3571ca78ce03fae4","632","16.5","160","91692","52973","12183","5","1868","178","2421","20.9","4119","73","4.4","5","287","2639","23618","28","985","4056","58","3165","122","58","21798","1.4","398","582","1"
"apache-carbondata","4a2d799272391e1c5d06416cbb9bdb6454488753","2018-02-06 22:37:33","[CARBONDATA-2143] Fixed query memory leak issue for task failure during initialization of record reader

Problem:
Whenever a query is executed, in the internalCompute method of CarbonScanRdd class record reader is initialized. A task completion listener is attached to each task after initialization of the record reader.
During record reader initialization, queryResultIterator is initialized and one blocklet is processed. The blocklet processed will use available unsafe memory.
Lets say there are 100 columns and 80 columns get the space but there is no space left for the remaining columns to be stored in the unsafe memory. This will result is memory exception and record reader initialization will fail leading to failure in query.
In the above case the unsafe memory allocated for 80 columns will not be freed and will always remain occupied till the JVM process persists.

Impact
It is memory leak in the system and can lead to query failures for queries executed after one one query fails due to the above reason.

Solution:
Attach the task completion listener before record reader initialization so that if the query fails at the very first instance after using unsafe memory, still that memory will be cleared.

This closes #1948
","refs/heads/master","manish.gupta@huawei.com","apache-carbondata","4a2d799272391e1c5d06416cbb9bdb6454488753","28","10","1","5637","696","123","5622","201","9189","1562","305","28","49","6810","0","69","49","528","apache-carbondata","4a2d799272391e1c5d06416cbb9bdb6454488753","632","16.5","160","91658","52951","12176","5","1867","178","2420","20.9","4118","73","4.4","5","287","2638","23608","28","985","4056","58","3165","122","58","21788","1.4","398","582","1"
"apache-carbondata","4a2a2d1b74901f96efc4ecf9cc16e9804884b929","2018-02-02 06:25:16","[CARBONDATA-2122] Add validation for empty bad record path

Data Load having bad record redirect with empty location should throw the exception of Invalid Path.

This closes #1914
","refs/heads/master","jatin.demla@knoldus.in","apache-carbondata","4a2a2d1b74901f96efc4ecf9cc16e9804884b929","28","10","1","5624","696","123","5618","200","9172","1561","305","28","49","6809","0","69","49","528","apache-carbondata","4a2a2d1b74901f96efc4ecf9cc16e9804884b929","630","16.5","159","91519","52888","12162","5","1866","178","2419","21","4110","73","4.4","5","287","2636","23591","27","985","4056","58","3145","122","58","21781","1.4","398","580","1"
"apache-carbondata","50e2f2c8f2cc6ee4b72839b704a038666ae629ba","2018-02-01 21:25:19","[CARBONDATA-2125] like% filter is giving ArrayIndexOutOfBoundException in case of table having more pages

Problem: like% filter is giving ArrayIndexOutOfBoundException in case of table having more pages
Solution: In RowlevelFilter the number of rows should be filled based on the rows in a page.

This closes #1909
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","50e2f2c8f2cc6ee4b72839b704a038666ae629ba","28","10","1","5624","696","123","5618","200","9172","1561","305","28","49","6809","0","69","49","528","apache-carbondata","50e2f2c8f2cc6ee4b72839b704a038666ae629ba","630","16.5","159","91514","52883","12160","5","1866","178","2419","21","4110","73","4.4","5","287","2636","23589","27","985","4056","58","3145","122","58","21781","1.4","398","580","1"
"apache-carbondata","54b7db51906340d6d7b417058f9665731fa51a21","2018-02-02 04:07:51","[CARBONDATA-2119] Fixed deserialization issues for carbonLoadModel

Problem:
Load model was not getting de-serialized in the executor due to which 2 different carbon table objects were being created.
Solution:
Reconstruct carbonTable from tableInfo if not already created.

This closes #1911
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","54b7db51906340d6d7b417058f9665731fa51a21","28","10","1","5624","695","123","5618","200","9172","1561","305","28","49","6809","0","69","49","528","apache-carbondata","54b7db51906340d6d7b417058f9665731fa51a21","630","16.5","159","91508","52877","12158","5","1866","178","2419","21","4110","73","4.4","5","287","2636","23585","27","985","4056","58","3145","122","58","21779","1.4","398","580","1"
"apache-carbondata","349be007fd20fb8c4a39b318e45b47445d2e798c","2018-01-30 07:24:12","[CARBONDATA-2101]Restrict direct query on pre aggregate and timeseries datamap

Restricting direct query on PreAggregate and timeseries data map
Added Property to run direct query on data map for testing purpose
validate.support.direct.query.on.datamap=true

This closes #1888
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","349be007fd20fb8c4a39b318e45b47445d2e798c","28","10","1","5624","695","123","5618","200","9172","1561","305","28","49","6809","0","69","49","528","apache-carbondata","349be007fd20fb8c4a39b318e45b47445d2e798c","630","16.5","159","91508","52877","12158","5","1866","178","2419","21","4110","73","4.4","5","287","2636","23585","27","985","4056","58","3145","122","58","21779","1.4","398","580","1"
"apache-carbondata","46d9bf966910afb98a4e4e9cf879f2a9beef5b72","2018-02-02 10:48:10","[CARBONDATA-2123] Refactor datamap schema thrift and datamap provider to use short name and classname

Update schema thrift file for datamap schema to correct the typo errors and updated the names.
Added class name to schema file and updated short name for each enum.

This closes #1919
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","46d9bf966910afb98a4e4e9cf879f2a9beef5b72","28","10","1","5620","695","123","5610","200","9172","1559","305","28","49","6809","0","69","49","528","apache-carbondata","46d9bf966910afb98a4e4e9cf879f2a9beef5b72","630","16.5","159","91496","52867","12157","5","1866","178","2419","21","4110","73","4.4","5","287","2636","23583","27","985","4056","58","3145","122","58","21776","1.4","398","580","1"
"apache-carbondata","55bffbe2dbe880bb2f7a1e51cf02d49e828098d9","2018-01-30 21:10:11","[CARBONDATA-2104] Add testcase for concurrent execution of insert overwrite and other command

More testcases are added for concurrent execution of insert overwrite and other commands.
Fix bug of delete segment, clean file when insert overwrite in progress
Change in all command processMetadata to throw ProcessMetadataException instead of sys.error

This closes #1891
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","55bffbe2dbe880bb2f7a1e51cf02d49e828098d9","28","10","1","5619","695","123","5612","200","9168","1560","305","28","49","6805","0","69","49","526","apache-carbondata","55bffbe2dbe880bb2f7a1e51cf02d49e828098d9","630","16.5","159","91463","52845","12146","5","1865","178","2419","20.9","4107","73","4.4","5","287","2636","23574","27","985","4056","58","3145","122","58","21780","1.4","399","580","1"
"apache-carbondata","91911af231583b9e2b210dd685770836b358bcd0","2018-02-02 00:32:38","[CARBONDATA-2112] Fixed bug for select operation on datamap with avg and a column name

Problem: When applying select operation(having a column name and an aggregate function) on a
table having a datamap, the data was coming out to be wrong as the group by expression
and aggregate expression were created incorrectly.

Solution: While creating the aggregate and group by expression, we were getting the child
column related to parent column name which was coming out to be wrong so added a new
check there to get the correct child column.

This closes #1910
","refs/heads/master","geetika.gupta@knoldus.in","apache-carbondata","91911af231583b9e2b210dd685770836b358bcd0","28","10","1","5619","695","123","5610","200","9163","1560","305","28","49","6803","0","69","49","526","apache-carbondata","91911af231583b9e2b210dd685770836b358bcd0","630","16.6","159","91440","52822","12138","5","1865","178","2419","20.9","4106","73","4.4","5","287","2636","23560","27","985","4056","58","3145","122","58","21780","1.4","399","580","1"
"apache-carbondata","6c097cbf310e8d2199e57cde4fcc417122a8a1ca","2018-02-02 04:23:57","[CARBONDATA-2120]Fixed is null filter issue

Problem: Is null filter is failing for numeric data type(No dictionary column).

Root cause: Min max calculation is wrong when no dictionary column is not the first column.

As it is not the first column null value can come in between and min max for null value is getting updated only when first row is null

Solution: Update the min max in all the case when value is null or not null for all type

This closes #1912
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","6c097cbf310e8d2199e57cde4fcc417122a8a1ca","28","10","1","5619","695","123","5610","200","9163","1560","305","28","49","6802","0","69","49","526","apache-carbondata","6c097cbf310e8d2199e57cde4fcc417122a8a1ca","630","16.6","159","91439","52821","12137","5","1865","178","2419","20.9","4106","73","4.4","5","287","2636","23560","27","985","4056","58","3145","122","58","21780","1.4","399","580","1"
"apache-carbondata","27ec6515a143dc3b697ac914bfcd4cfe10a49e17","2018-01-31 05:13:02","[CARBONDATA-2108]Updated unsafe sort memory configuration

Deprecated old property: sort.inmemory.size.inmb
Added new property: carbon.sort.storage.inmemory.size.inmb,
If user has configured old property then internally it will be converted to new property
for ex: If user has configured sort.inmemory.size.inmb then 20% memory will be used as working memory and rest for storage memory

This closes #1896
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","27ec6515a143dc3b697ac914bfcd4cfe10a49e17","28","10","1","5619","695","123","5612","200","9164","1560","305","28","49","6802","0","69","49","526","apache-carbondata","27ec6515a143dc3b697ac914bfcd4cfe10a49e17","630","16.6","159","91441","52823","12140","5","1864","178","2418","20.9","4106","73","4.4","5","287","2635","23562","27","985","4056","58","3145","122","58","21765","1.4","399","580","1"
"apache-carbondata","02eefca15862a8667d53e247272afb68efe7af60","2017-11-20 07:06:54","[Compatibility] Added changes for backward compatibility

This PR will fix the issues related to old version and new version compatibility.
Issues fixed:
1. Schema file name was different in one of the previous versions.
2. Bucket number was not supported in the previous versions.
3. Table parameters were stored in lower case while in the current version we are reading in camel case.

This closes #1747
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","02eefca15862a8667d53e247272afb68efe7af60","28","10","1","5617","694","122","5592","200","9153","1559","305","28","49","6802","0","69","49","524","apache-carbondata","02eefca15862a8667d53e247272afb68efe7af60","630","16.6","159","91337","52724","12124","5","1858","178","2411","20.9","4103","73","4.4","5","287","2627","23517","26","970","4060","57","3145","122","58","21713","1.4","398","580","1"
"apache-carbondata","473bd3197a69e3c0574f8c07f04c29e43f7a023d","2017-12-22 04:00:31","[CARBONDATA-2043] Configurable wait time for requesting executors and minimum registered executors ratio to continue the block distribution
- carbon.dynamicAllocation.schedulerTimeout : to configure wait time. defalt 5sec, Min 5 sec and max 15 sec.
- carbon.scheduler.minRegisteredResourcesRatio :     min 0.1, max 1.0 and default to 0.8 to configure minimum registered executors ratio.

This closes #1822
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","473bd3197a69e3c0574f8c07f04c29e43f7a023d","28","10","1","5616","694","122","5592","200","9148","1559","305","28","49","6799","0","69","49","524","apache-carbondata","473bd3197a69e3c0574f8c07f04c29e43f7a023d","630","16.6","159","91319","52707","12116","5","1858","178","2411","20.9","4102","73","4.4","5","287","2627","23508","26","970","4060","57","3145","122","58","21713","1.4","398","580","1"
"apache-carbondata","54a381c27024ece07d400a4a1d36917bd3ca09f9","2018-01-23 01:56:26","[CARBONDATA-2064] Add compaction listener

This closes #1847
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","54a381c27024ece07d400a4a1d36917bd3ca09f9","28","10","1","5618","694","122","5582","200","9146","1559","305","28","50","6797","0","217","49","524","apache-carbondata","54a381c27024ece07d400a4a1d36917bd3ca09f9","630","16.6","159","91246","52656","12113","5","1858","178","2411","20.9","4101","73","4.4","5","287","2627","23504","26","970","4060","57","3145","122","58","21702","1.4","398","580","1"
"apache-carbondata","1202e209eccda172f9671fa0cc2deeebeb4af456","2018-01-31 23:12:49","[CARBONDATA-2113]compatibility fix for v2

Fixes related to backword compatibility:

Count() issue:
when count() is run on old store where file format version is V2, it was unable to get the files, because when forming the filepath while creating the table block info object from index file info, the path was formed with double slash(//), beacuse in v2, local path was stored. so when trying to get this path with key, it was failing. So form the correct file path.

Select * issue:
when select * is run, then only the datachunck was considered as whole data and while uncompressing the measure data, it was failing. So, read proper data and datachunck before uncompressing.

Read Metadata file:
when readMetadataFile is called , the while reading the schema, it was explicitly returning null, so columns will be null and hence some nullpointerxception was coming. so do not return null, return proper schema, by reading the footer.

Vesion compatibility:
calculation the number of pages to be filled based on row count was not handled for V2 version, handled same, as no. of rows per page is different in V2 and V3

This closes #1901
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","1202e209eccda172f9671fa0cc2deeebeb4af456","28","10","1","5619","694","122","5586","200","9146","1559","305","28","50","6797","0","217","49","524","apache-carbondata","1202e209eccda172f9671fa0cc2deeebeb4af456","630","16.6","159","91253","52658","12113","5","1858","178","2411","20.9","4101","73","4.4","5","287","2627","23504","26","970","4060","57","3145","122","58","21702","1.4","398","580","1"
"apache-carbondata","1248bd4b7ff4bb45392106082011dde7f9db460f","2018-01-29 19:26:13","Problem:
For old store the measure min and max values are written opposite (i.e min in place of max and max in place of min). Due to this computing of measure filter with current code is impacted.
This problem specifically comes when measure data has negative values.

Impact
Filter query on measure

Solution
In order to sync with current min and max values for old store, measures min and max value is reversed by using an old store flag.

This closes #1879
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","1248bd4b7ff4bb45392106082011dde7f9db460f","28","10","1","5618","694","122","5584","200","9148","1559","305","28","50","6796","0","217","49","524","apache-carbondata","1248bd4b7ff4bb45392106082011dde7f9db460f","630","16.6","159","91235","52646","12113","5","1858","178","2411","20.9","4101","73","4.5","5","287","2627","23500","26","970","4060","57","3145","122","58","21717","1.4","398","580","1"
"apache-carbondata","d680e9cf5016475e6e9b320c27be6503e1c6e66c","2018-01-15 01:05:56","[CARBONDATA-2012] Add support to load pre-aggregate in one transaction

Current if a table(t1) has 2 preaggregate table(p1,p2) then while loading all the pre-aggregate tables are committed(table status writing) and then the parent table is committed.

After this PR the flow would be like this:

load t1
load p1
load p2
write table status for p2 with transactionID
write table status for p1 with transactionID
rename tablestatus_UUID to tablestatus for p2
rename tablestatus_UUID to tablestatus for p1
write table status for t1

This closes #1781
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","d680e9cf5016475e6e9b320c27be6503e1c6e66c","28","10","1","5607","699","122","5568","200","9135","1558","305","28","50","6766","0","217","46","524","apache-carbondata","d680e9cf5016475e6e9b320c27be6503e1c6e66c","630","16.6","159","91154","52597","12106","5","1859","178","2415","20.9","4098","73","4.5","5","288","2632","23475","27","980","4060","58","3145","122","60","21751","1.4","398","580","1"
"apache-carbondata","7ed144c537b48353de1ee8bf710c884d555c01ce","2018-01-23 07:42:39","[CARBONDATA-2092] Fix compaction bug to prevent the compaction flow from going through the restructure compaction flow

Problem and analysis:
During data load current schema timestamp is written to the carbondata fileHeader. This is used during compaction to decide whether the block is a restructured block or the block is according to the latest schema.
As the blocklet information is now stored in the index file, while laoding it in memory the carbondata file header is not read and due to this the schema timestamp is not getting set to the blocklet information. Due to this during compaction flow there is a mismatch on comparing the current schema time stamp with the timestamp stored in the block and the flow goes through the restructure compaction flow instead of normal compaction flow.

Impact:
Compaction performance degradation as restructure compaction flow involves sorting of data again.

Solution:
Modified code to fix compaction bug to prevent the compaction flow from going through the restructure compaction flow until and unless and restructure add or drop column operation has not been performed

This closes #1875
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","7ed144c537b48353de1ee8bf710c884d555c01ce","28","10","1","5605","699","122","5564","200","9131","1557","305","28","50","6765","0","217","46","524","apache-carbondata","7ed144c537b48353de1ee8bf710c884d555c01ce","630","16.6","159","91127","52576","12098","5","1859","178","2415","20.9","4095","73","4.5","5","288","2632","23466","27","980","4060","58","3145","122","60","21751","1.4","398","580","1"
"apache-carbondata","b2139cabe8cdeb7c241e30a525d754578cfa5ec6","2018-01-10 06:59:43","[CARBONDATA-2021]fix clean up issue when update operation is abprutly stopped

when delete is success and update is failed while writing status file then a stale carbon data file is created.
so removing that file on clean up . and also not considering that one during query.

This closes #1793
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","b2139cabe8cdeb7c241e30a525d754578cfa5ec6","28","10","1","5602","699","122","5560","200","9126","1557","305","28","50","6765","0","217","46","524","apache-carbondata","b2139cabe8cdeb7c241e30a525d754578cfa5ec6","630","16.6","159","91101","52565","12094","5","1859","178","2415","20.9","4093","73","4.5","5","288","2632","23461","27","980","4060","58","3145","122","60","21751","1.4","398","580","1"
"apache-carbondata","3c3f33dfcae84af11054eab8bde9ea83f1cf9f0d","2018-01-10 02:53:55","[CARBONDATA-1988] Fixed bug to remove empty partition directory for drop partition command

This closes #1786
","refs/heads/master","geetika.gupta@knoldus.in","apache-carbondata","3c3f33dfcae84af11054eab8bde9ea83f1cf9f0d","28","10","1","5598","697","122","5556","200","9111","1559","305","28","50","6763","0","217","46","526","apache-carbondata","3c3f33dfcae84af11054eab8bde9ea83f1cf9f0d","630","16.6","159","91024","52513","12078","5","1856","178","2412","20.8","4092","73","4.5","5","288","2629","23431","27","980","4060","58","3145","122","60","21713","1.4","398","580","1"
"apache-carbondata","e3498201e084167d3268eb545c2a5ee34269705f","2018-01-17 00:01:56","[CARBONDATA-1964] Fixed bug to set bad.records.action parameter using SET command

Fixed bug to set bad.records.action parameter using SET command

This closes #1819
","refs/heads/master","geetika.gupta@knoldus.in","apache-carbondata","e3498201e084167d3268eb545c2a5ee34269705f","28","10","1","5598","697","122","5556","200","9108","1559","305","28","50","6763","0","217","46","526","apache-carbondata","e3498201e084167d3268eb545c2a5ee34269705f","630","16.6","159","91019","52509","12078","5","1856","178","2412","20.8","4092","73","4.5","5","288","2629","23429","27","980","4060","58","3145","122","60","21713","1.4","398","580","1"
"apache-carbondata","c2528975ae76ff61a1bce73701a9e9162421fcfa","2017-11-18 01:39:37","[CARBONDATA-1765] Remove repeat code of Boolean

Remove repeat code of Boolean

This closes #1529
","refs/heads/master","601450868@qq.com","apache-carbondata","c2528975ae76ff61a1bce73701a9e9162421fcfa","26","12","1","5160","623","121","5232","187","8479","1446","289","31","44","6410","0","68","32","524","apache-carbondata","c2528975ae76ff61a1bce73701a9e9162421fcfa","606","16.5","154","85868","49345","11306","5","1723","185","2269","20.3","3819","72","4.8","5","275","2476","21927","28","880","4127","53","3045","118","56","20560","1.4","394","557","1"
"apache-carbondata","d509f17fbbf31b4baef23821f700bcbbfc987001","2018-01-22 09:47:26","[CARBONDATA-1224] Added page level reader instead of reading whole blocklet in V3

Problem:In V3 format we read the whole blocklet at once to memory in order save IO time. But it turns out to be costlier in case of parallel reading of more carbondata files.For example if we need to compact 50 segments then compactor need to open the readers on all the 50 segments to do merge sort. But the memory consumption is too high if each reader reads whole blocklet to the memory and there is high chances of going out of memory.Solution:In this type of scenarios we can introduce new readers for V3 to read the data page by page instead of reading whole blocklet at once to reduce the memory footprint.

This closes #1089
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","d509f17fbbf31b4baef23821f700bcbbfc987001","28","10","1","5598","697","122","5556","200","9109","1557","305","28","50","6763","0","216","46","526","apache-carbondata","d509f17fbbf31b4baef23821f700bcbbfc987001","630","16.6","159","91015","52505","12077","5","1855","178","2411","20.8","4092","73","4.5","5","288","2628","23427","27","980","4060","58","3145","122","60","21708","1.4","398","580","1"
"apache-carbondata","181c280b7d33ac5e4029bd935d6260b0fe79a2bf","2018-01-26 01:47:46","[CARBONDATA-2088][CARBONDATA-1516] Optimize syntax for creating timeseries pre-aggregate table

change using 'timeseries' instead of using preaggregate for creating timeseries pre-aggregate table

change timeseries.eventTime and hour_granularity and so on
granularity only support one

It should throw UnsupportDataMapException if don't use timeseries or preaggregate to create datamap

This closes #1865
","refs/heads/master","601450868@qq.com","apache-carbondata","181c280b7d33ac5e4029bd935d6260b0fe79a2bf","28","12","1","5557","695","122","5522","197","9068","1550","304","28","50","6792","0","216","46","526","apache-carbondata","181c280b7d33ac5e4029bd935d6260b0fe79a2bf","628","16.5","157","90488","52237","12009","5","1850","178","2404","20.8","4077","73","4.5","5","286","2619","23336","27","980","4052","58","3105","122","60","21643","1.4","396","578","1"
"apache-carbondata","ab763474f9a8191d84ea742a8b6ee615d310999a","2017-12-20 01:39:45","[CARBONDATA-1909] Load is failing during insert into operation when load is concurrently done to source table

This closes #1693
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","ab763474f9a8191d84ea742a8b6ee615d310999a","28","12","1","5553","695","122","5526","197","9067","1550","304","28","50","6792","0","216","46","526","apache-carbondata","ab763474f9a8191d84ea742a8b6ee615d310999a","626","16.5","157","90412","52218","12008","5","1850","178","2404","20.8","4076","73","4.5","5","286","2619","23334","27","980","4052","58","3105","121","60","21643","1.4","396","576","1"
"apache-carbondata","a597c2f9ba5213afd17fec223b5b5a4609c564bf","2018-01-19 08:01:14","[CARBONDATA-2016] Exception displays while executing compaction with alter query

Reason:
When we apply the alter table command to add column with default value it is always storing it as long object for all measures,it is wrongly written
in restructure util we should return the value as the same type as that of the measure,it was causing the compaction to fail with class cast exception
because the data type and its corresponding value does not have same data type

Solution: Correct the wrong logic in restructure util the type of returning value object should be same as that of measure

This closes #1839
","refs/heads/master","anubhav.tarar@knoldus.in","apache-carbondata","a597c2f9ba5213afd17fec223b5b5a4609c564bf","28","12","1","5547","695","122","5522","197","9067","1549","304","28","50","6792","0","216","46","526","apache-carbondata","a597c2f9ba5213afd17fec223b5b5a4609c564bf","626","16.4","157","90394","52215","12008","5","1850","178","2404","20.8","4076","73","4.5","5","286","2619","23334","27","980","4052","58","3105","121","60","21641","1.4","396","576","1"
"apache-carbondata","12ccf708f7b10fd9c7667aa37dc04938e76f36c6","2018-01-22 01:12:07","[CARBONDATA-2061] Check for only valid IN_PROGRESS segments

Problem:
During operations like drop, delete segment, compaction, IUD there is a check for the IN_PROGRESS segments of a table. This check is simply checking the tblstatus file for IN_PROGRESS segments.

Solution:
The check should validate the IN_PROGRESS segments and decide on Valid and Invalid IN_PROGRESS segments.

This closes #1844
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","12ccf708f7b10fd9c7667aa37dc04938e76f36c6","28","12","1","5547","695","122","5522","197","9067","1549","304","28","50","6792","0","216","46","526","apache-carbondata","12ccf708f7b10fd9c7667aa37dc04938e76f36c6","626","16.4","157","90389","52210","12008","5","1851","178","2405","20.8","4076","73","4.5","5","286","2620","23328","27","980","4052","58","3105","121","60","21656","1.4","396","576","1"
"apache-carbondata","3a6136df066b9d0cdeecec283115e4a99d82a900","2018-01-19 03:52:28","[CARBONDATA-2076] Refactored code segregated process meta and process data in load command

This closes #1837
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","3a6136df066b9d0cdeecec283115e4a99d82a900","28","12","1","5547","694","121","5516","197","9062","1549","304","28","50","6787","0","216","46","526","apache-carbondata","3a6136df066b9d0cdeecec283115e4a99d82a900","626","16.5","157","90362","52190","12002","5","1850","178","2403","20.8","4075","73","4.5","5","286","2618","23320","27","980","4052","58","3105","121","60","21632","1.4","395","576","1"
"apache-carbondata","ee11bb1eb7790687b685b4af35ec9f1ab7fa6eff","2018-01-23 05:29:51","[CARBONDATA-2070]fix create preaggregate on decimal column in hive metastore

Problem: when hive metastore is enabled and aggregate table is tried to create on the decimal column of main table, cast exception is thrown for Decimal datatype

solution:During creation of TableInfo from hivemetastore the DataMapSchemas and the columns
dataTypes are not converted to the appropriate child classes.
convert to actual datatype

This closes #1852
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","ee11bb1eb7790687b685b4af35ec9f1ab7fa6eff","28","12","1","5543","694","121","5516","197","9058","1548","304","28","50","6787","0","216","46","526","apache-carbondata","ee11bb1eb7790687b685b4af35ec9f1ab7fa6eff","626","16.5","157","90350","52179","11999","5","1850","178","2403","20.8","4072","73","4.5","5","285","2617","23316","27","950","4052","57","3105","121","60","21632","1.4","395","576","1"
"apache-carbondata","44ffaf57ef5dfbe6f73241d1a1e31536c0ae90d3","2018-01-23 05:01:54","[CARBONDATA-2071] Added block size to BblockletDataMap while initialising

This closes #1851
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","44ffaf57ef5dfbe6f73241d1a1e31536c0ae90d3","28","12","1","5543","689","121","5516","197","9055","1548","304","28","50","6784","0","216","46","526","apache-carbondata","44ffaf57ef5dfbe6f73241d1a1e31536c0ae90d3","626","16.5","157","90339","52168","11995","5","1849","178","2402","20.8","4072","73","4.5","5","285","2616","23309","27","950","4052","57","3105","121","60","21621","1.4","395","576","1"
"apache-carbondata","315f41c12557d9d8a355210082f096e1e6a19aca","2018-01-19 06:57:05","[CARBONDATA-2060] Fix insert overwrite on partition table

Problem:
When insert overwrite is done on partition table with the table which has empty data, it was not overwriting.

Solution:
when insert OverWrite is fired on partition table from empty table, it should create new empty segment and it should delete old segments.

This closes #1838
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","315f41c12557d9d8a355210082f096e1e6a19aca","28","12","1","5535","689","121","5510","197","9050","1548","302","28","50","6783","0","216","46","526","apache-carbondata","315f41c12557d9d8a355210082f096e1e6a19aca","625","16.5","157","90260","52131","11993","5","1849","178","2401","20.9","4070","73","4.5","5","285","2615","23296","27","950","4052","57","3105","121","60","21619","1.4","394","575","1"
"apache-carbondata","b4dc866fec0a42196435c6da0e1413dc2a2398d1","2018-01-18 05:21:50","[CARBONDATA-2036] Fix the insert static partition with integer values prefix with 0 not working

When trying to insert overwrite on the static partition with 0 at first on int column has an issue.Example :create table test(d1 string) partition by (c1 int, c2 int, c3 int)And use insert overwrite table partition(01, 02, 03) select s1The above case has a problem as 01 is not converting to an actual integer to partition map file.Solution :Convert the partition values to corresponding datatype value before adding to partition file.

This closes #1833
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b4dc866fec0a42196435c6da0e1413dc2a2398d1","28","12","1","5535","689","121","5510","197","9050","1548","302","28","50","6782","0","216","46","526","apache-carbondata","b4dc866fec0a42196435c6da0e1413dc2a2398d1","625","16.5","157","90258","52129","11992","5","1849","178","2401","20.9","4070","73","4.5","5","285","2615","23295","27","950","4052","57","3105","121","60","21618","1.4","394","575","1"
"apache-carbondata","937868d1b45af56c575ee77b93b99c35b8d632b7","2018-01-17 02:03:25","[HOTFIX] Listeners not getting registered to the bus in CarbonSessionState Implementations

Problem: Listeners are not getting registered if you create a new implementation of CarbonSessionState and add it to spark using configuration. In this case CarbonSession would not be created and thus listeners are not registered.

Solution: Register listeners in CarbonSessionState instead of CarbonSession.

This closes #1821
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","937868d1b45af56c575ee77b93b99c35b8d632b7","28","12","1","5536","689","121","5510","197","9050","1548","302","28","49","6778","0","68","46","526","apache-carbondata","937868d1b45af56c575ee77b93b99c35b8d632b7","625","16.4","157","90246","52141","11987","5","1848","178","2400","20.8","4069","73","4.5","5","285","2614","23294","27","950","4052","57","3105","121","60","21616","1.4","394","575","1"
"apache-carbondata","aac7af7333aabd3b94e5e91c49f3f3d766103048","2018-01-17 01:04:56","[CARBONDATA-2042][PreAggregate]Fixed data mismatch issue in case timeseries

Problem: Year, Month, Day level timeseries table giving wrong result
Solution: Timeseries UDF is not able to convert data when hour is in 24 hours format

This closes #1820
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","aac7af7333aabd3b94e5e91c49f3f3d766103048","28","12","1","5533","689","121","5508","196","9049","1547","302","28","48","6773","0","68","46","526","apache-carbondata","aac7af7333aabd3b94e5e91c49f3f3d766103048","625","16.4","157","90228","52127","11981","5","1849","178","2401","20.8","4066","73","4.5","5","285","2615","23289","27","950","4052","57","3105","121","60","21618","1.4","394","575","1"
"apache-carbondata","fdf90a4ed5c4c64584246ed5e960dd0925f74669","2017-08-03 18:40:47","[CARBONDATA-1357] fix convert bug

fix byte[] to string convert bug

This closes #1228
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","fdf90a4ed5c4c64584246ed5e960dd0925f74669","27","6","0","4544","523","91","4896","148","7450","1315","303","29","46","5978","0","23","21","498","apache-carbondata","fdf90a4ed5c4c64584246ed5e960dd0925f74669","547","17.3","126","79206","44800","9925","5","1655","152","2168","19.5","3426","64","4.2","5","246","2354","19564","34","960","3302","60","2490","110","69","18970","1.4","350","509","1"
"apache-carbondata","5ea538fe523749aa7f22629cd17a36c7a3e73b90","2018-01-12 04:58:56","[CARBONDATA-2039] Add relative blocklet id during initialization in the blocklet data map

Problem
Currently while loading the blocklets in data map all the blocklets are stored in the unsafe manager on array indexes for all the blocklets in one segment. So lets say if 1 segment has 7 task and each task has 10 part files with 3 blocklets each, total number of blocklets in the segment would be 210. Unsafe store will store all these blocklets in one array with start index as 0 and end index as 210.
Due to this while filling the blocklet information the blocklet id taken is the array index which can be any number from 0 to 210. This is leading to loss in actual mapping of blocklet with respect to carbondata file.

Solution
Add the relative blocklet id during loading of blocklets in the unsafe store (relative blocklet id is the id of blocklet in the carbondata file)

This closes #1796
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","5ea538fe523749aa7f22629cd17a36c7a3e73b90","28","12","1","5533","689","121","5508","196","9049","1547","302","28","48","6773","0","68","46","526","apache-carbondata","5ea538fe523749aa7f22629cd17a36c7a3e73b90","625","16.4","157","90228","52127","11981","5","1849","178","2401","20.8","4066","73","4.5","5","285","2615","23289","27","950","4052","57","3105","121","60","21618","1.4","394","575","1"
"apache-carbondata","d1d726a777c8ed848d71fa05a18dfd70b05d65bd","2018-01-16 21:57:09","[CARBONDATA-2020][Old Store Support] Add filter support for old store reading to improve query performance

Problem
For old stores blocklet level min/max comparison was not happening in the executor side due to which all the blocklets were getting scanned. This increased the IO and scanning time in the executor.

Solution
Modified code to retrieve the min/max value from blocklet node and use it for comparsion while scanning for valid blocklets.

This closes #1818
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","d1d726a777c8ed848d71fa05a18dfd70b05d65bd","28","12","1","5528","689","121","5498","196","9048","1547","302","28","48","6764","0","68","46","526","apache-carbondata","d1d726a777c8ed848d71fa05a18dfd70b05d65bd","625","16.4","157","90203","52113","11979","5","1847","178","2398","20.8","4066","73","4.5","5","285","2612","23277","27","950","4052","57","3105","121","60","21601","1.4","393","575","1"
"apache-carbondata","41b0074705fae4ff11202caf4603451a89320024","2018-01-16 00:07:50","[CARBONDATA-2037]Store carbondata locations in datamap to make the datamap retrieval faster

Currently carbondata locations are getting from namenode for each query and that makes queries slower. So this PR stores the block locations while loading
datamap and retrieves from it.
1. Store carbondata locations in datamap to make the datamap retrieval faster.
2. Add method to convert unsafe to safe to avoid multiple calculations.

This closes #1810
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","41b0074705fae4ff11202caf4603451a89320024","28","12","1","5525","689","121","5496","196","9045","1547","302","28","48","6744","0","68","46","526","apache-carbondata","41b0074705fae4ff11202caf4603451a89320024","625","16.4","157","90143","52063","11967","5","1845","178","2396","20.8","4064","73","4.5","5","285","2610","23253","27","950","4052","57","3105","121","60","21571","1.4","393","575","1"
"apache-carbondata","29c985587952945c9f2f5c3082a733ef32df4686","2018-01-15 04:01:44","[CARBONDATA-2028] Select Query failed with preagg having timeseries and normal agg table together

Select Query failed with preagg having timeseries and normal agg table together Root Cause:- hasTimeSeriesDataMap(CarbonTable carbonTable) in CarbonUtil returns result based on 1st DataMap. Solution:it should iterators all the DataMap and when finds timeseries datamap , then should returns the true.

This closes #1804
","refs/heads/master","babulaljangir111@gmail.com","apache-carbondata","29c985587952945c9f2f5c3082a733ef32df4686","28","12","1","5520","676","121","5490","197","9012","1541","301","28","49","6684","0","68","46","526","apache-carbondata","29c985587952945c9f2f5c3082a733ef32df4686","626","16.5","157","89928","51893","11933","5","1841","183","2393","20.8","4055","73","4.6","5","287","2607","23164","27","950","4099","57","3105","121","60","21615","1.4","392","575","1"
"apache-carbondata","383b2ed357f93c0a18fcbfb85e36e7156a0ee610","2018-01-15 22:47:53","[CARBONDATA-2031] Fix ArrayIndexOutOfBoundException when filter query is applied on column where all values are null and column is noinverted index column

Fix ArrayIndexOutOfBoundException when filter query is applied on column where all values are null and column is noinverted index column.when all the values are null in no inverted index column the number of exclude filter keys are null, hence just return the bitset if the exclude filters to be applied are none.

This closes #1809
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","383b2ed357f93c0a18fcbfb85e36e7156a0ee610","27","12","1","5520","676","121","5490","197","9012","1541","301","28","49","6684","0","68","46","526","apache-carbondata","383b2ed357f93c0a18fcbfb85e36e7156a0ee610","626","16.5","157","89926","51891","11932","5","1840","183","2392","20.8","4055","73","4.6","5","287","2606","23163","27","950","4099","57","3105","121","60","21610","1.4","392","575","1"
"apache-carbondata","4f9aeaea8290764dc108e4e3c2df0c479f311659","2018-01-16 01:07:25","[CARBONDATA-2034]Fixed Query performance issue

Problem: Dictionary loading is taking more time in executor side when number of nodes is high.

Solution: During query no need to load non complex dimension dictionary. Dictionary decoder will take care of loading and decoding the dictionary column

This closes #1811
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","4f9aeaea8290764dc108e4e3c2df0c479f311659","27","12","1","5519","676","121","5490","197","9012","1541","301","28","49","6684","0","68","46","526","apache-carbondata","4f9aeaea8290764dc108e4e3c2df0c479f311659","626","16.5","157","89922","51888","11930","5","1840","183","2392","20.7","4055","73","4.6","5","287","2606","23161","27","950","4099","57","3105","121","60","21608","1.4","392","575","1"
"apache-carbondata","7504a5c51fbebb682d4917e91e927933b113280a","2018-01-14 05:29:09","[CARBONDATA-2026] Fix all issues and testcases when enabling carbon hive metastore

This closes #1799
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7504a5c51fbebb682d4917e91e927933b113280a","27","12","1","5518","676","121","5490","197","9011","1540","301","28","49","6689","0","68","46","526","apache-carbondata","7504a5c51fbebb682d4917e91e927933b113280a","626","16.5","157","89921","51886","11928","5","1839","183","2391","20.7","4055","73","4.6","5","287","2605","23160","27","950","4099","57","3105","121","60","21606","1.4","392","575","1"
"apache-carbondata","6094af6823be994f4a18d5cd3502bc6e2aef3d22","2018-01-10 07:35:48","[CARBONDATA-2020] Fix avoid reading of all block information in driver for old stores

Problem:
For old stores prior to 1.2 version there is no blocklet information stored in carbonindex file. So the new code needs to read all carbondata files footers inside
the driver to get the blocklet information. That makes the first time queries become slower.
As observed count(*) query was taking 2 swconds on old version and after upgrade it takes very long time.

Solution:
If there is no information blocklet available in carbonindex file then don't read carbondata files footer in driver side. Instead read carbondata files in executor
to get the blocklet information.

This closes #1789
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","6094af6823be994f4a18d5cd3502bc6e2aef3d22","27","12","1","5519","676","121","5490","197","9011","1540","301","28","49","6681","0","68","46","526","apache-carbondata","6094af6823be994f4a18d5cd3502bc6e2aef3d22","626","16.5","157","89893","51874","11925","5","1839","183","2391","20.7","4054","73","4.6","5","287","2605","23159","27","950","4099","57","3105","121","60","21606","1.4","392","575","1"
"apache-carbondata","e820006bc5830d096c6d5e4ebeff887e6ca14e21","2018-01-09 07:02:36","[CARBONDATA-2019] Enhancement of merge index compaction feature to support creation of merge index file on old store where index file does not contain the blocklet info

Enhancement of merge index compaction feature to support creation of merge index file on old store where index file does not contain the blocklet info.
Old store created with carbondata 1.1 version does not contain the blocklet info in the index file. On that store if merge index file is created then blocklet information will not be present in the merge index file and for first time query again carbondata file footer will be read for blocklet information retrieval.
Benefits:

Support merge index file creation on old store
Improve first time query performance.
Note: First time query performance will be improved only if merge index file is created before running the first query

This closes #1782
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","e820006bc5830d096c6d5e4ebeff887e6ca14e21","27","12","1","5499","670","121","5458","195","8964","1535","299","28","48","6647","0","68","46","526","apache-carbondata","e820006bc5830d096c6d5e4ebeff887e6ca14e21","625","16.5","157","89599","51659","11905","5","1836","183","2385","20.7","4045","73","4.6","5","287","2599","23028","27","950","4099","57","3105","121","60","21578","1.4","389","575","1"
"apache-carbondata","fc81d831cdc608435104d27eb2c39a57f66c80ed","2018-01-10 23:04:22","[CARBONDATA-2010] Block streaming on main table of preaggregate datamap

If the table has 'preaggregate' DataMap, it doesn't support streaming now

This closes #1791
","refs/heads/master","qiangcai@qq.com","apache-carbondata","fc81d831cdc608435104d27eb2c39a57f66c80ed","27","12","1","5484","670","121","5442","195","8934","1534","299","28","48","6642","0","68","46","526","apache-carbondata","fc81d831cdc608435104d27eb2c39a57f66c80ed","625","16.4","157","89423","51552","11889","5","1836","183","2385","20.7","4039","73","4.6","5","287","2599","22971","27","950","4099","57","3105","121","60","21578","1.4","389","575","1"
"apache-carbondata","943588d1f07d8eb64b1ebcf84bdc7216049a182c","2018-01-10 02:59:14","[CARBONDATA-2015] Restricted maximum length of bytes per column

Validation for number of bytes for a column is added.

We have limited the number of characters per column to 32000. For example, a single unicode character takes 3 bytes. So in this case, if my column has 30,000 unicode characters, then 32000 * 3 exceeds the short range. So, load will fail.

This closes #1785
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","943588d1f07d8eb64b1ebcf84bdc7216049a182c","27","12","1","5484","670","121","5442","195","8932","1534","299","28","48","6641","0","68","46","526","apache-carbondata","943588d1f07d8eb64b1ebcf84bdc7216049a182c","625","16.4","157","89408","51541","11883","5","1836","183","2385","20.7","4038","73","4.6","5","287","2599","22964","27","950","4099","57","3105","121","60","21578","1.4","389","575","1"
"apache-carbondata","df278312c32ee9e377eced1f7d70fcec9c9248ba","2018-01-03 05:47:53","[CARBONDATA-1978] Handled preaggregate issues with hive metastore

During creation of TableInfo from hivemetastore the DataMapSchemas and the columns DataTypes are not converted to the appropriate child classes due to which data types not supported exception is thrown

This closes #1758
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","df278312c32ee9e377eced1f7d70fcec9c9248ba","27","12","1","5481","670","121","5440","195","8932","1534","299","28","48","6641","0","68","46","526","apache-carbondata","df278312c32ee9e377eced1f7d70fcec9c9248ba","625","16.4","157","89399","51536","11881","5","1836","183","2385","20.7","4038","73","4.6","5","287","2599","22962","27","950","4099","57","3105","121","60","21578","1.4","389","575","1"
"apache-carbondata","c1002511af34a3c2ce0ef05f3fb8977d33d43a68","2017-12-26 23:20:15","[CARBONDATA-1839] [DataLoad] Fix bugs and optimize in compressing sort temp files

1.fix bugs in compressing sort temp file, use file-level compression instead of batch-record-level compression

2.add tests

3.update docs, add property to configure the compressor

This closes #1707
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","c1002511af34a3c2ce0ef05f3fb8977d33d43a68","27","12","1","5458","660","121","5428","196","8925","1531","295","28","48","6615","0","67","46","526","apache-carbondata","c1002511af34a3c2ce0ef05f3fb8977d33d43a68","625","16.4","156","89099","51323","11810","5","1828","185","2382","20.5","4028","73","4.6","5","283","2592","22858","28","905","4125","54","3085","121","60","21495","1.4","393","575","1"
"apache-carbondata","1b72a02be2f176bcc99dc12f7621a0623d39b973","2018-01-07 19:14:00","[CARBONDATA-1999] Block drop table and delete streaming segment while streaming is in progress

1.Block drop table while streaming is in progress
2.Block delete streaming segment

This closes #1773
","refs/heads/master","qiangcai@qq.com","apache-carbondata","1b72a02be2f176bcc99dc12f7621a0623d39b973","27","12","1","5479","667","121","5440","194","8923","1530","299","28","48","6603","0","68","46","526","apache-carbondata","1b72a02be2f176bcc99dc12f7621a0623d39b973","625","16.5","156","89313","51460","11828","5","1827","183","2376","20.6","4036","73","4.6","5","285","2588","22898","27","940","4099","56","3085","121","60","21450","1.4","389","575","1"
"apache-carbondata","ed2c01f5d4d2da07449046271933f47e76b430af","2018-01-06 18:58:54","[HOTFIX] Fix exception handling in PartitionMapFileStore

Exception should not be ignored in PartitionMapFileStore.java, it should be thrown instead.

This closes #1771
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","ed2c01f5d4d2da07449046271933f47e76b430af","27","12","1","5479","664","121","5440","194","8923","1530","299","28","48","6608","0","68","46","526","apache-carbondata","ed2c01f5d4d2da07449046271933f47e76b430af","625","16.5","156","89307","51454","11825","5","1828","183","2376","20.6","4036","73","4.6","5","285","2588","22889","27","940","4099","56","3085","121","60","21440","1.4","388","575","1"
"apache-carbondata","c70e73f11b281cde9e8310d5a2d5640c75c30665","2017-12-25 01:34:39","[CARBONDATA-1926][CARBONDATA-1927][Pre-Aggregate] Expression support inside aggregate function for Query

Support transforming of query plan for aggregate table when query aggregate function contains any expression
Support sub query in Preaggregate table

This closes #1728
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","c70e73f11b281cde9e8310d5a2d5640c75c30665","27","12","1","5479","664","121","5440","194","8923","1530","299","28","48","6608","0","68","46","526","apache-carbondata","c70e73f11b281cde9e8310d5a2d5640c75c30665","625","16.5","156","89307","51454","11826","5","1828","183","2377","20.6","4036","73","4.6","5","286","2589","22889","27","940","4099","56","3085","121","60","21450","1.4","388","575","1"
"apache-carbondata","af4277e9495faac3082e8c179cc049bcbeb699e2","2018-01-02 21:18:09","[CARBONDATA-1976][PARTITION] Support combination of dynamic and static partitions. And fix concurrent partition load issue.

Support combination of dynamic and static partitions.

This closes #1755
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","af4277e9495faac3082e8c179cc049bcbeb699e2","27","12","1","5478","665","121","5436","194","8932","1533","299","28","48","6615","0","68","46","526","apache-carbondata","af4277e9495faac3082e8c179cc049bcbeb699e2","625","16.5","156","89345","51480","11836","5","1829","183","2378","20.6","4035","73","4.6","5","286","2590","22905","27","940","4099","56","3085","121","60","21467","1.4","388","575","1"
"apache-carbondata","829e7aa4e28e065d5162bd0ec48b4edfa4f6dc3d","2018-01-03 03:32:33","[CARBONDATA-1977][PARTITION] Fix aggregation table loading after loading of partition table.

Aggregate tables are not loading for the partition tables. Because the load events are not fired during the partition table load.

This closes #1757
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","829e7aa4e28e065d5162bd0ec48b4edfa4f6dc3d","27","12","1","5476","664","121","5434","193","8930","1533","299","28","48","6603","0","68","46","526","apache-carbondata","829e7aa4e28e065d5162bd0ec48b4edfa4f6dc3d","625","16.4","156","89317","51457","11829","5","1827","183","2376","20.6","4035","73","4.6","5","286","2588","22894","27","940","4099","56","3085","121","60","21449","1.4","388","575","1"
"apache-carbondata","08b8af7b044fa761caf58da2875935d40d4ca13b","2018-01-04 01:45:42","[CARBONDATA-1984][Compression Codec] Double Compression Codec Rectification.

This closes #1763
","refs/heads/master","sounakr@gmail.com","apache-carbondata","08b8af7b044fa761caf58da2875935d40d4ca13b","27","12","1","5475","664","121","5434","193","8930","1533","299","28","48","6603","0","68","46","526","apache-carbondata","08b8af7b044fa761caf58da2875935d40d4ca13b","625","16.5","156","89314","51455","11829","5","1827","183","2376","20.6","4035","73","4.6","5","285","2587","22894","27","910","4099","55","3085","121","60","21449","1.4","388","575","1"
"apache-carbondata","bcf3ca3feda544dcbc1b5c096b98369c8a27f4e3","2017-12-22 03:22:44","[CARBONDATA-1929][Validation]carbon property configuration validation + Fixed test case

Added validation for below parameter:
carbon.timestamp.format
carbon.date.format
carbon.sort.file.write.buffer.size (minValue = 10 KB, maxValue=10MB, defaultValue =16 KB )
carbon.sort.intermediate.files.limit (minValue = 2, maxValue=50, defaultValue =20 )

This closes #1718
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","bcf3ca3feda544dcbc1b5c096b98369c8a27f4e3","27","12","1","5475","664","121","5434","193","8930","1533","299","28","48","6603","0","68","46","526","apache-carbondata","bcf3ca3feda544dcbc1b5c096b98369c8a27f4e3","625","16.5","156","89314","51455","11829","5","1827","185","2376","20.6","4035","73","4.6","5","285","2587","22894","27","910","4119","55","3085","121","60","21469","1.4","388","575","1"
"apache-carbondata","1799642b1eed187c810d32a358777b76a167c8b2","2017-12-28 07:41:46","[CARBONDATA-1932]Add version info for CarbonData

Add version info for CarbonData.
The way of generating version info is the same as spark.

This closed #1738
","refs/heads/master","441586683@qq.com","apache-carbondata","1799642b1eed187c810d32a358777b76a167c8b2","27","12","1","5450","659","120","5432","197","8903","1530","295","28","48","6604","0","67","46","526","apache-carbondata","1799642b1eed187c810d32a358777b76a167c8b2","625","16.4","157","88961","51234","11771","5","1825","187","2379","20.5","4018","75","4.7","5","284","2590","22814","28","905","4151","54","3105","121","60","21504","1.4","393","575","1"
"apache-carbondata","6f10c4127914c94fdd6f7af16512e0758f2bb146","2017-12-27 01:15:36","[CARBONDATA-1936][PARTITION] Corrected bad record and avoid double conversion of data in Partitioning table

Currently, one time data conversion happens while loading data while creating RDD to make sure the partitions are added with the right format. But this approach creates an issue in case of bad record handling as the writing of bad records not possible from RDD.
In this PR we don't convert the data in RDD but convert the data while adding the partition information to hive.

This closes #1729
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","6f10c4127914c94fdd6f7af16512e0758f2bb146","27","12","1","5467","660","121","5428","192","8922","1531","299","28","48","6602","0","67","46","526","apache-carbondata","6f10c4127914c94fdd6f7af16512e0758f2bb146","625","16.5","156","89140","51324","11803","5","1826","185","2373","20.5","4030","73","4.6","5","283","2583","22840","27","905","4119","54","3085","121","59","21432","1.4","388","575","1"
"apache-carbondata","e40b34b08210981cbe3bffe73cacff2577fbd8cb","2017-06-28 06:52:45","[CARBONDATA-1249] Wrong order of columns in redirected csv for bad records

Problem:
Wrong order of columns in redirected csv for bad records
The RowParser rearrage the csv raw data based on the inputMapping & outputMapping.
So the converter step does not have actual raw csv record to log or redirect the bad record details.

Steps to repprodcue:

Create employee(Name string, age int, project string) stored by 'carbondata'

LOAD DATA LOCAL INPATH '' INTO table employee options('BAD_RECORDS_ACTION'='REDIRECT')
Data:

Name,age,Project
Sam,27,Carbon
Ruhi,23x,Hadoop

The second record is bad record so it will be writtern to the csv file at the bad record loation.

Expected:

Ruhi,23x,Hadoop

This closes #1116
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","e40b34b08210981cbe3bffe73cacff2577fbd8cb","27","12","1","5465","660","121","5424","192","8922","1531","299","28","48","6602","0","67","46","526","apache-carbondata","e40b34b08210981cbe3bffe73cacff2577fbd8cb","625","16.5","156","89120","51312","11801","5","1826","185","2373","20.5","4030","73","4.6","5","283","2583","22836","27","905","4119","54","3085","121","59","21430","1.4","388","575","1"
"apache-carbondata","1f54c47282bc201f2071bc8c9cc1be19baf0c9a1","2017-12-27 09:39:58","[CARBONDATA-1946] Exception thrown after alter data type change operation on dictionary exclude integer type column

Problem: After restructure change data type operation (INT to BIGINT) on dictionary exclude INT type column if select query is triggered then exception is thrown.

Analysis: This is happening because while retrieving the data the vector is created for BIGINT type (size 8 bytes) which but the actual length of each data is 4 bytes and there is length check while reading the data which is failing.

Solution: Added a new restructuredType variable in vector and assigned the block dimension data type to it.

This closes #1732
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","1f54c47282bc201f2071bc8c9cc1be19baf0c9a1","27","12","1","5463","660","121","5424","192","8920","1529","295","28","48","6602","0","67","46","526","apache-carbondata","1f54c47282bc201f2071bc8c9cc1be19baf0c9a1","625","16.5","156","89108","51306","11801","5","1826","185","2373","20.5","4030","73","4.6","5","282","2582","22835","27","875","4119","53","3085","121","59","21430","1.4","388","575","1"
"apache-carbondata","38038add7065a05957f84d884298c901253f3d4d","2017-12-28 04:42:37","[CARBONDATA-1955] Delta DataType calculation is incorrect for long type

Problem:
In case of Long type, the delta data type is always choosing the Long type.
But it should choose the datatype based on diff (max-min) of max and min values.
Solution:
Corrected to choose the delta data type based on max and min values.

This closes #1744
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","38038add7065a05957f84d884298c901253f3d4d","27","12","1","5456","660","121","5422","192","8915","1529","295","28","48","6596","0","67","46","526","apache-carbondata","38038add7065a05957f84d884298c901253f3d4d","625","16.4","156","89054","51277","11797","5","1826","185","2373","20.5","4027","73","4.6","5","282","2582","22826","27","875","4119","53","3085","121","59","21430","1.4","388","575","1"
"apache-carbondata","aee5213b8a6f137e14d1b902c523f836224a1953","2018-01-03 01:51:37","[CARBONDATA-1979] ][IMPLICIT COLUMN] Modified implicit column filtering logic to directly validate the blocklet ID

As BlockletDataMap directly identified the blocklets after pruning, implict column filter should validate directly for blocklet id instead of block Id

This closes #1760
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","aee5213b8a6f137e14d1b902c523f836224a1953","27","12","1","5456","660","121","5422","192","8914","1529","295","28","48","6596","0","67","46","526","apache-carbondata","aee5213b8a6f137e14d1b902c523f836224a1953","625","16.4","156","89049","51273","11796","5","1826","185","2374","20.5","4027","73","4.6","5","282","2583","22823","27","875","4119","53","3085","121","60","21430","1.4","388","575","1"
"apache-carbondata","d7852abeaa8915055bbad92e250662320b090bbc","2018-01-02 04:56:15","[CARBONDATA-1967][PARTITION] Fix autocompaction and auto merge index in partition tables

Auto compaction is not working in case of the partition table and merge index files are merging always even though it is configured as false.

Solution:
Auto compaction code is added after finishing of partition loading. And also merge index configuration is checked before going for index merging.

This closes #1748
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","d7852abeaa8915055bbad92e250662320b090bbc","27","12","1","5458","660","121","5424","192","8914","1529","295","28","48","6600","0","67","46","526","apache-carbondata","d7852abeaa8915055bbad92e250662320b090bbc","625","16.4","156","89072","51294","11801","5","1827","185","2375","20.5","4029","73","4.6","5","282","2584","22834","27","875","4119","53","3085","121","60","21445","1.4","388","575","1"
"apache-carbondata","910d496cf2a668dc10b40c202889003fe5cfb556","2018-01-03 00:14:54","[CARBONDATA-1903] Remove unused FileUtil and Optimize code

This closes #1678
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","910d496cf2a668dc10b40c202889003fe5cfb556","27","12","1","5458","660","121","5424","192","8912","1529","295","28","48","6599","0","67","46","526","apache-carbondata","910d496cf2a668dc10b40c202889003fe5cfb556","625","16.4","156","89061","51287","11798","5","1827","185","2375","20.5","4028","73","4.6","5","282","2584","22830","27","875","4119","53","3085","121","60","21445","1.4","388","575","1"
"apache-carbondata","3b6f26c696f34805b72719cdb40fce4efed33a12","2017-12-19 21:28:23","[CARBONDATA-1916]Correct the database location path during carbon drop database

Correct the database location path during carbon drop database, when drop database is called, to delete the databsae directory, the path formed is wrong, so when drop datasbe is executed, operation is successful , but the database directory is still present in hdfs.

This closes #1688
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","3b6f26c696f34805b72719cdb40fce4efed33a12","27","12","1","5458","660","121","5428","196","8923","1531","295","28","48","6615","0","67","46","526","apache-carbondata","3b6f26c696f34805b72719cdb40fce4efed33a12","625","16.4","156","89098","51322","11810","5","1828","185","2382","20.5","4028","73","4.6","5","283","2592","22857","28","905","4125","54","3085","121","60","21495","1.4","393","575","1"
"apache-carbondata","a51ad30f6647387de818dbeb2c3c39cbac2a8416","2017-12-28 02:43:43","[CARBONDATA-1904][CARBONDATA-1905] Support auto handoff and close streaming

Add support for:
1. auto handoff streaming segment
2. alter streaming table to normal table by syntax: alter table compact 'close_streaming'

This closes #1736
","refs/heads/master","qiangcai@qq.com","apache-carbondata","a51ad30f6647387de818dbeb2c3c39cbac2a8416","27","12","1","5447","659","120","5424","195","8901","1530","295","28","48","6604","0","67","46","526","apache-carbondata","a51ad30f6647387de818dbeb2c3c39cbac2a8416","624","16.4","157","88883","51197","11768","5","1824","187","2378","20.5","4018","75","4.7","5","284","2589","22801","28","905","4151","54","3105","121","60","21474","1.4","393","574","1"
"apache-carbondata","7f3c374bacdf54c9eac91a908701e3ea8dd369e0","2017-12-27 09:02:46","[CARBONDATA-1937][PARTITION] Fix partition fetch fail if null partition value present in integral columns

It seems like an issue in hive while querying partitions from metastore if any integral partition column contains a null value.

Now alternatively we get the full list of partitions from hive and then apply a filter to it.

This closes #1730
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7f3c374bacdf54c9eac91a908701e3ea8dd369e0","27","12","1","5445","659","120","5416","195","8898","1529","295","28","48","6602","0","67","46","526","apache-carbondata","7f3c374bacdf54c9eac91a908701e3ea8dd369e0","624","16.4","157","88855","51176","11765","5","1823","187","2377","20.5","4016","75","4.7","5","284","2588","22793","28","905","4151","54","3105","121","60","21462","1.4","393","574","1"
"apache-carbondata","03ddcc85db37cba37aedd3feb2f99f43d14b0c8a","2017-12-22 05:07:20","[CARBONDATA-1935]fix the backword compatibility issue for tableInfo deserialization

This closes #1720
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","03ddcc85db37cba37aedd3feb2f99f43d14b0c8a","27","12","1","5443","659","120","5412","195","8898","1528","295","28","48","6602","0","67","46","526","apache-carbondata","03ddcc85db37cba37aedd3feb2f99f43d14b0c8a","624","16.4","157","88846","51172","11765","5","1823","187","2377","20.5","4016","75","4.7","5","284","2588","22793","28","905","4151","54","3105","121","60","21462","1.4","393","574","1"
"apache-carbondata","adb8c1356d0b753ecefe132cf5193ea3f2f92dea","2017-12-20 02:16:02","[CARBONDATA-1925][Pre-Aggregate]Added code to support case expression

Added code to support expression inside aggregation function for pre-aggregate table

This closes #1694
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","adb8c1356d0b753ecefe132cf5193ea3f2f92dea","27","12","1","5437","656","120","5408","194","8893","1526","295","28","48","6571","0","67","46","526","apache-carbondata","adb8c1356d0b753ecefe132cf5193ea3f2f92dea","623","16.4","156","88745","51112","11728","5","1821","187","2374","20.5","4013","75","4.7","5","282","2583","22756","28","895","4151","53","3085","121","60","21423","1.4","392","573","1"
"apache-carbondata","0c8fa5908afd153e28d08009ca53241dbd1a506a","2017-12-13 23:24:08","[CARBONDATA-1731,CARBONDATA-1728] Update,Delete fails incorrectly with error

[QueryExecution] Fetch BlockletId in Executor. Currently the blockletId are not propagated to the excutrs properly. Due to this reason the Implicit columns i.e. tupleId formed in executers can wrongly form duplicate tupleId. For e.g. a Block having two blocklets i.e. 0 and 1, in executors each tasks picks each blocklets. As the ID is not propagated each executor will term the Blocklets as ID 0. Solution is to propagate the Blocklet IDs to the executor from driver

This closes #1719
","refs/heads/master","anubhav.tarar@knoldus.in","apache-carbondata","0c8fa5908afd153e28d08009ca53241dbd1a506a","27","12","1","5437","656","120","5408","194","8893","1526","295","28","48","6571","0","67","46","526","apache-carbondata","0c8fa5908afd153e28d08009ca53241dbd1a506a","623","16.4","156","88741","51110","11727","5","1820","187","2373","20.5","4013","75","4.7","5","282","2582","22755","28","895","4151","53","3085","121","60","21412","1.4","392","573","1"
"apache-carbondata","f635106a7c8af4a4ae2f1899d4a26ccbd43958d1","2017-12-22 02:35:31","[CARBONDATA-1934] Incorrect results are returned by select query in case when the number of blocklets for one part file are > 1 in the same task

Problem: When a select query is triggered, driver will prune the segments and give a list of blocklets that need to be scanned. The number of tasks from spark will be equal to the number of blocklets identified.
In case where one task has more than one blocklet for same file, then BlockExecution getting formed is incorrect. Due to this the query results are incorrect.

Fix: Use the abstract index to fill all the details in BlockExecutionInfo

This closes #1715
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","f635106a7c8af4a4ae2f1899d4a26ccbd43958d1","27","12","1","5428","655","120","5406","194","8881","1525","295","28","48","6565","0","67","46","526","apache-carbondata","f635106a7c8af4a4ae2f1899d4a26ccbd43958d1","623","16.4","156","88666","51068","11721","5","1819","187","2372","20.5","4007","75","4.7","5","282","2581","22740","28","895","4151","53","3085","121","60","21390","1.4","392","573","1"
"apache-carbondata","7dcc2e75572b4a88cdef246d3b3a0770fb73b8d2","2017-12-20 08:43:10","[CARBONDATA-1928] Seperate the properties for timeout and retries for load flow

Currently the property that is used to configure the lock retry count and the interval between retries is common for all the locks. This will be problematic when the user has configured the retries to 10/20 for concurrent loading. This property will be affecting other lock behaviours also, all other locks would have to retry for 10 times too.

1. Change the name of the ""carbon.load.metadata.lock.retries"" property to ""carbon.concurrent.lock.retries"" AND ""carbon.concurrent.lock.retry.timeout.sec""

2. Introduce a new property for all other locks ""carbon.lock.retries"" AND ""carbon.lock.retry.timeout.sec""

This closes #1708
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","7dcc2e75572b4a88cdef246d3b3a0770fb73b8d2","27","12","1","5427","655","120","5406","194","8879","1525","295","28","48","6569","0","67","46","526","apache-carbondata","7dcc2e75572b4a88cdef246d3b3a0770fb73b8d2","623","16.4","156","88660","51063","11721","5","1819","187","2372","20.5","4007","75","4.7","5","282","2581","22737","28","895","4151","53","3085","121","60","21390","1.4","392","573","1"
"apache-carbondata","1381c9f19508f68f95953c48126e27ca239818d1","2017-12-21 23:53:11","[CARBONDATA-1930] Added condition to refer to parent dictionary if filter is given in aggregate table query

When filter is applied to aggregate query then the query is not accessing the parent table dictionary instead it is trying to search for aggregate table dictionary files.Add check to access parent table dictionary files if aggregate column has parent columns.

This closes #1710
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","1381c9f19508f68f95953c48126e27ca239818d1","27","12","1","5422","655","120","5398","194","8875","1523","295","28","48","6567","0","67","46","526","apache-carbondata","1381c9f19508f68f95953c48126e27ca239818d1","623","16.4","156","88603","51040","11716","5","1819","187","2372","20.4","4004","75","4.7","5","282","2581","22731","28","895","4151","53","3085","121","60","21390","1.4","392","573","1"
"apache-carbondata","f79b9ea321ce0c9cb12214e0555f9425f5438c5a","2017-12-19 19:46:22","[CARBONDATA-1914][Dictionary Cache] Cache Access Rectification.

This closes #1686
","refs/heads/master","sounakr@gmail.com","apache-carbondata","f79b9ea321ce0c9cb12214e0555f9425f5438c5a","27","12","1","5422","655","120","5398","194","8876","1521","295","28","48","6559","0","67","46","526","apache-carbondata","f79b9ea321ce0c9cb12214e0555f9425f5438c5a","623","16.4","156","88589","51026","11714","5","1817","187","2370","20.4","4004","75","4.7","5","282","2579","22726","28","895","4151","53","3085","121","60","21380","1.4","392","573","1"
"apache-carbondata","9659edccbd05e9f5499911e6d049d9b9e1cf8c3a","2017-12-20 20:53:27","[CARBONDATA-1863][PARTITION] Supported clean files for partition table.

This closes #1706
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9659edccbd05e9f5499911e6d049d9b9e1cf8c3a","27","12","1","5422","655","120","5398","194","8876","1521","295","28","48","6559","0","67","46","526","apache-carbondata","9659edccbd05e9f5499911e6d049d9b9e1cf8c3a","623","16.4","156","88558","51010","11707","5","1817","187","2370","20.4","4001","75","4.7","5","282","2579","22718","28","895","4151","53","3085","121","60","21380","1.4","392","573","1"
"apache-carbondata","f1c6dddec8d7057dfc1a1f70555faec4c6184a52","2017-12-15 03:53:41","[CARBONDATA-1698]Adding support for table level compaction configuration

Adding support for table level compaction configuration

This closes #1575
","refs/heads/master","xaprice@yeah.net","apache-carbondata","f1c6dddec8d7057dfc1a1f70555faec4c6184a52","26","12","1","5420","648","120","5386","194","8840","1515","295","28","48","6523","0","67","46","526","apache-carbondata","f1c6dddec8d7057dfc1a1f70555faec4c6184a52","623","16.4","156","88422","50911","11679","5","1809","187","2362","20.4","3998","75","4.7","5","282","2571","22662","28","895","4151","53","3085","121","60","21313","1.4","392","573","1"
"apache-carbondata","425f820bded52998e2da3bc8712a52a1544e7138","2017-07-03 03:18:40","[CARBONDATA-1258] CarbonData should not allow loading Date Type values violating the boundary condition (""0001-01-01"" through ""9999-12-31"")

Spark date type, supporting ""0001-01-01"" through ""9999-12-31"". As carbon pushes the data to spark layer so can support beyond this range.

This closes #1126
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","425f820bded52998e2da3bc8712a52a1544e7138","26","12","1","5415","648","120","5376","194","8840","1515","295","28","48","6523","0","67","46","526","apache-carbondata","425f820bded52998e2da3bc8712a52a1544e7138","623","16.4","156","88410","50904","11679","5","1809","187","2362","20.4","3998","75","4.7","5","282","2571","22662","28","895","4151","53","3085","121","60","21313","1.4","392","573","1"
"apache-carbondata","47aafabb3bc2f64d828ed129746a5aea1bb5454c","2017-12-18 23:49:15","[CARBONDATA-1860][PARTITION] Support insertoverwrite for a specific partition

This closes #1700
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","47aafabb3bc2f64d828ed129746a5aea1bb5454c","26","10","1","5415","648","120","5374","194","8839","1514","295","28","48","6523","0","67","46","526","apache-carbondata","47aafabb3bc2f64d828ed129746a5aea1bb5454c","623","16.4","156","88382","50883","11674","5","1809","187","2362","20.4","3998","75","4.7","5","282","2571","22649","28","895","4151","53","3085","121","60","21313","1.4","392","573","1"
"apache-carbondata","5ed39de193c0a589c30fbbd01e19e85715f2cac0","2017-12-16 21:39:34","[CARBONDATA-1862][PARTITION] Support compaction for partition table

It supports compaction on partition table.
There is a change in compaction during the block identification and grouping. As all blocks which are related same partition always needs to group to same set for compaction.So compactor needs to get the partition information from partition map file during compaction of partition table

This closes #1675
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","5ed39de193c0a589c30fbbd01e19e85715f2cac0","27","10","1","5416","654","120","5374","194","8843","1516","295","28","48","6527","0","67","46","526","apache-carbondata","5ed39de193c0a589c30fbbd01e19e85715f2cac0","623","16.4","156","88401","50900","11682","5","1812","187","2365","20.4","3998","75","4.7","5","282","2574","22661","28","895","4151","53","3085","121","60","21339","1.4","392","573","1"
"apache-carbondata","3ff55a2eef1e2bc0e61ee909b62d485e5240243a","2017-12-16 09:08:00","[CARBONDATA-1859][CARBONDATA-1861][PARTITION] Support show and drop partitions

This closes #1674
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","3ff55a2eef1e2bc0e61ee909b62d485e5240243a","27","10","1","5415","654","120","5374","194","8843","1516","295","28","48","6526","0","67","46","526","apache-carbondata","3ff55a2eef1e2bc0e61ee909b62d485e5240243a","623","16.4","156","88396","50896","11681","5","1812","187","2365","20.4","3998","75","4.7","5","282","2574","22660","28","895","4151","53","3085","121","60","21339","1.4","392","573","1"
"apache-carbondata","a86c54b3e83fef0b45ed70c50ee7483f5cc0894c","2017-12-19 03:57:30","[CARBONDATA-1907] Avoid unnecessary logging to improve query performance for no dictionary non string columns

Changes done to return null in case of no dictionary column for non string data types when data is empty.This is done to avoid excessive logging which is impacting the query performance.

This closes #1679
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","a86c54b3e83fef0b45ed70c50ee7483f5cc0894c","26","10","1","5404","645","120","5364","194","8824","1509","295","28","48","6510","0","67","46","526","apache-carbondata","a86c54b3e83fef0b45ed70c50ee7483f5cc0894c","623","16.4","156","88275","50817","11658","5","1803","187","2356","20.3","3996","75","4.7","5","282","2565","22614","28","895","4151","53","3085","121","60","21247","1.4","392","573","1"
"apache-carbondata","694ee774cb8ca55ee24cd906368c3cf9cc96b0eb","2017-12-15 06:02:28","[CARBONDATA-1880] Combine input small files for GLOBAL_SORT

Combine input small files for GLOBAL_SORT to avoid carbon small file issue

This closes #1669
","refs/heads/master","qiangcai@qq.com","apache-carbondata","694ee774cb8ca55ee24cd906368c3cf9cc96b0eb","26","10","1","5403","643","120","5364","194","8823","1509","295","28","48","6511","0","67","46","526","apache-carbondata","694ee774cb8ca55ee24cd906368c3cf9cc96b0eb","623","16.4","156","88254","50808","11651","5","1803","187","2356","20.3","3995","75","4.7","5","283","2566","22608","28","910","4151","54","3085","121","60","21239","1.4","392","573","1"
"apache-carbondata","28c94183bf5e03f6af05a270b96c30529233332d","2017-12-12 01:19:27","[CARBONDATA-1854] add support for implicit column filter

This closes #1644
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","28c94183bf5e03f6af05a270b96c30529233332d","26","10","1","5401","643","120","5356","194","8821","1508","295","28","48","6511","0","67","46","526","apache-carbondata","28c94183bf5e03f6af05a270b96c30529233332d","623","16.4","156","88236","50792","11649","5","1803","187","2356","20.3","3994","75","4.7","5","283","2566","22602","28","910","4151","54","3085","121","60","21235","1.4","392","573","1"
"apache-carbondata","b8a02f391d9ff543abb54c7b58733cf9a4d7beaf","2017-12-18 09:07:59","[CARBONDATA-1858][PARTITION] Support querying data from partition table.

In case of partition table first, use sessioncatalog to prune the partitions. With the partition information, datamap should read partition.map file to get the index file and corresponding blocklets to prune

This closes #1672
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b8a02f391d9ff543abb54c7b58733cf9a4d7beaf","26","10","1","5401","643","120","5356","194","8820","1507","295","28","48","6503","0","67","46","526","apache-carbondata","b8a02f391d9ff543abb54c7b58733cf9a4d7beaf","623","16.4","156","88225","50783","11646","5","1803","187","2356","20.3","3994","75","4.7","5","283","2566","22598","28","910","4151","54","3085","121","60","21232","1.4","392","573","1"
"apache-carbondata","804ddb76fc32eee8a5ab79d8bdd4ede7c64560a1","2017-12-15 01:04:18","[CARBONDATA-1900][Core,processing] Modify loadmetadata to store timestamp long value(in ms) instead of formatted date string for fields ""loadStartTime"" and ""timestamp""

If the table is moved to environment having different timezone or we change the system current timezone, after IUD operation some of the blocks are not treated as valid blocks.

We should stop writing the loadStartTime and timestamp in dd-MM-yyyy HH:mm:ss:SSS format. We should write the long value of the timestamp

This closes #1666
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","804ddb76fc32eee8a5ab79d8bdd4ede7c64560a1","26","10","1","5394","645","120","5348","194","8793","1502","295","28","48","6493","0","67","46","526","apache-carbondata","804ddb76fc32eee8a5ab79d8bdd4ede7c64560a1","623","16.4","156","88119","50696","11618","5","1800","187","2351","20.3","3987","75","4.7","5","283","2561","22550","28","910","4151","54","3085","121","58","21230","1.4","392","573","1"
"apache-carbondata","54eedfe625c59dce869148bdcb77384602733e7b","2017-12-12 09:32:20","[CARBONDATA-1888][PreAggregate][Bug]Fixed compaction issue in case of timeseries

Problem:Compaction is failing in case of timeseries.
Solution: This is failing because in column schema timeseries function is added as aggregate function

This closes #1648
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","54eedfe625c59dce869148bdcb77384602733e7b","26","12","1","5376","645","120","5348","194","8795","1503","295","28","48","6493","0","67","46","526","apache-carbondata","54eedfe625c59dce869148bdcb77384602733e7b","623","16.4","156","88089","50690","11616","5","1800","187","2351","20.3","3989","75","4.7","5","283","2561","22549","28","910","4151","54","3085","121","58","21230","1.4","392","573","1"
"apache-carbondata","4430178c0f66f735f5d35ec733b0479d63b15fcb","2017-12-16 22:14:36","[CARBONDATA-1856][PARTITION] Support insert/load data for partition table

Changed carbonrelation to HadoopFSRelation during load in case of the partition table.
Implement sparks Fileformat interface for carbon and use carbonoutputformat inside.
Create partition.map file inside each segment for mapping between partition and index file.

This closes #1654
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","4430178c0f66f735f5d35ec733b0479d63b15fcb","26","12","1","5377","645","120","5350","194","8796","1500","295","28","48","6502","0","67","46","526","apache-carbondata","4430178c0f66f735f5d35ec733b0479d63b15fcb","623","16.4","156","88101","50701","11616","5","1800","187","2351","20.3","3989","75","4.7","5","283","2561","22551","28","910","4151","54","3085","121","58","21230","1.4","392","573","1"
"apache-carbondata","4daf0634e6338c627b01188a96b6d5c539308863","2017-07-06 08:18:54","[CARBONDATA-1288][DictionarySecureServer] Dictionary Secure Server Implementation.
During single pass load Dictionary key creation is done through driver and executor communication through external ports.
The communication will happen through TCP communication which is not secure or encrypted by default.
But in case spark turn on Security parameters then carbon dictionary ports will also follows same authentication and encryption
i.e. communicate through SASL Authentication protocol and Digest-MD5 encryption.
This PR makes the dictionary server and client communication Secure and encrypted.
In case spark turn ON security and authentication through the below parameters then Carbon communication also becomes secure.
By default the communication is still non secure.

Parameters to set in spark-default.conf in order to Turn ON Secure Mode Dictionary Server Communication.
spark.authenticate true
spark.authenticate.enableSaslEncryption true
spark.authenticate.secret

Note- Turning ON this flag will turn on authentication and encryption in spark too.

This Closes #1662
","refs/heads/master","sounak.chakraborty@huawei.com","apache-carbondata","4daf0634e6338c627b01188a96b6d5c539308863","26","12","1","5369","643","120","5350","194","8778","1499","295","28","48","6503","0","67","46","526","apache-carbondata","4daf0634e6338c627b01188a96b6d5c539308863","621","16.4","156","87962","50601","11594","5","1793","187","2345","20.3","3986","75","4.7","5","281","2554","22508","28","880","4151","53","3085","121","58","21159","1.4","394","572","1"
"apache-carbondata","91e6f6f43b915b7ddc52f36233526aa2f5a77782","2017-12-04 02:37:03","[CARBONDATA-1855][PARTITION] Added outputformat to carbon

Support standard Hadoop outputformat interface for carbon. This PR supports table level output format: CarbonTableOutputFormat, It will be helpful for integrations to execution engines like the spark, hive, and presto.
It should maintain segment management as well while writing the data to support incremental loading feature.

This closes #1642
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","91e6f6f43b915b7ddc52f36233526aa2f5a77782","26","12","1","5328","637","120","5334","189","8756","1490","295","28","45","6487","0","67","31","526","apache-carbondata","91e6f6f43b915b7ddc52f36233526aa2f5a77782","615","16.4","154","87640","50449","11571","5","1781","185","2330","20.4","3967","74","4.7","5","277","2537","22453","28","880","4123","53","3045","120","58","21002","1.4","393","566","1"
"apache-carbondata","40c7e8ee89e4fb136752c33662e2798691f29f5a","2017-12-15 19:34:07","Remove unnecessary mdk computation code

Remove unnecessary mdk computation code

This closes #1673
","refs/heads/master","kevinjmh@qq.com","apache-carbondata","40c7e8ee89e4fb136752c33662e2798691f29f5a","26","12","1","5329","637","120","5336","189","8761","1490","295","28","45","6493","0","67","31","528","apache-carbondata","40c7e8ee89e4fb136752c33662e2798691f29f5a","615","16.4","154","87655","50460","11572","5","1782","185","2331","20.4","3968","74","4.7","5","277","2538","22457","28","880","4123","53","3045","120","58","21003","1.4","393","566","1"
"apache-carbondata","eb7cf54ef352acf7c58372beddbedeb9698c48e6","2017-12-13 03:24:49","[CARBONDATA-1893] Data load with multiple QUOTECHAR characters in syntax should fail

During data load operation if quote character provided by user has lenght greater than 1, then data load should fail

This closes #1653
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","eb7cf54ef352acf7c58372beddbedeb9698c48e6","26","12","1","5330","637","120","5336","189","8762","1491","291","28","45","6493","0","67","31","528","apache-carbondata","eb7cf54ef352acf7c58372beddbedeb9698c48e6","615","16.4","154","87659","50464","11572","5","1783","185","2332","20.4","3968","74","4.7","5","277","2539","22458","28","880","4123","53","3045","120","58","21008","1.4","393","566","1"
"apache-carbondata","d504e067d15013a91dd6192a46688b8b93f2e204","2017-12-07 20:03:09","[CARBONDATA-1878] [DataMap] Fix bugs in unsafe datamap store

This closes #1633
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","d504e067d15013a91dd6192a46688b8b93f2e204","26","12","1","5326","637","120","5336","189","8760","1491","291","28","45","6492","0","67","31","528","apache-carbondata","d504e067d15013a91dd6192a46688b8b93f2e204","614","16.4","154","87610","50448","11569","5","1783","185","2332","20.5","3965","74","4.7","5","277","2539","22454","28","880","4123","53","3045","119","58","21008","1.4","393","565","1"
"apache-carbondata","6026680a13c0245fe2140b2fa7af67f1baf639d7","2017-12-10 05:01:56","[CARBONDATA-1879][Streaming] Support alter table to change the status of the streaming segment

Support new SQL command to change the status of the segment from 'streaming' to 'streaming finish': Alter table <dbname.tablename> finish streaming

This closes #1638
","refs/heads/master","qiangcai@qq.com","apache-carbondata","6026680a13c0245fe2140b2fa7af67f1baf639d7","26","12","1","5326","637","120","5336","189","8760","1491","291","28","45","6492","0","67","31","528","apache-carbondata","6026680a13c0245fe2140b2fa7af67f1baf639d7","614","16.4","154","87609","50447","11569","5","1783","185","2332","20.5","3965","74","4.7","5","277","2539","22454","28","880","4123","53","3045","119","58","21008","1.4","393","565","1"
"apache-carbondata","e5e74fc90855be7738b16573d6803411146baddf","2017-11-14 02:05:44","[CARBONDATA-1779] GenericVectorizedReader

This PR removes the Spark Dependency from Presto Integration Module for using the CarbonVectorizedRecordreader, This PR consolidate CarbonVectorizedRecordReader into one,to make it shared for all integration modules.In the earlier version of Presto Integration we were using ColumnarBatch of Spark, which is not a good practice, here we provided our own implementation of the ColumnVector and the VectorBatch to eliminate the Spark all together. This generic ColumnVector can now be used for all the integration module wherever we want to have a VectorizedReader to speed up the processing. There are some core module classes changed to ensure that we are using Java data types instead of Spark datatypes, Decimal being one of them.

This closes #1581
","refs/heads/master","bhavya@knoldus.com","apache-carbondata","e5e74fc90855be7738b16573d6803411146baddf","26","12","1","5326","637","120","5336","189","8760","1491","291","28","45","6492","0","67","31","528","apache-carbondata","e5e74fc90855be7738b16573d6803411146baddf","614","16.4","154","87609","50447","11569","5","1783","185","2332","20.5","3965","74","4.7","5","277","2539","22454","28","880","4123","53","3045","119","58","21008","1.4","393","565","1"
"apache-carbondata","6a185b8341f6f36f21b325c961a0a33ab17b15aa","2017-12-07 15:06:55","[CARBONDATA-1876] Clean all the InProgress segments for all databases during session initialization

Clean all the InProgress segments for all databases during session initialization. when carbon session initialize, clean all the in progress segments for all the databases created by user.

This closes #1637
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","6a185b8341f6f36f21b325c961a0a33ab17b15aa","26","12","1","5286","628","120","5334","189","8711","1485","291","28","45","6490","0","68","31","526","apache-carbondata","6a185b8341f6f36f21b325c961a0a33ab17b15aa","613","16.4","154","87373","50286","11492","5","1778","185","2327","20.4","3940","74","4.7","5","277","2534","22368","28","880","4123","53","3045","118","58","20955","1.4","393","564","1"
"apache-carbondata","34cb55194c2061efe54acaf4cea67d5b6179034c","2017-12-05 06:18:38","[CARBONDATA-1851] Refactor to use only SegmentsToAccess for Aggregatetable, move tableFolderDeletion to TableProcessingOperations

This closes #1616
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","34cb55194c2061efe54acaf4cea67d5b6179034c","26","12","1","5286","628","120","5334","189","8711","1485","291","28","45","6490","0","68","31","526","apache-carbondata","34cb55194c2061efe54acaf4cea67d5b6179034c","613","16.4","154","87373","50286","11492","5","1778","185","2327","20.4","3940","74","4.7","5","277","2534","22368","28","880","4123","53","3045","118","58","20957","1.4","393","564","1"
"apache-carbondata","3c5d10f399acdd42a563f40c9c153548ee2913f8","2017-12-06 05:43:27","[CARBONDATA-1869] Null pointer exception thrown when concurrent load and select queries executed for table with dictionary exclude or NO_INVERTED_INDEX

While updating the file, we need FileStatus, this FileStatus can be null. So before accessing FileStatus, a null check is needed.

This closes #1625
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","3c5d10f399acdd42a563f40c9c153548ee2913f8","26","12","1","5286","628","121","5332","189","8714","1484","291","28","45","6490","0","68","31","526","apache-carbondata","3c5d10f399acdd42a563f40c9c153548ee2913f8","613","16.4","154","87356","50282","11490","5","1778","185","2327","20.4","3938","74","4.7","5","277","2534","22366","28","880","4123","53","3045","118","58","20959","1.4","393","564","1"
"apache-carbondata","e2a79eebbcbe641f657e84ccf86a9a7e84e8e735","2017-12-05 07:26:58","[CARBONDATA-1519][PreAgg-Timeseries] Support Query and Load on timeseries table

This closes #1626
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","e2a79eebbcbe641f657e84ccf86a9a7e84e8e735","26","12","1","5286","628","121","5332","189","8714","1484","291","28","45","6490","0","68","31","526","apache-carbondata","e2a79eebbcbe641f657e84ccf86a9a7e84e8e735","613","16.4","154","87348","50274","11487","5","1778","185","2327","20.4","3938","74","4.7","5","277","2534","22361","28","880","4123","53","3045","118","58","20959","1.4","393","564","1"
"apache-carbondata","29dc30280d37e39306006c288546206db06d1bf4","2017-12-05 07:09:43","[CARBONDATA-1870] Add dictionary path support to carbondata

This closes #1617
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","29dc30280d37e39306006c288546206db06d1bf4","26","12","1","5278","627","121","5310","189","8686","1477","291","28","45","6460","0","68","31","524","apache-carbondata","29dc30280d37e39306006c288546206db06d1bf4","613","16.4","154","87136","50142","11440","5","1774","185","2321","20.3","3931","74","4.7","5","277","2528","22297","28","880","4123","53","3045","118","56","20923","1.4","393","564","1"
"apache-carbondata","99ec112f2e2285d2afb1fd1bcbe4682c3cac9979","2017-12-04 07:06:15","[CARBONDATA-1789][CARBONDATA-1791]do not drop the table if the load, insert or insert overwrite is in progress

This closes #1610
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","99ec112f2e2285d2afb1fd1bcbe4682c3cac9979","26","12","1","5276","627","121","5302","189","8689","1478","291","31","45","6491","0","68","31","524","apache-carbondata","99ec112f2e2285d2afb1fd1bcbe4682c3cac9979","613","16.4","154","87109","50157","11429","5","1774","185","2324","20.3","3921","74","4.7","5","277","2531","22301","28","880","4123","53","3045","118","56","20926","1.4","396","564","1"
"apache-carbondata","30457c41511ed22c9980cfe575e3f277cc7b4c33","2017-11-23 06:32:14","[CARBONDATA-1822][Spark-Integration] Support DDL to register the CarbonData table from existing carbon table data

Problem:
Support DDL command to create the table from existing table data.
Solution:
Existing spark refresh table DDL command will be overridden in the carbon to support the register
carbon table with hivemetastore.
REFRESH TABLE .;

This closes #1583
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","30457c41511ed22c9980cfe575e3f277cc7b4c33","26","12","1","5275","627","121","5300","189","8684","1478","291","31","45","6490","0","68","31","524","apache-carbondata","30457c41511ed22c9980cfe575e3f277cc7b4c33","613","16.4","154","87086","50140","11424","5","1774","185","2324","20.3","3920","74","4.7","5","277","2531","22291","28","880","4123","53","3045","118","56","20926","1.4","396","564","1"
"apache-carbondata","2bad144a2f13bcdf5518490c8c08bad25d9ea84d","2017-12-06 03:41:51","[CARBONDATA-1867] Add support for task/segment level pruning

Added support for task/segment level pruning. Added code to compute task level min/max which can be helpful for task/segment level pruning

This closes #1624
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","2bad144a2f13bcdf5518490c8c08bad25d9ea84d","26","12","1","5275","627","121","5300","189","8685","1478","291","31","45","6490","0","68","31","524","apache-carbondata","2bad144a2f13bcdf5518490c8c08bad25d9ea84d","613","16.4","154","87078","50136","11423","5","1774","185","2324","20.3","3920","74","4.7","5","277","2531","22289","28","880","4123","53","3045","118","56","20926","1.4","396","564","1"
"apache-carbondata","49763b72bce8f38404e693b39bb440acb04e601f","2017-12-05 02:30:48","[CARBONDATA-1518][Pre-Aggregate]Support creating timeseries while creating main table.

This closes #1565
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","49763b72bce8f38404e693b39bb440acb04e601f","26","12","1","5268","627","121","5276","187","8654","1479","291","31","45","6476","0","68","31","524","apache-carbondata","49763b72bce8f38404e693b39bb440acb04e601f","613","16.4","153","86914","50017","11396","5","1773","185","2321","20.2","3912","74","4.7","5","276","2527","22224","28","880","4123","53","3025","118","56","20912","1.4","394","564","1"
"apache-carbondata","0bbfa8597a17ed90f081f6d3f78d62c8c4bcc1bd","2017-12-05 03:06:56","[CARBONDATA-1854] Add support for implicit column filter

Whenever a filter is applied on implicit column, filter is applied at blocklet level to scan/read only the valid blocklets. This will ensure that only blocklets that contain the required data are read.

This closes #1619
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","0bbfa8597a17ed90f081f6d3f78d62c8c4bcc1bd","26","12","1","5258","626","121","5262","187","8648","1476","291","31","45","6440","0","68","31","524","apache-carbondata","0bbfa8597a17ed90f081f6d3f78d62c8c4bcc1bd","611","16.4","153","86699","49890","11373","5","1771","185","2318","20.2","3907","74","4.8","5","276","2524","22161","28","880","4123","53","3025","118","56","20900","1.4","393","562","1"
"apache-carbondata","38b53fefbf0277595f758829b8010e542813783b","2017-12-04 04:31:18","[CARBONDATA-1761]do not change status of segment during delete segment by ID to marked for delete if it is In progress

Do not change status of segment to marked for delete if it is in progress

This closed #1608
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","38b53fefbf0277595f758829b8010e542813783b","26","12","1","5228","626","121","5242","187","8600","1470","289","31","45","6408","0","68","31","524","apache-carbondata","38b53fefbf0277595f758829b8010e542813783b","608","16.4","153","86280","49630","11317","5","1764","185","2310","20.2","3885","74","4.8","5","276","2516","22051","28","880","4123","53","3025","118","56","20794","1.4","392","559","1"
"apache-carbondata","4e315108763858781d0ef2c340e3343e9860b14a","2017-12-04 06:31:06","[CARBONDATA-1831] BAD_RECORDS: Data Loading with Action as Redirect & logger enable is not logging the logs in the defined path.

Current system expects the carbon.badRecords.location to be absolute path with filescheme.
But, it should support absolute path without file scheme(eg.: hdfs://, viewfs://)

This closes #1609
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","4e315108763858781d0ef2c340e3343e9860b14a","26","12","1","5228","626","121","5242","187","8600","1470","289","31","45","6406","0","68","31","524","apache-carbondata","4e315108763858781d0ef2c340e3343e9860b14a","608","16.4","153","86267","49619","11313","5","1761","185","2307","20.2","3885","74","4.8","5","276","2513","22043","28","880","4123","53","3025","118","56","20761","1.4","392","559","1"
"apache-carbondata","f70e6d7008cb5300581da4307ef55ec444999577","2017-11-20 03:06:11","[CARBONDATA-1740][Pre-Aggregate] Fixed order by issue in case of preAggregate

Problem: Order by query is failing in case of pre aggregate table.
Solution: In pre aggregate rules order by scenario is not handled. Handling the same in this pr

This closes #1544
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","f70e6d7008cb5300581da4307ef55ec444999577","26","12","1","5228","626","121","5242","187","8601","1468","289","31","45","6406","0","68","31","524","apache-carbondata","f70e6d7008cb5300581da4307ef55ec444999577","608","16.4","153","86265","49617","11313","5","1759","185","2305","20.2","3885","74","4.8","5","276","2511","22041","28","880","4123","53","3025","118","56","20751","1.4","392","559","1"
"apache-carbondata","5ae596b76f1c15bd78f992bec1c51ae76223f635","2017-11-16 04:28:50","[CARBONDATA-1738] [PreAgg] Block direct insert/load on pre-aggregate table

This closes #1508
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","5ae596b76f1c15bd78f992bec1c51ae76223f635","26","12","1","5226","626","121","5240","187","8599","1466","289","31","45","6405","0","68","31","524","apache-carbondata","5ae596b76f1c15bd78f992bec1c51ae76223f635","608","16.4","153","86240","49594","11297","5","1759","185","2305","20.2","3883","74","4.8","5","276","2511","22027","28","880","4123","53","3025","118","56","20751","1.4","392","559","1"
"apache-carbondata","2fe7758be1278548f9f321b1b0fc0305488a46cd","2017-12-02 21:42:20","[CARBONDATA-1844] Add tablePath support when creating table

User should be able to specify table path when creating table. This PR supports it.
The tablePath of the table is determined as following steps:

Use the table property 'table_path' specified by user
Use database 's locationUri if it is specified by user in create database command, and concatenate with table name as table path
Use carbon store path and database name and table name to construct a table path

This closes #1603
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","2fe7758be1278548f9f321b1b0fc0305488a46cd","26","12","1","5226","626","121","5238","187","8599","1466","289","31","45","6405","0","68","31","524","apache-carbondata","2fe7758be1278548f9f321b1b0fc0305488a46cd","608","16.4","153","86234","49593","11297","5","1759","185","2305","20.2","3883","74","4.8","5","276","2511","22027","28","880","4123","53","3025","118","56","20751","1.4","392","559","1"
"apache-carbondata","25c28242a81a33918e2bf4f84a3a93b1415c9c83","2017-12-02 06:46:56","[CARBONDATA-1843] Block CTAS and external table feature

This closes #1604
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","25c28242a81a33918e2bf4f84a3a93b1415c9c83","26","12","1","5232","626","121","5258","189","8612","1465","289","31","45","6418","0","68","32","524","apache-carbondata","25c28242a81a33918e2bf4f84a3a93b1415c9c83","608","16.4","155","86372","49656","11311","5","1760","185","2309","20.2","3884","74","4.8","5","278","2517","22052","28","880","4123","53","3065","118","56","20774","1.4","395","559","1"
"apache-carbondata","6ae1f1b61cd4ac21f94f40fd76cdfd78648d117f","2017-11-27 01:45:17","[CARBONDATA-1816][Bad Records] Changing BAD_RECORDS_ACTION default action to FAIL

Currently, the default action is FORCE, this may allow the user by default to load bad records also. So, changing the default action of BAD_RECORDS_ACTION to FAIL will alert the user if any bad_records are there in the loading data.

This closes #1574
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","6ae1f1b61cd4ac21f94f40fd76cdfd78648d117f","26","12","1","5232","626","121","5258","189","8612","1465","289","31","45","6418","0","68","32","524","apache-carbondata","6ae1f1b61cd4ac21f94f40fd76cdfd78648d117f","608","16.4","155","86371","49656","11311","5","1760","185","2309","20.2","3884","74","4.8","5","278","2517","22052","28","880","4123","53","3065","118","56","20774","1.4","395","559","1"
"apache-carbondata","40f06084a9969e5dd7e14055633efdba8ea2190d","2017-11-16 23:11:49","[CARBONDATA-1734] Ignore empty line while reading CSV
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","40f06084a9969e5dd7e14055633efdba8ea2190d","26","12","1","5161","623","121","5238","187","8479","1447","289","31","44","6410","0","68","32","524","apache-carbondata","40f06084a9969e5dd7e14055633efdba8ea2190d","606","16.5","154","85880","49349","11306","5","1723","185","2269","20.3","3819","72","4.8","5","275","2476","21927","28","880","4127","53","3045","118","56","20562","1.4","394","557","1"
"apache-carbondata","7250ff1141d49dfb68b3fc3a14d37369c9b04d5b","2017-11-24 02:09:09","[CARBONDATA-1592] Refactored CarbonSession

Description : Refactored common code to avoid duplication code in extended classes.

This closes #1563
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","7250ff1141d49dfb68b3fc3a14d37369c9b04d5b","26","12","1","5233","626","121","5258","189","8612","1465","289","31","45","6418","0","68","32","524","apache-carbondata","7250ff1141d49dfb68b3fc3a14d37369c9b04d5b","608","16.4","155","86367","49656","11311","5","1760","185","2309","20.2","3884","74","4.8","5","278","2517","22052","28","880","4123","53","3065","118","56","20774","1.4","395","559","1"
"apache-carbondata","06473484b6a824a7a4abc9c4f4e3ce86b62ac49b","2017-11-17 01:17:43","[CARBONDATA-1756] Improve Boolean data compress rate by changing RLE to SNAPPY algorithm

Improve Boolean data compress rate by changing RLE to SNAPPY algorithm
Because Boolean data compress rate that uses RLE algorithm is lower than SNAPPY algorithm in most scenario.

This PR only changed about 4 lines for compress algorithm, and we also add some test cases for testing Boolean data compress rate.

This closes #1523
","refs/heads/master","601450868@qq.com","apache-carbondata","06473484b6a824a7a4abc9c4f4e3ce86b62ac49b","26","12","1","5232","626","121","5256","189","8612","1465","289","31","45","6418","0","68","32","524","apache-carbondata","06473484b6a824a7a4abc9c4f4e3ce86b62ac49b","608","16.4","155","86365","49655","11311","5","1760","185","2309","20.2","3884","74","4.8","5","278","2517","22052","28","880","4123","53","3065","118","56","20774","1.4","395","559","1"
"apache-carbondata","33de599a56cdd767e5779123a4797178b3c40ae5","2017-11-23 23:10:36","[CARBONDATA-1804] Support Plug-gable File Operations based on File types

Refactor FileFactory based on FileType to support plug-gable file handlers so that custom file handlers can have their specific logic.
Example : User can provide his own implementations by extending existing FileTypes
Refactore FileFactory code : Moved File type opearation code into specific file types instead of checking file type every time in FileFactory. So that custom file operations can be performed on the specific file types by extending required File type

This closes #1560
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","33de599a56cdd767e5779123a4797178b3c40ae5","26","12","1","5232","626","121","5256","189","8612","1465","289","31","45","6417","0","68","32","524","apache-carbondata","33de599a56cdd767e5779123a4797178b3c40ae5","608","16.4","155","86366","49656","11312","5","1760","185","2309","20.2","3884","74","4.8","5","278","2517","22052","28","880","4123","53","3065","118","56","20776","1.4","395","559","1"
"apache-carbondata","9e0fd5ffe3dfad001a95ff592644a34c448d4843","2017-11-24 01:41:59","[CARBONDATA-1592] Added event listeners

Description : Added Event Listener interface to Carbondata. This will allow extending the current functionality of various commands to perform various other operations.

This closes #1562
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","9e0fd5ffe3dfad001a95ff592644a34c448d4843","26","12","1","5173","624","121","5248","188","8518","1446","289","31","44","6422","0","68","32","524","apache-carbondata","9e0fd5ffe3dfad001a95ff592644a34c448d4843","606","16.5","154","86102","49513","11342","5","1728","183","2276","20.4","3832","72","4.8","5","277","2483","22004","28","880","4097","53","3045","118","56","20599","1.4","394","557","1"
"apache-carbondata","7e124f4f1dfa8fec3db2271e0f3d6b4590b8e02c","2017-11-27 22:42:51","[CARBONDATA-1820] Extract CarbonTable.buildUniqueName method and re-factory code to invoke this method

Extract CarbonTable.buildUniqueName method and re-factory code to invoke this method

This closes #1579
","refs/heads/master","qiangcai@qq.com","apache-carbondata","7e124f4f1dfa8fec3db2271e0f3d6b4590b8e02c","26","12","1","5174","624","121","5248","188","8522","1447","289","31","44","6422","0","68","32","524","apache-carbondata","7e124f4f1dfa8fec3db2271e0f3d6b4590b8e02c","606","16.5","154","86108","49518","11343","5","1728","183","2276","20.4","3833","72","4.8","5","277","2483","22007","28","880","4097","53","3045","118","56","20599","1.4","394","557","1"
"apache-carbondata","0f407de8c95ac908a877c9830408c049da8705b9","2017-11-27 18:24:48","[CARBONDATA-1818] Make carbon.streaming.segment.max.size as configurable

Make carbon.streaming.segment.max.size as configurable

This closes #1577
","refs/heads/master","qiangcai@qq.com","apache-carbondata","0f407de8c95ac908a877c9830408c049da8705b9","26","12","1","5174","624","121","5248","188","8516","1447","289","31","44","6422","0","68","32","524","apache-carbondata","0f407de8c95ac908a877c9830408c049da8705b9","606","16.4","154","86075","49508","11340","5","1728","183","2276","20.4","3830","72","4.8","5","277","2483","22004","28","880","4097","53","3045","118","56","20599","1.4","394","557","1"
"apache-carbondata","e19ada792dbdc8b1083c423b0cee66fb8d5a91a4","2017-11-26 18:01:44","[CARBONDATA-1812] Provide API to get table dynamic information(table size and last modified time)

provide API to get table dynamic information(table size and last modified time)

This closes #1572
","refs/heads/master","qiangcai@qq.com","apache-carbondata","e19ada792dbdc8b1083c423b0cee66fb8d5a91a4","26","12","1","5173","624","121","5246","188","8510","1447","289","31","44","6419","0","68","32","524","apache-carbondata","e19ada792dbdc8b1083c423b0cee66fb8d5a91a4","606","16.4","154","86018","49466","11333","5","1728","183","2276","20.3","3828","72","4.8","5","277","2483","21988","28","880","4097","53","3045","118","56","20597","1.4","394","557","1"
"apache-carbondata","f8e0585d2c31b90e70ff2574e47c6434d61fcced","2017-11-24 09:54:41","[CARBONDATA-1586][Streaming] Support handoff from row format to columnar format

1.configuration
carbon.handoff.size =>carbon.streaming.segment.max.size
2.SQL command
alter table <table_name> compact 'streaming'
3.refactory CompactionType

This closes #1566
","refs/heads/master","qiangcai@qq.com","apache-carbondata","f8e0585d2c31b90e70ff2574e47c6434d61fcced","26","12","1","5172","623","121","5246","188","8509","1447","289","31","44","6417","0","68","32","524","apache-carbondata","f8e0585d2c31b90e70ff2574e47c6434d61fcced","606","16.4","154","86003","49452","11330","5","1728","183","2276","20.3","3827","72","4.8","5","277","2483","21980","28","880","4097","53","3045","118","56","20597","1.4","394","557","1"
"apache-carbondata","ab9c2c083c601232d1a3663a44dfe375eb079da5","2017-11-22 00:30:12","[SDV] Fix sdv error

This closes #1550
","refs/heads/master","qiangcai@qq.com","apache-carbondata","ab9c2c083c601232d1a3663a44dfe375eb079da5","26","12","1","5171","623","121","5244","188","8509","1447","289","31","44","6417","0","68","32","524","apache-carbondata","ab9c2c083c601232d1a3663a44dfe375eb079da5","606","16.4","154","86002","49451","11330","5","1728","183","2276","20.3","3827","72","4.8","5","277","2483","21980","28","880","4097","53","3045","118","56","20597","1.4","394","557","1"
"apache-carbondata","cb6c2717347a1f98f48afdfba2967afe21960c0a","2017-11-20 02:38:20","[CARBONDATA-1780] Create configuration from SparkSession for data loading

Create configuration from SparkSession for data loading, so that we can set configuration into SparkSession during dataloading.

This closes #1539
","refs/heads/master","qiangcai@qq.com","apache-carbondata","cb6c2717347a1f98f48afdfba2967afe21960c0a","26","12","1","5171","623","121","5244","188","8509","1447","289","31","44","6417","0","68","32","524","apache-carbondata","cb6c2717347a1f98f48afdfba2967afe21960c0a","606","16.4","154","86001","49450","11330","5","1728","183","2276","20.3","3827","72","4.8","5","277","2483","21979","28","880","4097","53","3045","118","56","20597","1.4","394","557","1"
"apache-carbondata","075809a81b49e2bb8d8bdf6293493d73dab21e74","2017-11-16 18:29:12","[CARBONDATA-1729]Fix the compatibility issue with hadoop <= 2.6 and 2.7
1.Recover profile of 'hadoop-2.2.0' to pom.xml
2.Use reflection mechanism to implement 'truncate' method

This closes #1516
","refs/heads/master","441586683@qq.com","apache-carbondata","075809a81b49e2bb8d8bdf6293493d73dab21e74","26","12","1","5163","623","121","5244","188","8492","1447","289","31","44","6416","0","68","32","524","apache-carbondata","075809a81b49e2bb8d8bdf6293493d73dab21e74","606","16.5","154","85938","49396","11313","5","1726","185","2274","20.3","3820","72","4.8","5","277","2481","21957","28","880","4127","53","3045","118","56","20591","1.4","394","557","1"
"apache-carbondata","26f5bb99080a57baa9205a8ca6f6abc27536a7d2","2017-11-10 05:10:55","[CARBONDATA-1700][DataLoad] Add TableProperties during (de)serialization of TableSchema

This closes #1484
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","26f5bb99080a57baa9205a8ca6f6abc27536a7d2","26","12","1","5161","623","121","5244","187","8490","1447","289","31","44","6416","0","68","32","524","apache-carbondata","26f5bb99080a57baa9205a8ca6f6abc27536a7d2","606","16.5","154","85917","49380","11311","5","1725","185","2271","20.3","3820","72","4.8","5","275","2478","21951","28","880","4127","53","3045","118","56","20564","1.4","394","557","1"
"apache-carbondata","c16d543818d8bfc16637b183f22b65c943a7672e","2017-11-19 22:27:59","[CARBONDATA-1746] Count star optimization

This closes #1514
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","c16d543818d8bfc16637b183f22b65c943a7672e","26","12","1","5161","623","121","5244","187","8486","1447","289","31","44","6416","0","68","32","524","apache-carbondata","c16d543818d8bfc16637b183f22b65c943a7672e","606","16.5","154","85902","49367","11309","5","1723","185","2269","20.3","3820","72","4.8","5","275","2476","21939","28","880","4127","53","3045","118","56","20562","1.4","394","557","1"
"apache-carbondata","85dc4fff0ecca160654085379310a1c3096731f7","2017-11-17 03:25:33","[CARBONDATA-1762] Remove existing column level dateformat and support dateformat, timestampformat in the load option

(1) Remove column level dateformat option
(2) Support dateformat and timestampformat in load options(table level)

This closes #1524
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","85dc4fff0ecca160654085379310a1c3096731f7","26","12","1","5160","627","121","5232","187","8479","1446","289","31","44","6410","0","68","32","524","apache-carbondata","85dc4fff0ecca160654085379310a1c3096731f7","606","16.5","154","85872","49349","11310","5","1723","185","2269","20.3","3819","72","4.8","5","277","2478","21931","28","900","4127","55","3045","118","56","20564","1.4","394","557","1"
"apache-carbondata","ee71610e1c7686117f3feebab75fdeb82dc31d54","2017-11-14 08:05:03","[CARBONDATA-1614][Streaming] Show file format for segment

This closes #1498
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","ee71610e1c7686117f3feebab75fdeb82dc31d54","26","12","1","5158","627","121","5228","187","8479","1446","289","31","44","6409","0","68","32","524","apache-carbondata","ee71610e1c7686117f3feebab75fdeb82dc31d54","606","16.5","154","85864","49345","11309","5","1723","185","2269","20.3","3819","72","4.8","5","277","2478","21931","28","900","4127","55","3045","118","56","20563","1.4","394","557","1"
"apache-carbondata","589f126dea872f54c2096c9572436bf10589b1ca","2017-10-25 02:57:37","[CARBONDATA-1626]add data size and index size in table status file

This closes #1435
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","589f126dea872f54c2096c9572436bf10589b1ca","26","12","1","5158","627","121","5228","187","8479","1446","289","31","44","6409","0","68","32","524","apache-carbondata","589f126dea872f54c2096c9572436bf10589b1ca","606","16.5","154","85859","49344","11309","5","1723","185","2271","20.3","3819","72","4.8","5","277","2480","21931","28","900","4127","55","3045","118","56","20567","1.4","396","557","1"
"apache-carbondata","dfc7442a483d839282edb6e1305c191aa60da65a","2017-11-16 23:01:43","[CARBONDATA-1745] Use default metastore path from Hive

This closes #1513
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","dfc7442a483d839282edb6e1305c191aa60da65a","26","12","1","5146","620","121","5206","187","8447","1431","289","31","43","6369","0","68","32","522","apache-carbondata","dfc7442a483d839282edb6e1305c191aa60da65a","606","16.5","154","85655","49182","11280","5","1709","185","2246","20.3","3815","72","4.8","5","277","2455","21846","28","900","4127","55","3045","118","56","20402","1.4","385","557","1"
"apache-carbondata","75ec79e3f7ddbbfcddb1fbfe1413aae2ee13b6e2","2017-11-16 22:57:15","[CARBONDATA-1741] Remove AKSK in log when saving to S3

This closes #1511
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","75ec79e3f7ddbbfcddb1fbfe1413aae2ee13b6e2","26","12","1","5146","620","121","5206","187","8447","1431","289","31","43","6369","0","68","32","522","apache-carbondata","75ec79e3f7ddbbfcddb1fbfe1413aae2ee13b6e2","606","16.5","154","85654","49182","11280","5","1709","185","2246","20.3","3815","72","4.8","5","277","2455","21846","28","900","4127","55","3045","118","56","20402","1.4","385","557","1"
"apache-carbondata","52bf7c81c8ecc632bdfaee6225a2e83ca697c475","2017-11-16 18:45:13","[CARBONDATA-1750] Fix NPE when tablestatus file is empty

Fix NPE when tablestatus file is empty

This closes #1517
","refs/heads/master","qiangcai@qq.com","apache-carbondata","52bf7c81c8ecc632bdfaee6225a2e83ca697c475","26","12","1","5145","620","119","5206","187","8443","1431","289","31","43","6366","0","68","32","522","apache-carbondata","52bf7c81c8ecc632bdfaee6225a2e83ca697c475","606","16.5","154","85637","49166","11272","5","1709","185","2244","20.2","3814","72","4.8","5","277","2453","21837","28","900","4127","55","3045","118","56","20392","1.4","383","557","1"
"apache-carbondata","0f46ef04d66a513f0987b05ace393016c151fd1c","2017-11-16 03:22:18","[CARBONDATA-1326] Fixed high priority findbug issue

 Fixed high priority findbug issue

This closes #1507
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","0f46ef04d66a513f0987b05ace393016c151fd1c","26","12","1","5145","620","119","5206","187","8443","1431","289","31","43","6366","0","68","32","522","apache-carbondata","0f46ef04d66a513f0987b05ace393016c151fd1c","606","16.5","154","85631","49162","11270","5","1709","185","2245","20.2","3814","72","4.8","5","278","2454","21834","28","900","4127","55","3045","118","56","20402","1.4","383","557","1"
"apache-carbondata","5fc7f06f23e944719b2735b97176d68fe209ad75","2017-11-16 03:41:19","[CARBONDATA-1739] Clean up store path interface

This closes #1509
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","5fc7f06f23e944719b2735b97176d68fe209ad75","26","12","1","5145","620","119","5206","187","8443","1433","289","31","43","6377","0","68","32","522","apache-carbondata","5fc7f06f23e944719b2735b97176d68fe209ad75","606","16.5","154","85626","49159","11272","5","1709","185","2245","20.2","3814","72","4.8","5","278","2454","21833","28","900","4127","55","3045","118","56","20403","1.4","383","557","1"
"apache-carbondata","733bb516dc3fc4a1e2be02b6574c70aafa7d3b9d","2017-11-16 01:27:21","[CARBONDATA-1732] Add S3 support in FileFactory

This closes #1504
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","733bb516dc3fc4a1e2be02b6574c70aafa7d3b9d","26","12","1","5145","620","119","5206","187","8443","1433","289","31","43","6376","0","68","32","522","apache-carbondata","733bb516dc3fc4a1e2be02b6574c70aafa7d3b9d","606","16.5","154","85619","49156","11271","5","1709","185","2245","20.2","3813","72","4.8","5","278","2454","21832","28","900","4127","55","3045","118","56","20403","1.4","383","557","1"
"apache-carbondata","aff3b9e4c033ac736de4888195a85906ebd61b13","2017-11-16 02:45:38","[CARBONDATA-1733] While load is in progress, Show segments is throwing NPE
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","aff3b9e4c033ac736de4888195a85906ebd61b13","26","12","1","5139","620","119","5206","187","8442","1432","289","31","43","6367","0","68","32","522","apache-carbondata","aff3b9e4c033ac736de4888195a85906ebd61b13","606","16.5","154","85592","49127","11246","5","1704","185","2240","20.2","3813","72","4.8","5","278","2449","21829","28","900","4127","55","3045","118","56","20348","1.4","383","557","1"
"apache-carbondata","17892b17b688eaa637b3dd97c25286edb4183eaa","2017-11-15 05:11:00","[CARBONDATA-1720][FILTER] Wrong data displayed for <= filter for timestamp column(dictionary column)

Issue:
<= filter is giving wrong results for timestamp dictioinary column
Solution:
In less than equal to filter, we are considering surrogate 2 as default value. But surrogate 1 is for default value.

This closes #1502
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","17892b17b688eaa637b3dd97c25286edb4183eaa","26","12","1","5139","620","119","5206","187","8442","1432","289","31","43","6367","0","68","32","522","apache-carbondata","17892b17b688eaa637b3dd97c25286edb4183eaa","606","16.5","154","85588","49124","11244","5","1706","187","2242","20.2","3813","74","4.9","5","278","2451","21827","28","900","4157","55","3045","118","56","20388","1.4","383","557","1"
"apache-carbondata","40c31e8049784a53594896cd2e37cd2fb5135fbc","2017-11-10 03:57:17","[CARBONDATA-1572][Streaming] Add test case for streaming ingest

Add test case for streaming ingest using socket stream

This closes #1485
","refs/heads/master","qiangcai@qq.com","apache-carbondata","40c31e8049784a53594896cd2e37cd2fb5135fbc","25","12","1","5047","598","119","5076","187","8278","1395","287","29","43","6282","0","68","28","522","apache-carbondata","40c31e8049784a53594896cd2e37cd2fb5135fbc","598","16.7","154","84347","48249","11019","5","1682","187","2203","20.1","3752","74","5","5","276","2411","21354","28","870","4188","54","3045","117","56","20163","1.4","369","549","1"
"apache-carbondata","80195da41390cd122e6099483149aa4cf59300fd","2017-11-10 04:55:09","[CARBONDATA-1701][SEGMENT READING] Threadsafe api revealed for set segment to read

Example: CarbonSession.threadSet(carbon.input.segments.default.carbon_table_MulTI_THread, 1,2,3)

This closes #1482
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","80195da41390cd122e6099483149aa4cf59300fd","25","12","1","5047","598","119","5074","187","8278","1394","287","29","43","6282","0","68","28","522","apache-carbondata","80195da41390cd122e6099483149aa4cf59300fd","598","16.7","154","84336","48242","11015","5","1682","187","2203","20.1","3752","74","5","5","276","2411","21350","28","870","4188","54","3045","117","56","20163","1.4","369","549","1"
"apache-carbondata","53b92e5f8fb527529a6b075f8c71d3e389b2cee5","2017-06-29 03:20:56","[CARBONDATA-1248] change LazyColumnPage parent class
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","53b92e5f8fb527529a6b075f8c71d3e389b2cee5","29","8","0","3942","491","82","4472","127","6611","1159","272","27","45","5314","0","23","20","480","apache-carbondata","53b92e5f8fb527529a6b075f8c71d3e389b2cee5","520","18.8","108","73063","39906","8769","5","1475","121","1929","18.1","3101","51","3.8","5","228","2089","17245","24","815","2749","52","2120","106","65","16603","1.4","297","485","1"
"apache-carbondata","1155d4d8f236b7fc8e81197d7966ac5aa926488f","2017-10-09 22:20:11","[CARBONDATA-1573] [Integration] Support Database Location Configuration while Creating Database/ Support Creation of carbon Table in the database location

Problem:
Currently carbon stores the database and tables at the fixed configured location “carbon.storeLocation”. So even though in case of federated cluster i.e. multiple independent Namespaces/ Namenodes only one Namespace/ Namenode can be used as storage for the database and tables.
The requirement is to support when create database can specify the LOCATION; the location can be viewfs path, name service path.
Using database location attribute configuration different name nodes can be used to store different databases. Having different name nodes for different databases will scale the read/write throughput.
Solution:
Setting the LOCATION attribute for a new database is a way to work with sets of files in an HDFS directory structure outside the fixed carbon store location.
In Create database command user can specify the location, the location where database and table under that database namespace could be stored.

This closes #1418
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","1155d4d8f236b7fc8e81197d7966ac5aa926488f","26","12","1","5139","620","119","5206","187","8442","1432","289","31","43","6367","0","68","32","522","apache-carbondata","1155d4d8f236b7fc8e81197d7966ac5aa926488f","606","16.5","154","85580","49124","11244","5","1706","185","2242","20.2","3813","74","4.8","5","278","2451","21827","28","900","4081","55","3045","118","56","20368","1.4","383","557","1"
"apache-carbondata","17d07319c4174b007a65f9a95f0ddd0ada57798d","2017-11-02 07:24:40","[CARBONDATA-1617] Fixed atomic file operations and output stream close in Carbon index merge files

The merge file should be written to temp file and then renamed to actual after success.
And output stream close to Carbon index merge files

This closes #1461
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","17d07319c4174b007a65f9a95f0ddd0ada57798d","26","12","1","5144","620","119","5228","187","8481","1432","289","31","43","6375","0","68","32","522","apache-carbondata","17d07319c4174b007a65f9a95f0ddd0ada57798d","606","16.6","154","85782","49220","11246","5","1705","185","2242","20.2","3815","74","4.8","5","278","2451","21849","28","900","4081","55","3045","118","56","20390","1.4","384","557","1"
"apache-carbondata","d2319f067d436b0d8a7e099c44aab5858b859dd3","2017-11-13 00:54:55","[CARBONDATA-1704] [FILTER] Filter Optimization

If the include filter (on a dictionary column)gives more than 60% of data from a block, then Include Filter will be converted to Exclude Filter

Scenario:
column1
a
b
c
d

Query --> Select * from table_name where column1 in (a,b,c);
This will consume more than 60% of the data. In this case internally query will be optimized to exclude filter as below,
Select * from table_name where column1 not in (d);

This closes #1492
","refs/heads/master","dhatchayani.s@huawei.com","apache-carbondata","d2319f067d436b0d8a7e099c44aab5858b859dd3","26","12","1","5145","620","119","5228","187","8481","1431","289","31","43","6375","0","68","32","522","apache-carbondata","d2319f067d436b0d8a7e099c44aab5858b859dd3","606","16.6","154","85778","49216","11244","5","1705","185","2242","20.2","3814","74","4.8","5","278","2451","21845","28","900","4081","55","3045","118","56","20390","1.4","384","557","1"
"apache-carbondata","2f0959a824b728e8f6193753767e1f58dee4017d","2017-11-12 06:50:15","[CARBONDATA-1693][Streaming] Change SegmentStatus from String to enum

This closes #1480
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","2f0959a824b728e8f6193753767e1f58dee4017d","25","12","1","5138","612","119","5220","187","8462","1422","287","31","43","6361","0","68","29","522","apache-carbondata","2f0959a824b728e8f6193753767e1f58dee4017d","606","16.6","154","85607","49066","11199","5","1696","187","2227","20.1","3808","74","4.9","5","277","2436","21770","28","900","4188","55","3045","118","56","20306","1.4","379","557","1"
"apache-carbondata","1a621895b9c2646480a5d29aa8e6eafb9252c51a","2017-11-13 07:57:38","[CARBONDATA-1576][PREAGG][DATAMAP] Support DataMap drop

Added drop datamap sql parser to support dropping datamap from table.

DROP DATAMAP IF EXISTS datamapname ON TABLE tablename
Added restriction on dropping child table if user tries to drop the datamap table directly.

This closes #1489
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","1a621895b9c2646480a5d29aa8e6eafb9252c51a","25","12","1","5136","612","119","5242","187","8462","1425","287","31","43","6386","0","68","29","522","apache-carbondata","1a621895b9c2646480a5d29aa8e6eafb9252c51a","606","16.6","154","85602","49074","11202","5","1696","187","2227","20.1","3807","74","4.9","5","277","2436","21773","28","900","4188","55","3045","118","56","20306","1.4","379","557","1"
"apache-carbondata","1e408c5d67aac8fc14fc0abeb55f119aff026611","2017-11-10 06:21:24","[CARBONDATA-1699][FILTER] Filter is not working properly

Issue:
When having duplicate values in the data, filter results are wrong

Scenario:
Load data like below
a,11234567489.7976
b,11234567489.7976000000

Filter query on double_column = 11234567489.7976

Result - only either one of the row is selected
Actual Result - all the two rows should be selected(both the values will be same while parsing)

Logic of binary search while applying filter is changed (in case of duplicates in DOUBLE column)

This closes #1483
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","1e408c5d67aac8fc14fc0abeb55f119aff026611","25","12","1","5136","612","119","5242","187","8458","1425","287","31","43","6385","0","68","30","522","apache-carbondata","1e408c5d67aac8fc14fc0abeb55f119aff026611","606","16.6","154","85585","49062","11197","5","1697","187","2228","20.1","3806","74","4.9","5","277","2437","21765","28","900","4188","55","3045","118","56","20311","1.4","379","557","1"
"apache-carbondata","fab102b89a41fe08ad4d583e35dcbaa6ab6177b9","2017-11-13 10:53:11","[CARBONDATA-1528] [PreAgg] Restrict alter for pre-aggregate tables

This closes #1493
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","fab102b89a41fe08ad4d583e35dcbaa6ab6177b9","25","12","1","5136","609","119","5236","187","8455","1425","287","31","43","6384","0","68","29","522","apache-carbondata","fab102b89a41fe08ad4d583e35dcbaa6ab6177b9","606","16.6","154","85567","49044","11192","5","1694","187","2223","20.1","3805","74","4.9","5","277","2432","21754","28","900","4188","55","3045","118","56","20281","1.4","377","557","1"
"apache-carbondata","e4f2843c6d9aa3dc8dfca52c6fcfa084b07492a5","2017-10-30 00:14:32","[CARBONDATA-1523]Pre Aggregate table selection and Query Plan changes

This closes #1464
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","e4f2843c6d9aa3dc8dfca52c6fcfa084b07492a5","25","12","1","5135","609","119","5236","187","8455","1425","287","31","43","6384","0","68","29","522","apache-carbondata","e4f2843c6d9aa3dc8dfca52c6fcfa084b07492a5","606","16.6","154","85563","49041","11191","5","1694","187","2223","20.1","3804","74","4.9","5","277","2432","21753","28","900","4188","55","3045","118","56","20281","1.4","377","557","1"
"apache-carbondata","1c16afad8decb42f28cb656e5f11664dcadf503b","2017-11-12 03:38:09","[CARBONDATA-1576] Added create datamap parser and saved to schema file

User can create datamap using the following syntax.

 CREATE DATAMAP agg_sales
  ON TABLE sales
USING org.apache.carbondata.datamap.AggregateDataMapHandler
DMPROPERTIES (
 'KEY’=’VALUE’
) AS
SELECT order_time, count(user_id) FROM sales GROUP BY order_time
In the above syntax DMPROPERTIES and AS QUERY are optional.

This closes #1481
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","1c16afad8decb42f28cb656e5f11664dcadf503b","25","12","1","5108","602","119","5202","187","8391","1411","287","31","43","6338","0","68","29","522","apache-carbondata","1c16afad8decb42f28cb656e5f11664dcadf503b","601","16.6","154","85032","48768","11111","5","1687","187","2215","20.1","3782","74","4.9","5","276","2423","21616","28","870","4188","54","3045","117","56","20207","1.4","376","552","1"
"apache-carbondata","2b5faefada0d9078988f28b33249ebc3b2549c80","2017-10-23 05:58:15","[CARBONDATA-1527] [CARBONDATA-1528] [PreAgg] Restrict alter/update/delete for pre-aggregate table

This closes #1476
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","2b5faefada0d9078988f28b33249ebc3b2549c80","25","12","1","5106","602","119","5202","187","8389","1410","287","31","43","6338","0","68","29","522","apache-carbondata","2b5faefada0d9078988f28b33249ebc3b2549c80","601","16.6","154","85018","48751","11107","5","1686","187","2214","20.1","3781","74","4.9","5","276","2422","21608","28","870","4188","54","3045","117","56","20202","1.4","376","552","1"
"apache-carbondata","cc0e6f1e77b39d712de0e6101b2d24e57c5b47cb","2017-10-26 04:39:54","[CARBONDATA-1520] [PreAgg] Support pre-aggregate table load

This closes #1446
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","cc0e6f1e77b39d712de0e6101b2d24e57c5b47cb","25","12","1","5102","602","119","5202","187","8386","1407","287","31","43","6337","0","68","29","522","apache-carbondata","cc0e6f1e77b39d712de0e6101b2d24e57c5b47cb","601","16.6","154","85002","48738","11105","5","1686","187","2209","20.1","3780","74","4.9","5","276","2417","21604","28","870","4188","54","3045","117","56","20177","1.4","371","552","1"
"apache-carbondata","f7f516ef665c98e43fce0427c40da933bb6f3185","2017-10-18 07:39:04","[CARBONDATA-1524][CARBONDATA-1525][AggTable] Added support for aggregate table drop

This closes #1443
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","f7f516ef665c98e43fce0427c40da933bb6f3185","25","12","1","5096","600","119","5194","187","8378","1406","287","31","43","6308","0","68","29","522","apache-carbondata","f7f516ef665c98e43fce0427c40da933bb6f3185","601","16.6","154","84946","48693","11094","5","1686","187","2209","20.1","3775","74","4.9","5","276","2417","21584","28","870","4188","54","3045","117","56","20176","1.4","371","552","1"
"apache-carbondata","3d1d1ce85a5905f0877ce3e367f255fd71e18ad2","2017-10-15 05:35:55","[CARBONDATA-1517]- Pre Aggregate Create Table Support

Support CTAS in carbon and support creating aggregation tables using CTAS and update aggregation table information to main table schema.

This closes #1433
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","3d1d1ce85a5905f0877ce3e367f255fd71e18ad2","25","12","1","5095","600","119","5194","187","8378","1406","287","31","43","6308","0","68","29","522","apache-carbondata","3d1d1ce85a5905f0877ce3e367f255fd71e18ad2","601","16.6","154","84944","48692","11094","5","1686","187","2209","20.1","3775","74","4.9","5","276","2417","21584","28","870","4188","54","3045","117","56","20176","1.4","371","552","1"
"apache-carbondata","3169918523a42c8f2c1d612052a7680514372bf9","2017-10-21 04:01:15","[CARBONDATA-1609] Thrift Changes to support Pre-aggregate

This closes #1425
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","3169918523a42c8f2c1d612052a7680514372bf9","25","12","1","5086","600","119","5188","187","8373","1406","287","31","43","6308","0","68","29","522","apache-carbondata","3169918523a42c8f2c1d612052a7680514372bf9","600","16.6","154","84872","48654","11091","5","1686","187","2209","20.1","3772","74","4.9","5","276","2417","21571","28","870","4188","54","3045","117","56","20176","1.4","371","551","1"
"apache-carbondata","933e30ccc74d499a6323f328349c9a71ba0c44e3","2017-11-05 19:13:40","[CARBONDATA-1662] Make ArrayType and StructType contain child DataType

StructType and ArrayType should be class that have nested children.

This closes #1429
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","933e30ccc74d499a6323f328349c9a71ba0c44e3","25","12","0","5041","598","118","5074","187","8270","1394","287","29","43","6278","0","68","28","522","apache-carbondata","933e30ccc74d499a6323f328349c9a71ba0c44e3","598","16.7","154","84278","48196","11006","5","1680","187","2198","20","3749","74","5","5","274","2406","21326","28","870","4188","54","3045","117","56","20101","1.4","368","549","1"
"apache-carbondata","4aa0f493038a050f61af7c5d6c3af22cd20fd56b","2017-11-06 22:20:15","[CARBONDATA-1592]Event listener added

This closes #1473
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","4aa0f493038a050f61af7c5d6c3af22cd20fd56b","25","12","0","5034","598","118","5080","187","8271","1392","287","29","43","6298","0","70","25","526","apache-carbondata","4aa0f493038a050f61af7c5d6c3af22cd20fd56b","597","16.7","154","84218","48185","11015","5","1678","187","2200","20.1","3742","74","5","5","274","2408","21316","28","870","4188","54","3045","117","56","20110","1.4","372","548","1"
"apache-carbondata","fd0bdf6f6c9ebe124789d4041ed98a9a790f38c1","2017-09-14 06:14:09","[CARBONDATA-1398] Support query from specified segments

A new property will introduce to set the segment no.
User will set property(carbon.input.segments. <database_name> .<table_name>) to specify segment no.
During CarbonScan data will be read from from specified segments only.
If property is not set, all segments will be caonsidered as default behavior.

This closes #1367
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","fd0bdf6f6c9ebe124789d4041ed98a9a790f38c1","25","12","0","5029","598","118","5064","183","8255","1390","287","29","40","6297","0","70","25","526","apache-carbondata","fd0bdf6f6c9ebe124789d4041ed98a9a790f38c1","596","16.7","151","84054","48128","11001","5","1676","187","2198","20.1","3737","74","5","5","271","2403","21293","28","870","4188","54","2985","117","56","20099","1.4","372","546","1"
"apache-carbondata","9e9d68988e29a9c3a2520189d822835562f4a34d","2017-10-30 19:55:38","[CARBONDATA-1624]Set the default value of 'carbon.number.of.cores.while.loading' as per the spark conf 'spark.executor.cores'

1.Use 'spark.executor.cores' as the default value for 'carbon.number.of.cores.while.loading'
2.Use 'CarbonProperties.getNumberOfCores()' to get 'carbon.number.of.cores.while.loading' uniformly

This closes #1455
","refs/heads/master","441586683@qq.com","apache-carbondata","9e9d68988e29a9c3a2520189d822835562f4a34d","25","12","0","5028","598","118","5062","183","8251","1388","287","29","40","6297","0","70","25","526","apache-carbondata","9e9d68988e29a9c3a2520189d822835562f4a34d","596","16.7","151","84015","48094","10988","5","1673","187","2195","20.1","3736","74","5","5","271","2400","21277","28","870","4188","54","2985","117","56","20071","1.4","372","546","1"
"apache-carbondata","d7393da9890c2360831d17d23145b78f8da70575","2017-10-17 20:13:00","[CARBONDATA-1572][Streaming] Support streaming ingest and query

This PR supports streaming ingest from spark structured streaming:
1.row format writer and support to append batch data

2.support StreamSinkProvider and append batch data to row format file

3.row format reader and support to split row format file to small blocks

4.query with streaming row format file.

This closes #1470
","refs/heads/master","qiangcai@qq.com","apache-carbondata","d7393da9890c2360831d17d23145b78f8da70575","25","12","0","5028","598","118","5062","183","8250","1388","287","29","40","6301","0","70","25","526","apache-carbondata","d7393da9890c2360831d17d23145b78f8da70575","596","16.7","151","84033","48112","10991","5","1673","187","2195","20.1","3736","74","5","5","271","2400","21283","28","870","4188","54","2985","117","56","20071","1.4","372","546","1"
"apache-carbondata","46731137579750d8389f3f9c4ec58547457fda2d","2017-11-06 04:40:14","[CARBONDATA-1618]Table comment support for alter table

This closes #1472
","refs/heads/master","pmalwal1981@gmail.com","apache-carbondata","46731137579750d8389f3f9c4ec58547457fda2d","25","12","0","4986","597","118","5028","183","8191","1380","283","29","40","6257","0","70","25","526","apache-carbondata","46731137579750d8389f3f9c4ec58547457fda2d","595","16.8","151","83654","47814","10905","5","1661","187","2180","20","3713","74","5","5","271","2383","21150","26","860","4215","52","2985","117","56","19916","1.4","369","545","1"
"apache-carbondata","74bd52b66f7dae938c1d993e5dc3a7a225227866","2017-10-29 09:01:21","[CARBONDATA-1611][Streaming] Reject Update and Delete operation for streaming table

This closes #1447
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","74bd52b66f7dae938c1d993e5dc3a7a225227866","25","12","0","4990","597","118","5028","183","8192","1381","283","29","40","6257","0","70","25","526","apache-carbondata","74bd52b66f7dae938c1d993e5dc3a7a225227866","595","16.8","151","83663","47822","10906","5","1662","187","2181","20","3714","74","5","5","271","2384","21152","26","860","4215","52","2985","117","56","19921","1.4","369","545","1"
"apache-carbondata","ae280e239aa76ff547ceedfdb8fb031ae5af078e","2017-10-25 20:12:42","[CARBONDATA-1618] Fix issue of not support table comment

Background: Current carbon do not support table comment when create table.
This PR will support table comment.

This closes #1437
","refs/heads/master","chenerlu@huawei.com","apache-carbondata","ae280e239aa76ff547ceedfdb8fb031ae5af078e","25","12","0","4989","597","118","5028","183","8191","1381","283","29","40","6253","0","70","25","526","apache-carbondata","ae280e239aa76ff547ceedfdb8fb031ae5af078e","595","16.8","151","83655","47818","10904","5","1661","187","2180","20","3713","74","5","5","271","2383","21150","26","860","4215","52","2985","117","56","19911","1.4","369","545","1"
"apache-carbondata","0578ba0f2f9931a89f9759ea4be97975957280ae","2017-11-06 19:41:30","[CARBONDATA-1669] Clean up code in CarbonDataRDDFactory

This closes #1467
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","0578ba0f2f9931a89f9759ea4be97975957280ae","25","12","0","4986","597","118","5028","183","8190","1381","283","29","40","6253","0","70","25","526","apache-carbondata","0578ba0f2f9931a89f9759ea4be97975957280ae","595","16.8","151","83644","47811","10904","5","1661","187","2180","20","3713","74","5","5","271","2383","21148","26","860","4215","52","2985","117","56","19911","1.4","369","545","1"
"apache-carbondata","11661eb69d8a484747cba30abac88eb4c0cb2125","2017-10-01 10:23:12","[CARBONDATA-1537] Added back Adaptive delta encoding for floating type for backward compatibility

Currently, backward compatibility is broken because of missing adaptive delta floating encoding which was present in older versions but it is removed in the latest version.
Added back this encoding to keep the compatibility

This closes #1400
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","11661eb69d8a484747cba30abac88eb4c0cb2125","25","12","0","4986","597","118","5028","183","8187","1381","283","29","40","6253","0","70","25","526","apache-carbondata","11661eb69d8a484747cba30abac88eb4c0cb2125","595","16.8","151","83637","47804","10903","5","1661","187","2180","20","3712","74","5","5","271","2383","21146","26","860","4215","52","2985","117","56","19911","1.4","369","545","1"
"apache-carbondata","f209e8ee315a272f1f60a7a037d6c15fc08b6add","2017-10-31 11:48:47","[CARBONDATA-1594] Add precision and scale to DecimalType

Refactor on DecimalType to include precision and scale parameter.
Precision and scale parameter is required for Decimal data type. In earlier code, they are stored in following classes:

ColumnSpec
ColumnPageEncoderMeta
PrimitivePageStatsCollector
ColumnSchema
Since now we have changed DataType from enum to class, precision and scale should be stored in DecimalType object only. The PR does this change.

No new test case is added in this PR since no functionality change.

This closes #1417
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","f209e8ee315a272f1f60a7a037d6c15fc08b6add","25","12","0","4956","596","117","5028","172","8146","1378","283","29","39","6247","0","71","25","526","apache-carbondata","f209e8ee315a272f1f60a7a037d6c15fc08b6add","594","16.8","140","83410","47630","10851","5","1657","181","2173","19.9","3707","73","4.8","5","260","2365","21080","26","860","4040","52","2765","117","56","19762","1.4","366","544","1"
"apache-carbondata","8815dd586c181e74400190ae04f4ec0e86d25402","2017-03-15 02:08:31","fixed multiple dictionary server issue
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","8815dd586c181e74400190ae04f4ec0e86d25402","23","6","0","3655","410","78","4226","86","6458","989","331","29","46","5100","0","23","56","412","apache-carbondata","8815dd586c181e74400190ae04f4ec0e86d25402","477","19.2","70","68885","37242","7953","5","1459","148","1894","17.5","2880","73","4.4","5","178","2003","16124","18","660","3010","39","1360","101","58","15942","1.4","290","455","1"
"apache-carbondata","0586146a8bd953db63e1d99608ba8a77a9f5a899","2017-10-24 22:43:22","[CARBONDATA-1617] Merging carbonindex files within segment

Merge the carbonindex files after data load, so that we can reduce the IO calls to namenode and improves the read performance for first query

This closes #1436
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","0586146a8bd953db63e1d99608ba8a77a9f5a899","25","14","0","4973","598","117","5032","172","8149","1385","283","29","39","6219","0","77","26","526","apache-carbondata","0586146a8bd953db63e1d99608ba8a77a9f5a899","594","16.8","140","83419","47632","10833","5","1664","181","2185","19.9","3706","73","4.8","5","260","2377","21076","26","860","4041","52","2765","117","56","19860","1.4","371","544","1"
"apache-carbondata","4d70a2118fb26936e0b7eee9a0ce2147cb0501c9","2017-10-28 03:56:38","[CARBONDATA-1653] Rename aggType to measureDataType

This closes #1444
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","4d70a2118fb26936e0b7eee9a0ce2147cb0501c9","25","14","0","4954","598","117","5022","172","8088","1378","279","29","39","6160","0","77","25","522","apache-carbondata","4d70a2118fb26936e0b7eee9a0ce2147cb0501c9","590","16.8","141","82951","47380","10794","5","1658","181","2177","20","3691","73","4.9","5","261","2370","20962","26","860","4041","52","2775","117","56","19832","1.4","369","540","1"
"apache-carbondata","9326cfdc07bf741b3516c22fae7362088ce1d7ac","2017-10-10 05:59:46","[CARBONDATA-1568] Optimize annotation of code

There are some improper places in code annotation by IDEA inspect code
We optimize annotation of code:

Fix an error of Javadoc issues
modify the expression of annotation

This closes #1408
","refs/heads/master","601450868@qq.com","apache-carbondata","9326cfdc07bf741b3516c22fae7362088ce1d7ac","25","14","0","4954","598","117","5022","172","8090","1378","279","29","39","6162","0","77","25","522","apache-carbondata","9326cfdc07bf741b3516c22fae7362088ce1d7ac","590","16.8","141","82968","47390","10798","5","1659","181","2178","20","3692","73","4.9","5","261","2371","20967","26","860","4041","52","2775","117","56","19833","1.4","369","540","1"
"apache-carbondata","6abdd97a42e945a0df61573aa477c9b3ddb7af02","2017-10-16 04:59:50","[CARBONDATA-1444] Support Boolean data type

Spark/Hive table support Boolean data type, the internal table also should support Boolean data type.

Boolean data type Range: TRUE or FALSE. Do not use quotation marks around the TRUE and FALSE literal values. You can write the literal values in uppercase, lowercase, or mixed case. The values queried from a table are always returned in lowercase, true or false.

This closes #1362
","refs/heads/master","601450868@qq.com","apache-carbondata","6abdd97a42e945a0df61573aa477c9b3ddb7af02","25","14","0","4954","598","117","5022","172","8090","1378","279","29","39","6162","0","77","25","522","apache-carbondata","6abdd97a42e945a0df61573aa477c9b3ddb7af02","590","16.8","141","82953","47390","10798","5","1659","181","2178","20","3692","73","4.9","5","261","2371","20967","26","860","4041","52","2775","117","56","19833","1.4","369","540","1"
"apache-carbondata","956833e5525742616d8a0e6b885132acd7291b76","2017-10-08 07:06:01","[CARBONDATA-1539] Change data type from enum to class

DataType should be java class instead of enum, to hold more information for decimal and complex type. And it is needed to decouple carbon core and spark.

No logic is changed in this PR.

This closes #1402
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","956833e5525742616d8a0e6b885132acd7291b76","25","14","0","4947","586","117","5022","172","8064","1374","279","29","39","6133","0","77","25","514","apache-carbondata","956833e5525742616d8a0e6b885132acd7291b76","587","16.8","141","82702","47200","10688","5","1649","180","2168","19.8","3683","73","4.9","5","258","2358","20841","26","830","4029","49","2775","116","56","19659","1.4","369","539","1"
"apache-carbondata","75e0bd4199e4c8123bd4dde6dbae208ab5f8311b","2017-10-08 04:18:59","[CARBONDATA-1538] Added code to support BITSET PIPE LINE in filter

This closes #1403
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","75e0bd4199e4c8123bd4dde6dbae208ab5f8311b","25","8","0","4835","539","118","4976","172","7942","1371","279","29","42","6132","0","25","26","514","apache-carbondata","75e0bd4199e4c8123bd4dde6dbae208ab5f8311b","568","16.7","141","82429","47350","10667","5","1689","178","2209","20.5","3645","72","4.9","5","256","2399","20608","26","830","4075","49","2775","116","56","19822","1.4","372","520","1"
"apache-carbondata","133b30391a41131d510485ce77f4f1f2bf35900c","2017-09-30 05:06:01","[CARBONDATA-1537] Fixed version compatabilty issues from V1 to latest carbon version

This closes #1398
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","133b30391a41131d510485ce77f4f1f2bf35900c","25","6","0","4818","537","118","4960","172","7854","1363","279","29","42","6076","0","25","26","514","apache-carbondata","133b30391a41131d510485ce77f4f1f2bf35900c","568","16.7","141","82000","47081","10596","5","1671","176","2190","20.4","3628","72","4.8","5","256","2380","20492","26","830","3956","49","2775","116","56","19599","1.4","371","520","1"
"apache-carbondata","ad25ffc31ec5d2b74207fc55b2c66bda8443eb7a","2017-09-28 04:33:46","[CARBONDATA-1533] Fixed decimal data load fail issue and restricted max characters per column

1. Fixed data load failure when both precision and data falls in integer range for decimal data type.
2. Restricted max characters per column to 32000 as we use short to store the length of each column

This closes #1395
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","ad25ffc31ec5d2b74207fc55b2c66bda8443eb7a","25","6","0","4815","532","116","4952","171","7816","1358","279","29","42","6024","0","25","26","518","apache-carbondata","ad25ffc31ec5d2b74207fc55b2c66bda8443eb7a","568","16.7","140","81876","46968","10577","5","1675","178","2192","20.3","3624","73","4.9","5","255","2379","20414","24","810","4006","47","2755","116","56","19677","1.4","369","520","1"
"apache-carbondata","a734add5a95790f207d21a2e0dcc4e1480d51932","2017-09-25 05:54:03","[CARBONDATA-1410] Fixed thread leak issue in case of data loading

Problem: In case of data loading failure threads are not getting closed and its causing thread leak in long run, because of this OOM is coming
Solution: Close all the thread in case of failure , Success and killing

This closes #1401
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","a734add5a95790f207d21a2e0dcc4e1480d51932","25","6","0","4815","532","116","4952","171","7816","1358","279","29","42","6024","0","25","26","518","apache-carbondata","a734add5a95790f207d21a2e0dcc4e1480d51932","568","16.7","140","81873","46965","10576","5","1675","178","2192","20.3","3624","73","4.9","5","255","2379","20412","24","810","4006","47","2755","116","56","19677","1.4","369","520","1"
"apache-carbondata","28f78b2fc1eda650d1e7a7ea48258ba911361b1a","2017-09-20 22:40:57","[CARBONDATA-1505] Get the detailed blocklet information using default BlockletDataMap for other datamaps

All the detail information of blocklet which is need for exceuting query is present only BlockletDataMap. It is actually default datamap.
So if new datamap is added then it gives only information of blocklet and blockid, it is insuffucient information to exceute query.
Now this PR adds the functionality of retrieving detailed blocklet information from the BlockletDataMap based on block and blocklet id. So now new datamaps can only concentrate on business logic and return only block and blockletid.

This closes #1376
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","28f78b2fc1eda650d1e7a7ea48258ba911361b1a","25","6","0","4812","532","116","4948","171","7813","1357","279","29","42","6024","0","25","26","518","apache-carbondata","28f78b2fc1eda650d1e7a7ea48258ba911361b1a","567","16.7","140","81816","46946","10573","5","1675","178","2192","20.4","3621","73","4.9","5","255","2379","20406","24","810","4006","47","2755","116","56","19677","1.4","369","519","1"
"apache-carbondata","eb771f5ee6511288e3c53281f3fac02d6f69c66a","2017-09-21 06:33:06","[CARBONDATA-1504] Fixed refresh of segments in datamap for update and partition

Currently datamap scans complete segment every time for query execution to get all the carbonindex files. It will be slow when data/number of files are big.
So this PR caches the content of segment and refreshes when any updation or store changes.

This closes #1377
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","eb771f5ee6511288e3c53281f3fac02d6f69c66a","25","6","0","4803","532","116","4938","171","7786","1355","279","29","42","6018","0","25","26","518","apache-carbondata","eb771f5ee6511288e3c53281f3fac02d6f69c66a","565","16.7","140","81632","46849","10554","5","1674","178","2191","20.4","3612","73","4.9","5","255","2378","20366","24","810","4006","47","2755","116","56","19675","1.4","369","517","1"
"apache-carbondata","d5dd78afd237f10593c4403d9bf1d3bc482d3636","2017-09-25 05:45:20","[CARBONDATA-1278] Data Mismatch issue when dictionary column filter values doesn't exists in dictionary

Root cause: when filter value is not present in dictionary, end key for that column is updated with 0,and hence btree jump is not selecting all the leaf node.
Fix:
To handle this issue end key should be updated with Integer max value, so that it can go till last leafnode of btree

This closes #1383
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d5dd78afd237f10593c4403d9bf1d3bc482d3636","25","6","0","4793","532","116","4932","171","7772","1351","279","29","42","6017","0","25","25","516","apache-carbondata","d5dd78afd237f10593c4403d9bf1d3bc482d3636","564","16.7","140","81546","46783","10531","5","1673","178","2190","20.4","3607","73","4.9","5","255","2377","20330","24","810","4006","47","2755","116","56","19670","1.4","369","517","1"
"apache-carbondata","2cd22e1d682f29c54a2491deec18314e65a03f4e","2017-09-25 04:36:21","[CARBONDATA-1449]Fixed date and timestamp filter gc issue in case of direct dictionary

Problem: When date or timestamp filter is going to row level there is lots of gc this is because for each row it is creating new direct dictionary object for data type;
Solution: create one object and use the same.
Improvement tested with 2million rows:
~19 seconds to ~9 seconds

This closes #1381
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","2cd22e1d682f29c54a2491deec18314e65a03f4e","26","6","0","4793","531","116","4932","171","7772","1351","279","29","42","6021","0","25","25","516","apache-carbondata","2cd22e1d682f29c54a2491deec18314e65a03f4e","564","16.7","140","81542","46779","10530","5","1672","178","2189","20.4","3607","73","4.9","5","255","2376","20326","24","810","4006","47","2755","116","56","19649","1.4","369","517","1"
"apache-carbondata","7f6b08a2b5b13799a2a0bbd29d40f45da14d07b1","2017-09-21 23:52:39","[CARBONDATA-1509] Fixed bug for maintaining compatibility of decimal type with older releases of Carbondata

In old Carbondata releases, precision and scale is not stored for decimal data type and both values are initialized to -1. In TableSpec.ColumnSpec default values for precision and scale are initialized to 0 because of which exception is thrown while reading the old store with decimal column. Both precision and scale should be initialized to -1.

This closes #1378
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","7f6b08a2b5b13799a2a0bbd29d40f45da14d07b1","26","6","0","4793","531","116","4930","170","7773","1349","279","29","42","6023","0","25","25","516","apache-carbondata","7f6b08a2b5b13799a2a0bbd29d40f45da14d07b1","564","16.7","139","81527","46772","10526","5","1672","178","2189","20.4","3607","73","4.9","5","254","2375","20325","24","810","4006","47","2735","116","56","19649","1.4","369","517","1"
"apache-carbondata","80fa37c5547f7d19ee5471602ed16ca2b5303bcd","2017-09-19 01:50:16","[CARBONDATA-1448] fix partitionInfo null issue in CarbonTableInputFormat

This closes #1369
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","80fa37c5547f7d19ee5471602ed16ca2b5303bcd","26","6","0","4792","531","116","4930","170","7773","1349","279","29","42","6023","0","25","25","516","apache-carbondata","80fa37c5547f7d19ee5471602ed16ca2b5303bcd","564","16.7","139","81525","46772","10526","5","1672","178","2189","20.4","3607","73","4.9","5","254","2375","20325","24","810","4006","47","2735","116","56","19649","1.4","369","517","1"
"apache-carbondata","1e7da59b466ae4f33e3c184db02f218f91a6a2ae","2017-09-19 23:33:18","[CARBONDATA-1491] Dictionary_exclude columns are not going into no_dictionary flow

(1) DICTIONARY_EXCLUDE columns are not considered as no_dictionary columns - while parsing we are not setting nodictionary columns.
(2) For reconstructing defaultValue for newly added no dictionary measure column, logic is changed, as the previous logic can throw IllegalArgumentException for wrong length.
(3) Test cases are added for the same.

This closes #1374
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","1e7da59b466ae4f33e3c184db02f218f91a6a2ae","26","6","0","4786","531","116","4942","170","7750","1348","279","29","42","6015","0","25","25","516","apache-carbondata","1e7da59b466ae4f33e3c184db02f218f91a6a2ae","564","16.7","139","81393","46651","10500","5","1670","178","2191","20.3","3601","73","4.9","5","254","2377","20245","24","810","4006","47","2735","116","56","19653","1.4","373","517","1"
"apache-carbondata","e9c24c50536e7700fe4ce468114820cb21942ee3","2017-09-19 03:54:35","[CARBONDATA-1488] JVM crashes when unsafe columnpage is enabled

Fixed capacity size calculation when column value size is larger than initial capacity in this PR.

This closes #1370
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","e9c24c50536e7700fe4ce468114820cb21942ee3","26","6","0","4786","531","116","4942","170","7750","1348","279","29","42","6015","0","25","25","516","apache-carbondata","e9c24c50536e7700fe4ce468114820cb21942ee3","564","16.7","139","81390","46648","10500","5","1669","178","2190","20.3","3601","73","4.9","5","254","2376","20242","24","810","4006","47","2735","116","56","19638","1.4","373","517","1"
"apache-carbondata","36ceb59f014f7369575f433064e88aa07a7de48e","2017-09-05 03:24:28","[CARBONDATA-1450] Support timestamp, int and Long as Dictionary Exclude

Timestamp column supports 68 years.

This PR breaks the limitation of 68 years and can support any time.

To be noted,

(1) By default timestamp will be no dictionary column that can support any timestamp without limitation

(2) If it is enough to load only 68 years, then explicitly timestamp column can be included in DICTIONARY_INCLUDE(this will be direct_dictionary)

(3) Sort columns support for int,long, bigint

(4) int, long, bigint can be DICTIONARY_EXCLUDE columns

(5) If the timestamp column to be partitioned, it should be a DICTIONARY_INCLUDE column.(Partition on timestamp column(dictionary_exclude column) will not throw any exception but not supported)

This closes #1322
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","36ceb59f014f7369575f433064e88aa07a7de48e","26","6","0","4786","531","116","4942","170","7754","1348","279","29","42","6015","0","25","25","516","apache-carbondata","36ceb59f014f7369575f433064e88aa07a7de48e","564","16.7","139","81402","46656","10501","5","1669","178","2190","20.3","3602","73","4.9","5","254","2376","20247","24","810","4006","47","2735","116","56","19638","1.4","373","517","1"
"apache-carbondata","cb51b86218cd815167f7c702b643ed0852c7f3dc","2017-09-04 00:38:44","[CARBONDATA-1316] Support drop partition function

This closes #1317
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","cb51b86218cd815167f7c702b643ed0852c7f3dc","26","6","0","4786","520","116","4944","169","7744","1344","279","29","42","5978","0","25","25","512","apache-carbondata","cb51b86218cd815167f7c702b643ed0852c7f3dc","564","16.8","136","81290","46545","10464","5","1663","178","2187","20.2","3602","73","4.9","5","252","2371","20189","25","820","4002","48","2685","116","58","19534","1.4","373","517","1"
"apache-carbondata","dd42277a0f545b2749ccc60beb52d077245622a6","2017-09-06 08:12:34","[CARBONDATA-1445] Fix update fail when carbon.update.persist.enable'='false'

The UDF for getting segementid while loading the data is not handled so when it needs to reexecute the rdd when persist enable is false it is not getting tupleId from carbon

This closes #1337
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","dd42277a0f545b2749ccc60beb52d077245622a6","26","6","0","4785","520","116","4944","169","7743","1344","279","29","42","5978","0","25","25","512","apache-carbondata","dd42277a0f545b2749ccc60beb52d077245622a6","564","16.8","136","81285","46541","10463","5","1663","178","2187","20.2","3601","73","4.9","5","252","2371","20187","25","820","4002","48","2685","116","58","19534","1.4","373","517","1"
"apache-carbondata","6f204376f880231c8f537052fe1b29008178aad8","2017-08-24 00:13:58","[CARBONDATA-1429] Add a value based compression for decimal data type when decimal is stored as Int or Long

Added a value based compression for decimal data type when decimal is stored as Int or Long

When decimal precision is <= 9, decimal values are stored in 4 bytes but they are not compressed further based on min and max values as compared with other primitive data type compression. Therefore now based on min and max value decimal data falling in Integer range will be further compressed as byte or short.
When decimal precision is <= 18, decimal values are stored in 8 bytes but they are not compressed further based on min and max values as compared with other primitive data type compression. Therefore now based on min and max value decimal data falling in Long range will be further compressed as byte, short or int.
Advantage: This will reduce the storage space thereby decreasing the IO time while decompressing the data.

This closes #1297
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","6f204376f880231c8f537052fe1b29008178aad8","26","6","0","4784","520","116","4942","169","7743","1344","279","29","42","5978","0","25","25","512","apache-carbondata","6f204376f880231c8f537052fe1b29008178aad8","564","16.8","136","81284","46540","10463","5","1663","178","2187","20.2","3601","73","4.9","5","252","2371","20187","25","820","4002","48","2685","116","58","19534","1.4","373","517","1"
"apache-carbondata","8791eabf0c6f2db385ed9c0886c0aa054a421b2f","2017-09-06 03:13:56","[CARBONDATA-1452] Issue with loading timestamp data beyond cutoff

(1)Removed timeValue>=0 condition => this condition will restrict loading proper data when the CARBON_CUTOFF_TIMESTAMP is set before 1970. In this case timeValue will always be < 0
(2) Added test case for the same

This closes #1355
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","8791eabf0c6f2db385ed9c0886c0aa054a421b2f","26","6","0","4708","521","114","4914","164","7608","1326","272","29","42","5910","0","25","25","514","apache-carbondata","8791eabf0c6f2db385ed9c0886c0aa054a421b2f","560","16.9","131","80463","45907","10280","5","1651","165","2165","20","3527","66","4.4","5","247","2344","19935","25","820","3503","48","2585","116","58","19201","1.4","363","514","1"
"apache-carbondata","642b4bf738a91b7d744d6ce619028efd0bef103f","2017-09-13 20:44:21","[SDV]Disable tests in other modules except cluster

This closes #1358
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","642b4bf738a91b7d744d6ce619028efd0bef103f","26","6","0","4708","521","114","4914","164","7608","1326","272","29","42","5910","0","25","25","514","apache-carbondata","642b4bf738a91b7d744d6ce619028efd0bef103f","560","16.9","131","80466","45910","10281","5","1651","165","2165","20","3527","66","4.4","5","247","2344","19937","25","820","3503","48","2585","116","58","19201","1.4","363","514","1"
"apache-carbondata","df95547d1b7e79c04407966a4f07ba6dbd6442da","2017-09-04 00:04:54","[CARBONDATA-1412] - Fixed bug related to incorrect behavior of delete functionality while using segment.starttime before '<any_date_value>'

This closes #1316
","refs/heads/master","sangeeta.gulia@knoldus.in","apache-carbondata","df95547d1b7e79c04407966a4f07ba6dbd6442da","26","6","0","4708","521","114","4914","164","7608","1326","272","29","42","5910","0","25","25","514","apache-carbondata","df95547d1b7e79c04407966a4f07ba6dbd6442da","560","16.9","131","80466","45910","10281","5","1651","165","2165","20","3527","66","4.4","5","247","2344","19937","25","820","3503","48","2585","116","58","19201","1.4","363","514","1"
"apache-carbondata","887310fc75e8c20c82929d2d92114887cecf44df","2017-09-10 02:27:09","[CARBONDATA-1472] Optimize memory and fix nosort queries

1.Use UnsafeManager for dimension chunks as well to avoid leaks
2.Fix filters on nosort columns.
3.Optimize scanRDD

This closes #1346
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","887310fc75e8c20c82929d2d92114887cecf44df","26","6","0","4708","521","114","4914","164","7608","1326","272","29","42","5910","0","25","25","514","apache-carbondata","887310fc75e8c20c82929d2d92114887cecf44df","560","16.9","131","80466","45910","10281","5","1651","165","2165","20","3527","66","4.4","5","247","2344","19937","25","820","3503","48","2585","116","58","19201","1.4","363","514","1"
"apache-carbondata","8c1ddbf2a6ba74a0a6d1333d95d0f6ad70297c01","2017-09-11 18:33:20","[CARBONDATA-1400] Fix bug of array column out of bound when writing carbondata file

If there is a big array in input csv file, when loading carbondata table, it may throw ArrayIndexOutOfBoundException because data exceed page size (32000 rows)

This PR fixed it by changing complex column encoding to DirectCompressionEncoding
This PR added a test case to test input data with big array

This closes #1273
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","8c1ddbf2a6ba74a0a6d1333d95d0f6ad70297c01","26","6","0","4709","521","114","4910","163","7609","1327","272","29","42","5908","0","25","25","514","apache-carbondata","8c1ddbf2a6ba74a0a6d1333d95d0f6ad70297c01","561","17","130","80481","45901","10276","5","1651","167","2165","20","3528","66","4.3","5","246","2343","19929","25","820","3497","48","2565","116","58","19220","1.4","363","515","1"
"apache-carbondata","2176a2f1d317763f5423dc1a5c254ee29e096c4b","2017-09-06 03:13:56","[CARBONDATA-1452] Issue with loading timestamp data beyond cutoff

While generating surrogate for timestamp dictionary column, we are casting the value to int. We are considering only the +ve values for generating dictionary, when the value is out of range,overflow occurs and cyclic rotation happens while casting, in the cyclic rotation there is possibility of getting +ve values in overflow cases too.

Lets say cutoff timestamp is 1970-01-01 05:30:00, so we will be able to load data 68 years from this date, not beyond 68 years

While loading 3007-01-01 00:00:00, dictionary generation will throw bad record exception as converting this data to int is -ve (overflows and cyclic rotation)

But while loading 4016-01-01 00:00:00, dictionary will be generated for this as converting this data to int is +ve (overflows and cyclic rotation) --> This data is loaded but not as actual value. Different timestamp will be loaded.

This PR has,

(1) Refactoring
(2) Checking overflow

This closes #1335
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","2176a2f1d317763f5423dc1a5c254ee29e096c4b","26","6","0","4736","521","115","4922","162","7625","1339","272","29","42","5925","0","25","25","518","apache-carbondata","2176a2f1d317763f5423dc1a5c254ee29e096c4b","567","16.9","129","80674","45949","10273","5","1654","162","2170","19.7","3540","66","4.3","5","245","2347","19919","25","820","3459","48","2545","116","57","19228","1.4","366","521","1"
"apache-carbondata","a8b3face6271562d415922af737e3e9b22d2fce0","2017-09-10 01:51:15","[CARBONDATA-1471] Replace BigDecimal to double to improve performance

While calculating adaptive floating encoding currently it uses BigDecimal for calculations, But it is very slow to use BIgdecimal as it creates many objects of BigDecimals. Alternatively, we can use double to improve the performance.

This closes #1345
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","a8b3face6271562d415922af737e3e9b22d2fce0","26","6","0","4736","521","115","4922","162","7625","1339","272","29","42","5925","0","25","25","518","apache-carbondata","a8b3face6271562d415922af737e3e9b22d2fce0","567","16.9","129","80677","45952","10275","5","1655","162","2171","19.7","3540","66","4.3","5","245","2348","19920","25","820","3459","48","2545","116","57","19243","1.4","366","521","1"
"apache-carbondata","0ab928e9c1730d69a3fcd1805c26ef1200214fc9","2017-09-07 22:27:42","[CARBONDATA-1462]Add an option 'carbon.update.storage.level' to support configuring the storage level when updating data with 'carbon.update.persist.enable'='true'

When updating data with 'carbon.update.persist.enable'='true'(default), the storage level of dataset is 'MEMORY_AND_DISK', it should support configuring the storage level to correspond to different environment.

This closes #1340
","refs/heads/master","441586683@qq.com","apache-carbondata","0ab928e9c1730d69a3fcd1805c26ef1200214fc9","26","6","0","4736","521","115","4922","162","7625","1339","272","29","42","5973","0","25","25","518","apache-carbondata","0ab928e9c1730d69a3fcd1805c26ef1200214fc9","567","16.9","129","80688","45963","10275","5","1655","162","2171","19.7","3540","66","4.3","5","245","2348","19920","25","820","3469","48","2545","116","57","19243","1.4","366","521","1"
"apache-carbondata","590bbb9b65efa3c801f677113fd05b24ab2d218b","2017-09-08 22:36:12","[CARBONDATA-1458] Fixed backward compatibility issue with decimal

The table loaded in 1.1 version cannot be queried in 1.2 branch as decimal min/max are hard coded to double.

This closes #1343
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","590bbb9b65efa3c801f677113fd05b24ab2d218b","26","6","0","4731","521","115","4914","162","7623","1336","272","29","42","5971","0","25","25","518","apache-carbondata","590bbb9b65efa3c801f677113fd05b24ab2d218b","567","16.9","129","80632","45933","10271","5","1654","162","2170","19.7","3538","66","4.3","5","245","2347","19908","25","820","3469","48","2545","116","57","19233","1.4","366","521","1"
"apache-carbondata","4030cfb27795e7d8dea6dadd7573bc0e3265a437","2017-08-11 23:12:26","[CARBONDATA-1379] Fixed Date range filter with cast not working

This closes #1254
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","4030cfb27795e7d8dea6dadd7573bc0e3265a437","26","6","0","4731","521","115","4914","162","7623","1336","272","29","42","5971","0","25","25","518","apache-carbondata","4030cfb27795e7d8dea6dadd7573bc0e3265a437","567","16.9","129","80632","45933","10271","5","1654","162","2170","19.7","3538","66","4.3","5","245","2347","19908","25","820","3469","48","2545","116","57","19233","1.4","366","521","1"
"apache-carbondata","435ea26eb8864db44b2e246d7f47a416d2dfdbd4","2017-09-06 02:55:33","[CARBONDATA-1451] Removing configuration for number_of_rows_per_blocklet_column_page

This closes #1334
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","435ea26eb8864db44b2e246d7f47a416d2dfdbd4","26","6","0","4734","518","115","4916","162","7623","1337","272","29","42","5972","0","25","25","518","apache-carbondata","435ea26eb8864db44b2e246d7f47a416d2dfdbd4","567","16.9","129","80633","45933","10271","5","1654","162","2170","19.7","3538","66","4.3","5","245","2347","19906","25","820","3469","48","2545","116","57","19232","1.4","366","521","1"
"apache-carbondata","1852e135ae07a343b1f2a270e20d21069bd23c27","2017-08-19 09:04:39","[CARBONDATA-1399]Enable findbugs

This closes #1272
","refs/heads/master","carbondatacontributions@gmail.com","apache-carbondata","1852e135ae07a343b1f2a270e20d21069bd23c27","26","4","0","4735","518","115","4928","162","7625","1337","272","29","42","5972","0","25","25","518","apache-carbondata","1852e135ae07a343b1f2a270e20d21069bd23c27","567","16.9","129","80684","45967","10275","5","1654","162","2170","19.7","3539","66","4.3","5","245","2347","19914","25","820","3469","48","2545","116","57","19236","1.4","366","521","1"
"apache-carbondata","a85b4f4b1dbf112ebe1bae192a33cdee6cac7baa","2017-08-30 23:08:45","[CARBONDATA-1436] optimize concurrent control for datamap

Synchronized by table.

Use double-checked locking to reduce lock overhead

This closes #1306
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","a85b4f4b1dbf112ebe1bae192a33cdee6cac7baa","26","4","0","4735","518","115","4928","162","7625","1337","272","29","42","5972","0","25","25","518","apache-carbondata","a85b4f4b1dbf112ebe1bae192a33cdee6cac7baa","567","16.9","129","80682","45965","10275","5","1654","162","2170","19.7","3539","66","4.3","5","245","2347","19914","25","820","3469","48","2545","116","57","19236","1.4","366","521","1"
"apache-carbondata","892f1209ea434314258aff12888cd898dc9b1854","2017-08-30 09:18:48","[CARBONDATA-1435] Fix reader backward compatible issue

Using master code, it is having NPE when reading old carbondata file. This PR fixed it

This closes #1302
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","892f1209ea434314258aff12888cd898dc9b1854","26","4","0","4735","518","115","4928","162","7626","1338","272","29","42","5971","0","25","25","518","apache-carbondata","892f1209ea434314258aff12888cd898dc9b1854","567","16.9","129","80674","45958","10274","5","1654","162","2170","19.7","3539","66","4.3","5","245","2346","19910","24","805","3469","47","2545","116","57","19236","1.4","366","521","1"
"apache-carbondata","2e04c357c72a09841a17427462f8967d2adb72c5","2017-07-12 08:17:15","[CARBONDATA-1305] Add limit for external dictionary values

Analysis: During dictionary creation the dictionary values are kept in a HashSet.

 When the size of hashset reaches more than 500000000 this exception is thrown.

Solution: Limit the dictionary values to 10000000

This closes #1166
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","2e04c357c72a09841a17427462f8967d2adb72c5","26","4","0","4729","518","114","4928","160","7618","1338","272","29","42","5965","0","25","25","518","apache-carbondata","2e04c357c72a09841a17427462f8967d2adb72c5","567","16.9","127","80639","45926","10263","5","1652","162","2167","19.7","3538","66","4.3","5","243","2341","19889","24","805","3469","47","2505","116","57","19202","1.4","365","521","1"
"apache-carbondata","ee5f65f7d3f8aa73eaef13758b06cfffca9f31af","2017-06-06 06:02:38","updated map for dictionary generator
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","ee5f65f7d3f8aa73eaef13758b06cfffca9f31af","26","4","0","4729","518","114","4926","160","7618","1338","272","29","42","5965","0","25","25","518","apache-carbondata","ee5f65f7d3f8aa73eaef13758b06cfffca9f31af","567","16.9","127","80634","45925","10263","5","1652","162","2167","19.7","3538","66","4.3","5","243","2341","19889","24","805","3469","47","2505","116","57","19202","1.4","365","521","1"
"apache-carbondata","baca6f925ad973864ff432dbaccd6a99df5ea363","2017-08-31 22:21:04","[CARBONDATA-1443] Schema storage has issue while converting table object to json string

Every table object converts to json and splits to small splits as there is limit in hive metastore of 4000. While splitting the json string code has problem so it could not get table and throws NPE

This closes #1314
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","baca6f925ad973864ff432dbaccd6a99df5ea363","26","4","0","4726","518","114","4926","160","7626","1336","272","29","42","5976","0","25","25","518","apache-carbondata","baca6f925ad973864ff432dbaccd6a99df5ea363","567","16.9","127","80672","45958","10270","5","1653","162","2168","19.7","3536","66","4.3","5","243","2342","19909","24","805","3469","47","2505","116","57","19214","1.4","365","521","1"
"apache-carbondata","bb0b34717db38a4bba15b39351895a2492d9e48c","2017-08-23 12:52:57","Fix Findbugs

This closes #1287
","refs/heads/master","carbondatacontributions@gmail.com","apache-carbondata","bb0b34717db38a4bba15b39351895a2492d9e48c","24","4","0","4727","518","114","4926","160","7621","1336","272","29","42","5982","0","25","25","518","apache-carbondata","bb0b34717db38a4bba15b39351895a2492d9e48c","567","16.9","127","80633","45947","10264","5","1651","162","2166","19.7","3534","66","4.3","5","243","2340","19905","24","805","3469","47","2505","116","57","19204","1.4","365","521","1"
"apache-carbondata","289232607ae51f350c0dc13dcbb9da7b95491c11","2017-08-18 02:04:50","[CARBONDATA-1393] Avoid to throw NPE when execute 'freeMemory' of UnsafeMemoryManager/UnsafeSortMemoryManager

UnsafeMemoryManager.freeMemoryAll(long taskId) may run before freeMemory(long taskId, MemoryBlock memoryBlock), so taskIdToMemoryBlockMap.get(taskId) will return null and then throw NPE.

This closes #1266
","refs/heads/master","441586683@qq.com","apache-carbondata","289232607ae51f350c0dc13dcbb9da7b95491c11","24","4","0","4727","518","114","4922","160","7622","1335","272","29","42","5982","0","25","25","518","apache-carbondata","289232607ae51f350c0dc13dcbb9da7b95491c11","567","16.9","129","80622","45936","10261","5","1653","162","2168","19.7","3534","66","4.3","5","246","2345","19895","24","810","3469","48","2545","116","57","19224","1.4","365","521","1"
"apache-carbondata","8ea7272d9a80821f941f8fedfbade70ee8c678dd","2017-08-23 21:31:44","[CARBONDATA-1407] Fix default end key bug for no-dictionary dimension

Now the default end key of no-dictionary dimension is 127 (0xEF), it should be 0xFF.

This closes #1290
","refs/heads/master","qiangcai@qq.com","apache-carbondata","8ea7272d9a80821f941f8fedfbade70ee8c678dd","24","4","0","4725","518","114","4922","160","7620","1335","272","29","42","5979","0","25","25","518","apache-carbondata","8ea7272d9a80821f941f8fedfbade70ee8c678dd","567","16.9","129","80592","45913","10254","5","1653","162","2168","19.7","3533","66","4.3","5","246","2345","19883","24","810","3465","48","2545","116","57","19224","1.4","365","521","1"
"apache-carbondata","4f7487decfa46627fda935e2772285e4986b69f1","2017-08-29 02:31:20","[CARBONDATA-1419] Support adaptive encoding for Double data type

Add a new encoding for Double data type:

AdaptiveFloatingCodec, it will multiple the column value by Math.pow(10, decimalCount) and do type cast from double to target data type like byte, short, int

This closes#1295
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","4f7487decfa46627fda935e2772285e4986b69f1","24","4","0","4725","518","114","4922","160","7620","1335","272","29","42","5979","0","25","25","518","apache-carbondata","4f7487decfa46627fda935e2772285e4986b69f1","567","16.9","129","80592","45913","10254","5","1653","162","2168","19.7","3533","66","4.3","5","246","2345","19883","24","810","3465","48","2545","116","57","19224","1.4","365","521","1"
"apache-carbondata","1e21cd1cfbaaf618457d3dcc02fea9f8b67f8d95","2017-08-29 11:01:13","[CARBONDATA-1364] Added the blocklet info to index file and make the datamap distributable with job

1.Added the blocklet info to the carbonindex file, so datamap not required to read each carbondata file footer to the blocklet information. This makes the datamap loading faster.

2. Made the data map distributable and added the spark job. So datamap pruning could happen distributable and pruned blocklet list would be sent to driver.

This closes #1179
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","1e21cd1cfbaaf618457d3dcc02fea9f8b67f8d95","24","4","0","4712","516","114","4920","157","7589","1337","272","29","42","5917","0","24","25","514","apache-carbondata","1e21cd1cfbaaf618457d3dcc02fea9f8b67f8d95","566","16.9","126","80446","45825","10234","5","1650","155","2161","19.7","3538","66","4.5","5","243","2335","19861","24","810","3628","48","2485","116","56","19081","1.4","362","520","1"
"apache-carbondata","03c1774f772f0dc3241886e272d10f12cdfc5c9f","2017-08-20 23:38:22","[CARBONDATA-1329] The first carbonindex file needs to be deleted during clean files operation

This closes #1277
","refs/heads/master","pannerselvam.velmyl@gmail.com","apache-carbondata","03c1774f772f0dc3241886e272d10f12cdfc5c9f","24","4","0","4696","517","114","4904","155","7559","1331","270","29","42","5903","0","24","25","514","apache-carbondata","03c1774f772f0dc3241886e272d10f12cdfc5c9f","565","16.9","124","80276","45702","10220","5","1649","155","2161","19.7","3534","67","4.5","5","241","2333","19805","24","810","3650","48","2445","116","57","19083","1.4","362","519","1"
"apache-carbondata","2a205a5546692b3fc78ce9e3d51ba085da5d7000","2017-07-30 01:12:18","[CARBONDATA-1342] Fixed bugs for spark conf property and debugging in windows

Fixes include:

In spark 2, spark conf once set in spark context cannot be modified with the same context again. Therefore removed setting property in spark conf and directly getting the property from carbon properties.
Fixed bug of running CarbonSessionExample in windows by removing File.Separator
Removed call of namenode after completion of each data load for renaming bad folders

This closes#1213
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","2a205a5546692b3fc78ce9e3d51ba085da5d7000","24","4","0","4696","517","114","4904","155","7558","1331","270","29","42","5905","0","24","25","514","apache-carbondata","2a205a5546692b3fc78ce9e3d51ba085da5d7000","565","17","124","80273","45699","10220","5","1650","155","2162","19.7","3533","67","4.5","5","241","2334","19804","24","810","3650","48","2445","116","57","19088","1.4","362","519","1"
"apache-carbondata","af5fdcb928e602d785167020a7263c24a85b7113","2017-08-18 08:46:23","[CARBONDATA-1326] Findbug fixes

This closes#1267
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","af5fdcb928e602d785167020a7263c24a85b7113","24","4","0","4696","517","114","4904","155","7558","1331","270","29","42","5905","0","24","25","514","apache-carbondata","af5fdcb928e602d785167020a7263c24a85b7113","565","17","124","80274","45700","10220","5","1650","155","2162","19.7","3533","67","4.5","5","241","2334","19804","24","810","3650","48","2445","116","57","19088","1.4","362","519","1"
"apache-carbondata","e6a4f6419823e9862503f4325b3cf70ab0e25550","2017-08-17 23:48:09","[CARBONDATA-1371] Support creating decoder based on encoding metadata

Currently, when writing column page into carbondata file, it is not leveraging encoder metadata in the DataChunk2 (page metadata). In this PR, it uses the encoder metadata, So that encoder and decoder can be extend in the future.

Modifications:

When writing column page, support writing codec metadata into DataChunk2, for both dimension and measure column.
When reading column page, support creating decoder base on metadata in the DataChunk2.
schema.thrift file is modified, 5 encodings are added:
	DIRECT_COMPRESS = 6;  // Identifies that a columm is encoded using DirectCompressCodec
	ADAPTIVE_INTEGRAL = 7; // Identifies that a column is encoded using AdaptiveIntegralCodec
	ADAPTIVE_DELTA_INTEGRAL = 8; // Identifies that a column is encoded using AdaptiveDeltaIntegralCodec
	RLE_INTEGRAL = 9;     // Identifies that a column is encoded using RLECodec
	DIRECT_STRING = 10;   // Stores string value and string length separately in page data
backward compatibility is ensure by reusing ValueEncoderMeta, all new codec meta is extended from ValueEncoderMeta

V1 and V2 writer and corresponding test case are removed.

CI will fail due to thrift file modification. Please test it with mvn clean verify -Pspark-2.1 -Pbuild-with-format command.

This closes #1248
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","e6a4f6419823e9862503f4325b3cf70ab0e25550","24","4","0","4696","517","114","4904","155","7559","1330","270","29","42","5905","0","24","25","514","apache-carbondata","e6a4f6419823e9862503f4325b3cf70ab0e25550","564","16.9","124","80281","45707","10221","5","1654","160","2166","19.7","3531","68","4.6","5","241","2338","19807","24","810","3697","48","2445","116","57","19163","1.4","362","519","1"
"apache-carbondata","d3a09e2790ec1d130feee78cdce5357a02c11628","2017-07-28 04:33:22","[CARBONDATA-1308] Added tableProvider to supply carbonTable wherever needed

This closes #1208
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","d3a09e2790ec1d130feee78cdce5357a02c11628","24","4","0","4614","520","111","4960","146","7552","1327","303","29","43","6084","0","25","24","498","apache-carbondata","d3a09e2790ec1d130feee78cdce5357a02c11628","557","17.2","114","80351","45588","10110","5","1646","152","2160","19.7","3487","64","4","5","230","2321","19862","24","805","3252","47","2245","112","69","18868","1.4","352","514","1"
"apache-carbondata","6488bc018a2ec715b31407d12290680d388a43b3","2017-06-29 09:00:32","[CARBONDATA-1250] Change default partition id & Add PartitionIdList in partitionInfo

This closes #1125
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","6488bc018a2ec715b31407d12290680d388a43b3","29","8","0","3925","479","85","4508","128","6617","1163","272","27","45","5332","0","23","19","478","apache-carbondata","6488bc018a2ec715b31407d12290680d388a43b3","512","18.8","107","73241","40089","8814","5","1483","123","1945","18.2","3097","53","3.8","5","228","2105","17340","24","830","2785","53","2110","107","65","16709","1.4","305","484","1"
"apache-carbondata","e3f98fa4378e068af5ccdcbb7b2ce1fdb4684601","2017-05-16 23:59:04","[CARBONDATA-1169] Support input read bytes size / Record metrics in the UI

Requirement : Support store input size / Record metrics for carbon UI

Solution : Adding input read bytes size / Records details in carbon UI
Example : Execute any query (select * query etc., )and check input size/ Records details in the UI

Input size metrics : We can use Hadoop FileSystem statistics but it is based on thread local variables, this is ok if the RDD computation chain is running on the same thread, but in carbon we are spawning multiple threads for computating Btree load, dictionary, read block etc.,. So we need to maintain one global map to track readbytes for all spawned threads & return total task readbytes, by summing all parent and spawned thread readbytes.

Record metrics: increment record count for each row

This closes #918
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","e3f98fa4378e068af5ccdcbb7b2ce1fdb4684601","24","4","0","4600","520","111","4898","146","7522","1324","303","29","43","6054","0","25","24","498","apache-carbondata","e3f98fa4378e068af5ccdcbb7b2ce1fdb4684601","555","17.3","114","80164","45462","10102","5","1645","152","2157","19.7","3483","64","4.1","5","230","2318","19840","24","805","3252","47","2245","112","69","18856","1.4","350","512","1"
"apache-carbondata","c81c3b1962155457d4fb42efe527ddeaa1896291","2017-08-20 19:42:30","[CARBONDATA-1376] Fix warn message when setting LOCK_TYPE to HDFSLOCK

This closes #1275
","refs/heads/master","chenerlu@huawei.com","apache-carbondata","c81c3b1962155457d4fb42efe527ddeaa1896291","24","4","0","4586","520","111","4888","145","7498","1322","303","29","43","6032","0","25","24","498","apache-carbondata","c81c3b1962155457d4fb42efe527ddeaa1896291","553","17.2","111","79932","45336","10075","5","1639","152","2150","19.7","3471","64","4.1","5","225","2307","19783","24","800","3252","46","2190","112","69","18790","1.4","350","511","1"
"apache-carbondata","500654e60d4fb7b1ab5eda39f29a415933838006","2017-08-17 06:44:48","[Review][CARBONDATA-1386] fixed findbugs errors in carbondata-core

fixed findbugs errors in carbondata-core

This closes #1263
","refs/heads/master","carbondatacontributions@gmail.com","apache-carbondata","500654e60d4fb7b1ab5eda39f29a415933838006","24","4","0","4586","520","111","4888","145","7498","1322","303","29","43","6032","0","25","24","498","apache-carbondata","500654e60d4fb7b1ab5eda39f29a415933838006","553","17.2","111","79933","45337","10075","5","1639","152","2150","19.7","3471","64","4.1","5","225","2307","19783","24","800","3252","46","2190","112","69","18794","1.4","350","511","1"
"apache-carbondata","2ee7775519cc86f51cb351e90f6b042d6db38adb","2017-08-11 08:00:20","[CARBONDATA-1373] Enhance update performance by increasing parallelism

+ Increase parallelism while processing one segment in update
+ Use partitionBy instead of groupby
+ Return directly for no-rows-update case
+ Add a property to configure the parallelism
+ Clean up local files after update (previous bugs)

This closes #1261
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","2ee7775519cc86f51cb351e90f6b042d6db38adb","27","6","0","4595","522","91","4900","143","7518","1333","303","29","45","5988","0","25","21","500","apache-carbondata","2ee7775519cc86f51cb351e90f6b042d6db38adb","552","17.3","113","79895","45299","10045","5","1651","152","2163","19.7","3463","64","4.1","5","232","2337","19769","34","970","3298","61","2220","112","71","18788","1.4","349","511","1"
"apache-carbondata","379d4f66c432c4ba942a6738967c4700e6de1ffa","2017-08-16 18:57:43","[CARBONDATA-1365] add RLE codec implementation

A new RLE codec for integral type is added
A test suite is added

Another PR is needed to modify encoding strategy to use this codec

This closes #1240
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","379d4f66c432c4ba942a6738967c4700e6de1ffa","27","6","0","4594","522","91","4896","143","7517","1332","303","29","45","5988","0","25","21","500","apache-carbondata","379d4f66c432c4ba942a6738967c4700e6de1ffa","552","17.3","113","79845","45269","10040","5","1651","152","2163","19.6","3462","64","4.1","5","232","2337","19757","34","970","3298","61","2220","112","71","18786","1.4","349","511","1"
"apache-carbondata","0e1d37e644731f122d74625f0f63ab74ffa6d1ad","2017-08-16 20:45:24","[BUGFIX] Fix ZERO_BYTE_ARRAY constant not found in codegen

CarbonCommonConstant.ZERO_BYTE_ARRAY is used in codegen, it should not be deleted. This PR add it back

This closes #1262
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","0e1d37e644731f122d74625f0f63ab74ffa6d1ad","27","6","0","4571","521","91","4886","142","7465","1320","303","29","45","5983","0","25","21","494","apache-carbondata","0e1d37e644731f122d74625f0f63ab74ffa6d1ad","548","17.3","112","79423","44952","9966","5","1646","152","2157","19.5","3438","64","4.2","5","231","2330","19600","34","970","3298","61","2200","112","70","18773","1.4","349","510","1"
"apache-carbondata","874764f95629c98d8f98a424ca742614e38f704f","2017-07-18 23:36:18","[CARBONDATA-940] alter table add/split partition for spark 2.1

add/split partition function

This closes #1192
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","874764f95629c98d8f98a424ca742614e38f704f","27","6","0","4571","521","91","4886","142","7465","1320","303","29","45","5983","0","25","21","494","apache-carbondata","874764f95629c98d8f98a424ca742614e38f704f","548","17.3","110","79418","44951","9966","5","1646","152","2157","19.5","3438","64","4.2","5","229","2328","19600","34","970","3298","61","2170","112","70","18773","1.4","349","510","1"
"apache-carbondata","d25fee225567bc96f65fab85c0859cfba7957da3","2017-07-27 23:04:12","[CARBONDATA-1326] Fixed normal/low priority findbug issues

This closes #1204
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","d25fee225567bc96f65fab85c0859cfba7957da3","27","6","0","4559","521","91","4868","142","7451","1317","303","29","45","5981","0","25","20","494","apache-carbondata","d25fee225567bc96f65fab85c0859cfba7957da3","547","17.3","109","79290","44877","9945","5","1644","152","2154","19.5","3430","64","4.2","5","228","2324","19573","34","970","3298","61","2150","112","70","18756","1.4","348","509","1"
"apache-carbondata","f089287cef1d685b81e8fa26868325503acdb635","2017-08-09 22:36:18","[CARBONDATA-1363] Add DataMapWriter interface

This closes #1238
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","f089287cef1d685b81e8fa26868325503acdb635","27","6","0","4556","523","91","4904","145","7458","1322","303","29","45","5981","0","25","20","498","apache-carbondata","f089287cef1d685b81e8fa26868325503acdb635","547","17.3","125","79309","44887","9946","5","1656","152","2170","19.5","3433","64","4.2","5","246","2355","19584","33","960","3302","60","2460","112","70","18993","1.4","350","509","1"
"apache-carbondata","0be69cd36cd875b35499ea78efb0297bf0377a93","2017-08-08 02:42:40","[CARBONDATA-1366]add an option 'carbon.global.sort.rdd.storage.level' to configure rdd storage level when sort_scope=global_sort

add an option 'carbon.global.sort.rdd.storage.level' for users to configure rdd storage level according to their different env, and the default value of this option is MEMORY_ONLY.

This closes #1245
","refs/heads/master","441586683@qq.com","apache-carbondata","0be69cd36cd875b35499ea78efb0297bf0377a93","27","6","0","4550","523","91","4902","148","7455","1319","303","29","45","5980","0","24","21","498","apache-carbondata","0be69cd36cd875b35499ea78efb0297bf0377a93","547","17.3","126","79299","44863","9948","5","1657","152","2170","19.5","3431","64","4.2","5","246","2356","19582","34","960","3302","60","2490","110","69","18998","1.4","350","509","1"
"apache-carbondata","7b5a1c3b9bbf19d209fee3c7a36ce0d9a4dce8b4","2017-08-08 10:53:07","[CARBONDATA-1368] Fix HDFS lock issue in SDV cluster

HDFS lock issue in SDV cluster
All runs share the same lock so resulting some test fails randomly. This PR fix takes the lock from the corresponding store location.

This closes #1247
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7b5a1c3b9bbf19d209fee3c7a36ce0d9a4dce8b4","27","6","0","4548","523","91","4896","148","7453","1316","303","29","45","5978","0","24","21","498","apache-carbondata","7b5a1c3b9bbf19d209fee3c7a36ce0d9a4dce8b4","547","17.3","126","79237","44824","9928","5","1655","152","2168","19.5","3429","64","4.2","5","246","2354","19571","34","960","3302","60","2490","110","69","18970","1.4","350","509","1"
"apache-carbondata","8c17ceeadffbb8525abc5dd5ea2435ec1bd1c864","2017-08-04 06:52:09","[CARBONDATA-1361] Reduced the SDV cluster time to 22 minutes

This closes #1225
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","8c17ceeadffbb8525abc5dd5ea2435ec1bd1c864","27","6","0","4548","523","91","4896","148","7452","1316","303","29","45","5978","0","24","21","498","apache-carbondata","8c17ceeadffbb8525abc5dd5ea2435ec1bd1c864","547","17.3","126","79229","44820","9927","5","1655","152","2168","19.5","3428","64","4.2","5","246","2354","19569","34","960","3302","60","2490","110","69","18970","1.4","350","509","1"
"apache-carbondata","382ff2f99e204a360ce926f902c51230f3a8cbc8","2017-08-02 23:17:15","[CARBONDATA-1356] Delete stale folder in insert overwrite

When user issued insert overwrite command, it should delete the file immediately to avoid stale folders.
This PR implements this behavior.

This closes #1227
","refs/heads/master","jacky.likun@qq.com","apache-carbondata","382ff2f99e204a360ce926f902c51230f3a8cbc8","27","6","0","4545","523","91","4896","148","7451","1315","303","29","46","5978","0","23","21","498","apache-carbondata","382ff2f99e204a360ce926f902c51230f3a8cbc8","547","17.3","126","79210","44803","9926","5","1655","152","2168","19.5","3427","64","4.2","5","246","2354","19565","34","960","3302","60","2490","110","69","18970","1.4","350","509","1"
"apache-carbondata","d2e70a464c342d8ef51331bd5bd195c3d76658a1","2017-08-01 03:05:13","[CARBONDATA-1353] Fixed measure filter tests with null

SDV tests are failing on measure filter http://144.76.159.231:8080/job/ApacheSDVTests/32/, now those are fixed

This closes #1222
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","d2e70a464c342d8ef51331bd5bd195c3d76658a1","27","6","0","4544","523","91","4896","148","7450","1315","303","29","46","5978","0","23","21","498","apache-carbondata","d2e70a464c342d8ef51331bd5bd195c3d76658a1","547","17.3","126","79204","44799","9925","5","1655","152","2168","19.5","3426","64","4.2","5","246","2354","19564","34","960","3302","60","2490","110","69","18970","1.4","350","509","1"
"apache-carbondata","f781337ea0a207a541c4d21a26286309225adfa8","2017-07-30 18:14:34","[CARBONDATA-1344] Remove useless variables

remove aggTables & aggTableName

This closes #1216
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","f781337ea0a207a541c4d21a26286309225adfa8","27","6","0","4546","523","91","4892","148","7450","1319","303","29","46","5973","0","23","21","498","apache-carbondata","f781337ea0a207a541c4d21a26286309225adfa8","547","17.3","126","79205","44795","9919","5","1650","151","2168","19.5","3427","64","4.2","5","246","2354","19562","34","960","3309","60","2490","110","69","18913","1.4","355","509","1"
"apache-carbondata","2c4e6c45ebb81396737de2ff8834af0b1faa9912","2017-08-01 01:42:16","[CARBONDATA-1351]Fix NPE of 'ThreadLocalTaskInfo.getCarbonTaskInfo()' When 'SORT_SCOPE'='GLOBAL_SORT' and 'enable.unsafe.columnpage'='true'

Set the CarbonTaskInfo in the method of 'ThreadLocalTaskInfo.getCarbonTaskInfo()' when 'threadLocal.get()' is null.

This closes #1221
","refs/heads/master","441586683@qq.com","apache-carbondata","2c4e6c45ebb81396737de2ff8834af0b1faa9912","27","6","0","4546","523","91","4892","148","7452","1319","303","29","46","5973","0","23","21","498","apache-carbondata","2c4e6c45ebb81396737de2ff8834af0b1faa9912","547","17.3","126","79212","44802","9920","5","1651","151","2169","19.5","3427","64","4.2","5","246","2355","19568","34","960","3309","60","2490","110","69","18914","1.4","355","509","1"
"apache-carbondata","1462495372f9c3f39852ab1a2797e72c714c3a79","2017-05-17 08:44:05","[CARBONDATA-1346] SDV cluster tests

New module spark-common-cluster-test has been added under integration module. Framework to run the tests in cluster is added here. And all the existing tests are migrated here.Following activities are done part of this PR.

This closes #1169
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","1462495372f9c3f39852ab1a2797e72c714c3a79","27","6","0","4546","523","91","4892","148","7451","1320","303","29","46","5973","0","23","21","498","apache-carbondata","1462495372f9c3f39852ab1a2797e72c714c3a79","547","17.3","126","79208","44798","9920","5","1651","151","2169","19.5","3427","64","4.2","5","246","2355","19564","34","960","3309","60","2490","110","69","18914","1.4","355","509","1"
"apache-carbondata","4e8350956efbba338316e3ead698106af7222f09","2017-07-31 00:15:13","Rebased with new master and fixed binary comparisions and comments.
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","4e8350956efbba338316e3ead698106af7222f09","27","6","0","4546","523","91","4894","148","7452","1320","303","29","46","5973","0","23","21","498","apache-carbondata","4e8350956efbba338316e3ead698106af7222f09","547","17.3","126","79198","44793","9920","5","1651","151","2169","19.5","3427","64","4.2","5","246","2355","19562","34","960","3309","60","2490","110","69","18914","1.4","355","509","1"
"apache-carbondata","266c473bab10476addf09b64f0db22d48ee6924a","2017-06-20 10:22:36","Measure Filter implementation

Measure Implementation for Include and Exclude Filter

RowLevel Measure Implementation

RowLevel Less LessThan Greater GreaterThan Implementation for measure

Rectify Datatype Conversion Measure

Rectify 1

Restructure Changes for Measure

Test Case Fixes
","refs/heads/master","sounakr@gmail.com","apache-carbondata","266c473bab10476addf09b64f0db22d48ee6924a","27","6","0","4535","526","91","4878","148","7491","1320","299","29","47","6016","0","24","22","494","apache-carbondata","266c473bab10476addf09b64f0db22d48ee6924a","547","17.4","126","79267","44822","9933","5","1682","159","2200","19.5","3423","64","4.4","5","245","2386","19587","35","940","3456","60","2490","110","66","19181","1.4","358","509","1"
"apache-carbondata","09f7cdd4480634407c09a0b4f515fda0d9c4911e","2017-06-28 08:45:50","[CARBONDATA-1238] Decouple the datatype convert from Spark code in core module

Decouple the datatype convert from Spark code in core module：
1.Use decimal(org.apache.spark.sql.types.Decimal.apply()) in Spark engine, use java's decimal in other engines.
2.Use org.apache.spark.unsafe.types.UTF8String in Spark engine, use String in other engines.

This closes #1197
","refs/heads/master","chenliang613@apache.org","apache-carbondata","09f7cdd4480634407c09a0b4f515fda0d9c4911e","27","6","0","4461","492","91","4754","147","7237","1270","297","29","46","5586","0","23","20","468","apache-carbondata","09f7cdd4480634407c09a0b4f515fda0d9c4911e","544","17.6","125","77651","43491","9550","5","1572","137","2070","18.9","3393","60","3.9","5","244","2250","18924","30","870","3002","55","2470","110","64","17963","1.4","340","506","1"
"apache-carbondata","74226907990cdee41a6ccbd69e2a813077792f89","2017-07-26 06:59:05","Resolve rebase conflicts when rebasing branch encoding_override onto master
","refs/heads/master","carbondatacontributions@gmail.com","apache-carbondata","74226907990cdee41a6ccbd69e2a813077792f89","27","6","0","4445","492","91","4752","147","7232","1268","297","29","46","5583","0","26","20","468","apache-carbondata","74226907990cdee41a6ccbd69e2a813077792f89","542","17.7","125","77570","43466","9556","5","1573","137","2069","19","3385","60","3.9","5","244","2249","18922","30","870","3002","55","2470","110","64","17973","1.4","338","504","1"
"apache-carbondata","a5af0ff238230bf64c8ac987bec9977d3f081ff2","2017-07-12 18:21:30","[CARBONDATA-1268] Support encoding strategy for dimension columns

In this PR, dimension encoding is changed to use EncodingStrategy instead of hard coding.
In future, dimension encoding can be adjusted by extending EncodingStrategy

This closes#1136
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","a5af0ff238230bf64c8ac987bec9977d3f081ff2","27","6","0","4430","492","91","4748","147","7222","1265","297","29","47","5559","0","27","21","470","apache-carbondata","a5af0ff238230bf64c8ac987bec9977d3f081ff2","542","17.7","125","77461","43376","9550","5","1569","137","2063","18.9","3385","60","3.9","5","244","2243","18872","30","870","3004","55","2470","110","64","17940","1.4","336","504","1"
"apache-carbondata","bc3e6843ee83370b6b20e5c9eef92f10667edbae","2017-07-03 17:12:13","[CARBONDATA-1098] Change page statistics use exact type and use column page in writer

This PR changes writer in data load:

make statistics collection use exact data type in schema instead of generic type
change consumer and writer to use EncodedTablePage instead of NodeHolder. EncodedTablePage is the output of TablePage.encode

This closes#1102
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","bc3e6843ee83370b6b20e5c9eef92f10667edbae","27","6","0","4396","498","91","4752","146","7179","1265","297","29","47","5553","0","27","22","474","apache-carbondata","bc3e6843ee83370b6b20e5c9eef92f10667edbae","536","17.8","124","77145","43170","9516","5","1572","135","2065","19.1","3361","58","3.9","5","243","2244","18832","30","870","2976","55","2450","110","63","17924","1.4","336","499","1"
"apache-carbondata","2340cc49d7592bafc4a5dc0e4bae11aab746365f","2017-07-17 09:27:50","[CARBONDATA-1313] Remove unnecessary measure statistics

Decimal count and unique value is not used, so removing them in measure statistics

This closes #1181
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","2340cc49d7592bafc4a5dc0e4bae11aab746365f","27","6","0","4265","501","92","4706","140","7143","1229","283","29","45","5589","0","25","21","500","apache-carbondata","2340cc49d7592bafc4a5dc0e4bae11aab746365f","543","18.2","118","76945","42570","9344","5","1547","131","2039","18.5","3335","56","3.8","5","240","2213","18526","29","870","2954","56","2330","110","69","17586","1.4","328","506","1"
"apache-carbondata","ded8b4162f1fc156355a183792d8077e9db794c6","2017-07-25 04:17:53","[CARBONDATA-1281] Support multiple temp dirs for writing files while loading data

This closes #1198
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","ded8b4162f1fc156355a183792d8077e9db794c6","29","6","0","4270","503","92","4708","140","7152","1229","283","29","45","5594","0","25","21","504","apache-carbondata","ded8b4162f1fc156355a183792d8077e9db794c6","543","18.2","118","77018","42626","9350","5","1551","131","2044","18.5","3339","56","3.8","5","243","2221","18569","29","885","2954","59","2330","110","69","17602","1.4","329","506","1"
"apache-carbondata","79feac96ae789851c5ad7306a7acaaba25d8e6c9","2017-07-27 05:38:48","Rebase datamap branch onto master

This closes #1196
","refs/heads/master","raghunandan.subramanya@gmail.com","apache-carbondata","79feac96ae789851c5ad7306a7acaaba25d8e6c9","29","6","0","4270","503","92","4704","140","7148","1227","283","29","45","5593","0","25","21","504","apache-carbondata","79feac96ae789851c5ad7306a7acaaba25d8e6c9","543","18.2","118","76973","42601","9345","5","1550","131","2043","18.5","3337","56","3.8","5","243","2220","18556","29","885","2954","59","2330","110","69","17590","1.4","329","506","1"
"apache-carbondata","b6812449a4040dc5d3454cd0d6dd38f07be2854c","2017-06-17 10:23:57","[CARBONDATA-1232] Datamap implementation for Blocklet

This closes #1099
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b6812449a4040dc5d3454cd0d6dd38f07be2854c","29","6","0","4267","503","92","4708","138","7141","1223","283","29","45","5582","0","25","21","504","apache-carbondata","b6812449a4040dc5d3454cd0d6dd38f07be2854c","543","18.2","119","76932","42565","9333","5","1551","131","2043","18.4","3332","56","3.9","5","244","2221","18540","29","885","2978","59","2350","110","69","17592","1.4","328","506","1"
"apache-carbondata","92fe63cf3a1378c68623bb8f97b72bc9d2a75d94","2017-06-28 03:33:03","Optimizing decimal datatype

Optimized big decimal to use less space

Fixed comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","92fe63cf3a1378c68623bb8f97b72bc9d2a75d94","29","8","0","4042","495","90","4530","131","6823","1182","272","27","45","5391","0","25","18","486","apache-carbondata","92fe63cf3a1378c68623bb8f97b72bc9d2a75d94","524","18.5","112","74507","41009","9041","5","1505","129","1975","18.4","3177","55","4","5","237","2142","17821","24","850","2945","55","2210","107","66","17139","1.4","310","491","1"
"apache-carbondata","2b66476dd643bad15aa4713b84bc84afe2233c35","2017-07-21 06:48:20","[CARBONDATA-1326] Fixed high priority findbug issues

Fixed high priority findbug issues in the code

This closes #1191
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","2b66476dd643bad15aa4713b84bc84afe2233c35","29","8","0","4042","495","90","4526","131","6823","1182","272","27","45","5391","0","25","18","486","apache-carbondata","2b66476dd643bad15aa4713b84bc84afe2233c35","524","18.5","111","74507","41009","9041","5","1504","129","1973","18.4","3177","55","4","5","236","2139","17821","24","850","2945","55","2190","107","66","17127","1.4","309","491","1"
"apache-carbondata","aadbd5c8868d9d61543213e953b07163bf2c6159","2017-07-20 02:27:21","[CARBONDATA-1322] Insert overwrite support and force clean up files and clean up in progress files support added

1. Added support for LOAD OVERWRITE and INSERT OVERWRITE in carbon load
2. Added support for force clean table to remove the table with force from disk
3. Cleanup the inprogress files while driver is initializing

This closes #1189
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","aadbd5c8868d9d61543213e953b07163bf2c6159","29","8","0","4046","495","90","4530","131","6824","1186","272","27","45","5385","0","25","19","484","apache-carbondata","aadbd5c8868d9d61543213e953b07163bf2c6159","524","18.5","112","74486","40989","9033","5","1507","129","1976","18.4","3177","55","4","5","237","2144","17817","25","860","2945","56","2210","107","65","17159","1.4","310","491","1"
"apache-carbondata","1f83125f12b14d18ae567e34768d22e280f1d32c","2017-07-19 06:47:23","[CARBONDATA-1319] Support concurrent data load on the same table

Modified code to support concurrent data load. Changes done

Removed meta.lock file
Modified code to add for the new load and generate segment ID inside table status lock

This closes #1187
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","1f83125f12b14d18ae567e34768d22e280f1d32c","29","8","0","4042","495","90","4526","131","6822","1186","272","27","45","5384","0","25","19","484","apache-carbondata","1f83125f12b14d18ae567e34768d22e280f1d32c","524","18.5","112","74464","40974","9027","5","1507","129","1976","18.4","3176","55","4","5","237","2144","17809","25","860","2945","56","2210","107","65","17157","1.4","310","491","1"
"apache-carbondata","c3b266635e5275832792ea000736adf57117bab0","2017-07-13 22:42:57","[CARBONDATA-1311] Added carbon storelocation to spark warehouse. And extracted storelocation out of metastore

1. Changed default storelocation to sparkwouse, ,so if user does not provide storelocation then it chooses sparkwarelocation as store location.
2. Changed file metastore and avoid reading all schema files once keep it in memory, instead implemented cache based storage where it reads when request comes.
3. Extracted store location out of metastore and refactored carbonmetastore.

This closes #1176
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","c3b266635e5275832792ea000736adf57117bab0","29","8","0","4033","494","90","4524","131","6816","1185","272","27","45","5374","0","25","19","484","apache-carbondata","c3b266635e5275832792ea000736adf57117bab0","523","18.5","111","74388","40938","9020","5","1507","129","1976","18.4","3174","55","4","5","236","2143","17793","25","860","2945","56","2190","107","65","17157","1.4","310","490","1"
"apache-carbondata","9a8fac30316a4783dfa521dc81f09c4ee76fa322","2017-07-08 04:44:04","[CARBONDATA-1284]Implement hive based schema storage in carbon

This closes #1149
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9a8fac30316a4783dfa521dc81f09c4ee76fa322","29","8","0","4034","494","88","4524","131","6812","1185","272","27","45","5375","0","25","19","484","apache-carbondata","9a8fac30316a4783dfa521dc81f09c4ee76fa322","523","18.5","111","74387","40939","9020","5","1507","129","1976","18.4","3174","55","4","5","236","2143","17790","25","860","2945","56","2190","107","65","17153","1.4","310","490","1"
"apache-carbondata","ac5aee187f4f1c3332226435ac9d1aa7c396ae29","2017-07-08 02:34:44","[CARBONDATA-1286] Change Query related RDD to use TableInfo

This closes #1146
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","ac5aee187f4f1c3332226435ac9d1aa7c396ae29","29","8","0","4024","494","85","4518","130","6772","1183","272","27","45","5365","0","24","19","484","apache-carbondata","ac5aee187f4f1c3332226435ac9d1aa7c396ae29","523","18.6","110","74252","40821","8997","5","1505","129","1971","18.4","3166","55","4","5","235","2137","17719","25","860","2945","56","2170","107","65","17108","1.4","307","490","1"
"apache-carbondata","01589684f2804527872a791c8a0058581e1bc760","2017-07-05 19:41:55","[CARBONDATA-1273] String datatype will be no dictionary column by default

This closes #1144
","refs/heads/master","david.caiq@gmail.com","apache-carbondata","01589684f2804527872a791c8a0058581e1bc760","29","8","0","4002","488","85","4514","128","6751","1181","272","27","45","5362","0","24","19","484","apache-carbondata","01589684f2804527872a791c8a0058581e1bc760","521","18.6","108","74021","40624","8928","5","1503","129","1969","18.3","3152","55","4","5","233","2133","17591","25","860","2945","56","2130","107","65","16994","1.4","307","488","1"
"apache-carbondata","9e064eee9f6a8d7f36de3f9bded1081407d16c34","2017-06-28 03:33:03","Optimizing decimal datatype

Optimized big decimal to use less space

Fixed comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9e064eee9f6a8d7f36de3f9bded1081407d16c34","29","8","0","4007","488","85","4532","128","6756","1184","272","27","45","5362","0","24","19","484","apache-carbondata","9e064eee9f6a8d7f36de3f9bded1081407d16c34","521","18.6","108","74081","40670","8933","5","1503","129","1969","18.3","3154","55","4","5","233","2133","17606","25","860","2945","56","2130","107","65","16998","1.4","307","488","1"
"apache-carbondata","c7aba5e5d831440c438e6448b00bbd98e7a5acd6","2017-07-18 08:45:23","[CARBONDATA-1312] fix list partition compare issue

This closes #1183
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","c7aba5e5d831440c438e6448b00bbd98e7a5acd6","29","8","0","3941","482","85","4514","128","6634","1171","272","27","45","5340","0","23","19","478","apache-carbondata","c7aba5e5d831440c438e6448b00bbd98e7a5acd6","515","18.7","106","73620","40326","8856","5","1492","129","1956","18.2","3108","55","4","5","230","2116","17450","24","845","2935","54","2090","107","65","16914","1.4","305","487","1"
"apache-carbondata","df22368d98f0390cc7f9c1289a81257adf4509a6","2017-07-19 01:12:52","[CARBONDATA-1318]Fixed Concurrent table data loading unsafe memory issue

Fixed task cancellation leak issue
Fixed task cleanup issue in data loading
Fixed Concurrent table data loading unsafe memory issue
 @CarbonDataQA

This closes#1185
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","df22368d98f0390cc7f9c1289a81257adf4509a6","29","8","0","3941","479","85","4514","128","6639","1171","272","27","45","5340","0","23","19","478","apache-carbondata","df22368d98f0390cc7f9c1289a81257adf4509a6","515","18.8","106","73601","40306","8850","5","1492","129","1956","18.2","3108","55","4","5","230","2116","17437","24","845","2935","54","2090","107","65","16910","1.4","305","487","1"
"apache-carbondata","52ab730979509bb49dcf80ab7e0ffc1ab571bf9f","2017-07-13 04:12:08","[CARBONDATA-1306] Fixed carbondata crash after using short-int datatype

This closes #1171
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","52ab730979509bb49dcf80ab7e0ffc1ab571bf9f","29","8","0","3951","479","85","4510","128","6638","1169","272","27","45","5331","0","23","20","478","apache-carbondata","52ab730979509bb49dcf80ab7e0ffc1ab571bf9f","521","18.8","107","73399","40169","8823","5","1483","123","1941","18.2","3110","53","3.8","5","228","2101","17358","24","830","2785","53","2110","106","65","16676","1.4","301","486","1"
"apache-carbondata","1a35cfb90d0f4a4da05ec80f7a5c192f6832b36d","2017-07-10 05:17:16","[CARBONDATA-1283] Carbon should continue with default value for wrong value in configured property

This closes #1155
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","1a35cfb90d0f4a4da05ec80f7a5c192f6832b36d","29","8","0","3951","479","85","4510","128","6638","1169","272","27","45","5331","0","23","20","478","apache-carbondata","1a35cfb90d0f4a4da05ec80f7a5c192f6832b36d","521","18.8","107","73396","40166","8821","5","1483","123","1941","18.2","3110","53","3.8","5","228","2101","17356","24","830","2785","53","2110","106","65","16676","1.4","301","486","1"
"apache-carbondata","cbe141976a53a558b84d6e31baf3ec54a9bc38cc","2017-07-05 23:23:03","[CARBONDATA-1271] Enhanced Performance for Hive Integration with Carbondata

This closes #1142
","refs/heads/master","bhavya@knoldus.com","apache-carbondata","cbe141976a53a558b84d6e31baf3ec54a9bc38cc","29","8","0","3954","479","83","4492","128","6625","1166","272","27","45","5323","0","23","20","478","apache-carbondata","cbe141976a53a558b84d6e31baf3ec54a9bc38cc","521","18.8","107","73265","40060","8795","5","1482","123","1938","18.1","3104","53","3.8","5","228","2098","17313","24","830","2785","53","2110","106","65","16638","1.4","299","486","1"
"apache-carbondata","285ce72d4c9b3364bbdc454f4b6b331b3caa42db","2017-07-08 03:16:25","[CARBONDATA-1277] Dictionary generation failure due to hdfs lease expiry

This closes #1147
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","285ce72d4c9b3364bbdc454f4b6b331b3caa42db","29","8","0","3954","479","83","4492","128","6625","1166","272","27","45","5322","0","23","20","478","apache-carbondata","285ce72d4c9b3364bbdc454f4b6b331b3caa42db","521","18.8","107","73263","40058","8794","5","1481","123","1937","18.1","3104","53","3.8","5","228","2097","17312","24","830","2785","53","2110","106","65","16627","1.4","299","486","1"
"apache-carbondata","403c3d9b41e166311ac45ec33b375cbecc8c4741","2017-07-09 23:42:10","[CARBONDATA-1229] acquired meta.lock during table drop

This closes #1153
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","403c3d9b41e166311ac45ec33b375cbecc8c4741","29","8","0","3942","477","82","4470","128","6608","1159","272","27","45","5315","0","23","20","478","apache-carbondata","403c3d9b41e166311ac45ec33b375cbecc8c4741","520","18.8","107","73002","39874","8751","5","1474","123","1929","18","3097","53","3.8","5","227","2088","17233","24","815","2785","52","2110","106","65","16517","1.4","298","485","1"
"apache-carbondata","c6bc1f07180c4740ba9b3e518ead34daa093be1c","2017-07-05 06:00:45","[CARBONDATA-1267] Add short_int case branch in DeltaIntegalCodec

This closes #1139
","refs/heads/master","xuchuanyin@hust.edu.cn","apache-carbondata","c6bc1f07180c4740ba9b3e518ead34daa093be1c","29","8","0","3941","477","82","4470","127","6605","1159","272","27","45","5313","0","23","20","478","apache-carbondata","c6bc1f07180c4740ba9b3e518ead34daa093be1c","520","18.8","106","72978","39860","8748","5","1474","123","1929","18","3096","53","3.8","5","226","2087","17227","24","815","2785","52","2090","106","65","16517","1.4","298","485","1"
"apache-carbondata","659036fee8dd1645eea31eeab0423bd0d5c03f19","2017-06-28 21:43:51","fix null pointer exception by changing null to empty array
","refs/heads/master","jelly.guodong.jin@gmail.com","apache-carbondata","659036fee8dd1645eea31eeab0423bd0d5c03f19","29","8","0","3941","477","82","4470","127","6605","1159","272","27","45","5313","0","23","20","478","apache-carbondata","659036fee8dd1645eea31eeab0423bd0d5c03f19","520","18.8","106","72966","39848","8744","5","1474","123","1929","18","3096","53","3.8","5","226","2087","17219","24","815","2779","52","2090","106","65","16517","1.4","298","485","1"
"apache-carbondata","e9329ee7c1adc913d6e65c970e6312a5b18c6ec2","2017-06-29 02:48:20","Fixed described formatted for sort_columns after alter
","refs/heads/master","aayushmantri@gmail.com","apache-carbondata","e9329ee7c1adc913d6e65c970e6312a5b18c6ec2","29","8","0","3941","477","82","4470","127","6605","1159","272","27","45","5313","0","23","20","478","apache-carbondata","e9329ee7c1adc913d6e65c970e6312a5b18c6ec2","520","18.8","106","72966","39848","8744","5","1478","123","1933","18","3096","53","3.8","5","226","2091","17219","24","815","2779","52","2090","106","65","16637","1.4","298","485","1"
"apache-carbondata","5f9741ebcb5b2b606f4d710785ce97c4d6b49229","2017-06-30 04:51:19","[CARBONDATA-1253] Sort_columns should not support float,double,decimal

This closes #1122
","refs/heads/master","qiangcai@qq.com","apache-carbondata","5f9741ebcb5b2b606f4d710785ce97c4d6b49229","29","8","0","3941","477","82","4468","127","6601","1159","272","27","45","5313","0","23","20","478","apache-carbondata","5f9741ebcb5b2b606f4d710785ce97c4d6b49229","520","18.8","106","72947","39838","8741","5","1477","123","1931","18","3095","53","3.8","5","226","2089","17212","24","815","2779","52","2090","106","65","16634","1.4","297","485","1"
"apache-carbondata","03d484abf2cf5c57aeda11ca9355cfbfbdf137c2","2017-06-28 12:45:21","Rectify Vector Buffer Calculation
","refs/heads/master","sounakr@gmail.com","apache-carbondata","03d484abf2cf5c57aeda11ca9355cfbfbdf137c2","29","8","0","3942","491","82","4472","127","6611","1159","272","27","45","5314","0","23","20","480","apache-carbondata","03d484abf2cf5c57aeda11ca9355cfbfbdf137c2","520","18.8","108","73064","39905","8769","5","1478","123","1932","18.1","3101","53","3.8","5","228","2092","17245","24","815","2779","52","2120","106","65","16658","1.4","297","485","1"
"apache-carbondata","fdb672ad946c0fe5b9982aee9b09717db36a54f7","2017-06-30 03:27:08","fix unsafe column page bug
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","fdb672ad946c0fe5b9982aee9b09717db36a54f7","29","8","0","3910","490","81","4472","127","6578","1153","272","27","45","5314","0","23","20","480","apache-carbondata","fdb672ad946c0fe5b9982aee9b09717db36a54f7","520","18.9","108","72901","39777","8705","5","1475","121","1928","17.9","3069","51","3.8","5","228","2088","17213","24","815","2749","52","2120","106","65","16537","1.4","296","485","1"
"apache-carbondata","c671c5b60ad4989643e9b6f92540b60c2c540145","2017-06-29 05:29:33","[CARBONDATA-1236] Support absolute path without scheme in loading - change in logic
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","c671c5b60ad4989643e9b6f92540b60c2c540145","29","8","0","3910","490","81","4472","127","6574","1153","272","27","45","5316","0","23","20","480","apache-carbondata","c671c5b60ad4989643e9b6f92540b60c2c540145","520","18.9","108","72879","39770","8704","5","1475","121","1928","17.9","3068","51","3.8","5","228","2088","17207","24","815","2749","52","2120","106","65","16537","1.4","296","485","1"
"apache-carbondata","aecf496eda9c1b3ae854a16d4dcbfb1c7e3701e8","2017-06-06 20:51:08","fix compact bug for partition table
","refs/heads/master","david.caiq@gmail.com","apache-carbondata","aecf496eda9c1b3ae854a16d4dcbfb1c7e3701e8","29","8","0","3910","491","81","4472","127","6574","1153","272","27","45","5316","0","23","20","480","apache-carbondata","aecf496eda9c1b3ae854a16d4dcbfb1c7e3701e8","520","18.9","108","72879","39771","8703","5","1476","121","1929","17.9","3067","51","3.8","5","228","2089","17206","24","815","2749","52","2120","106","65","16549","1.4","296","485","1"
"apache-carbondata","377dee94780a4fe6073c855cc980ac234a576bf6","2017-06-14 08:31:07","lru object size calculation
","refs/heads/master","raghunandan.subramanya@gmail.com","apache-carbondata","377dee94780a4fe6073c855cc980ac234a576bf6","29","8","0","3909","491","81","4472","127","6574","1153","272","27","45","5316","0","23","20","480","apache-carbondata","377dee94780a4fe6073c855cc980ac234a576bf6","520","18.9","108","72875","39768","8702","5","1476","121","1929","17.9","3066","51","3.8","5","228","2089","17205","24","815","2749","52","2120","106","65","16549","1.4","296","485","1"
"apache-carbondata","e54456fa66350e045223dee96d3a584c1b9a61d8","2017-06-21 04:23:49","[CARBONDATA-1207] Resource leak problem in CarbonDictionaryWriter
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","e54456fa66350e045223dee96d3a584c1b9a61d8","29","8","0","3883","491","81","4424","126","6543","1149","272","27","45","5312","0","23","20","480","apache-carbondata","e54456fa66350e045223dee96d3a584c1b9a61d8","519","18.8","107","72547","39582","8671","5","1473","119","1917","17.9","3053","49","3.7","5","228","2076","17138","23","815","2683","52","2100","106","64","16461","1.4","288","484","1"
"apache-carbondata","82ef875ef2163d4fdc7f0d0a098d24c3a539eb55","2017-06-28 02:14:54","[CARBONDATA-1236] Support absolute path without scheme in loading - hdfs path issue fix
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","82ef875ef2163d4fdc7f0d0a098d24c3a539eb55","29","8","0","3883","491","81","4424","126","6543","1149","272","27","45","5312","0","23","20","480","apache-carbondata","82ef875ef2163d4fdc7f0d0a098d24c3a539eb55","519","18.8","107","72541","39576","8671","5","1473","119","1917","17.9","3053","49","3.7","5","228","2076","17136","23","815","2683","52","2100","106","64","16461","1.4","288","484","1"
"apache-carbondata","eadfea789b0fd63c4adcd4f7f335530a98dfbb78","2017-06-27 01:54:54","use raw compression
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","eadfea789b0fd63c4adcd4f7f335530a98dfbb78","29","8","0","3883","491","81","4424","126","6543","1149","272","27","45","5312","0","23","20","480","apache-carbondata","eadfea789b0fd63c4adcd4f7f335530a98dfbb78","519","18.8","107","72541","39576","8671","5","1473","119","1917","17.9","3053","49","3.7","5","228","2076","17136","23","815","2683","52","2100","106","64","16461","1.4","288","484","1"
"apache-carbondata","47a05a8adb027b2ac8c8cc6d83e378564c4c90b9","2017-06-27 02:56:12","[CARBONDATA-1236] Support absolute path without scheme in loading
","refs/heads/master","dhatcha.official@gmail.com","apache-carbondata","47a05a8adb027b2ac8c8cc6d83e378564c4c90b9","29","8","0","3901","494","82","4426","137","6579","1152","272","27","45","5346","0","23","20","482","apache-carbondata","47a05a8adb027b2ac8c8cc6d83e378564c4c90b9","520","18.8","118","72750","39729","8735","5","1476","122","1925","18","3055","50","3.7","5","239","2095","17200","23","815","2716","52","2320","106","65","16573","1.4","292","485","1"
"apache-carbondata","39644b5e003bddf89c80ad539506b4a29b04b526","2017-06-12 06:03:22","1. Refactored the bad record code, by default the bad record path will be empty, if bad record logger is    enabled or action is redirect and bad record path is not configured then data-load will fail. 2. Support dynamic set command for some of load options 3. fixed test cases 4. Added validation for the supported property in the dynamic set command 5. Change table delete behavior // now the bad record would not be deleted ion table drop 6. added test case for bad record path in load option 7. fixed failing test cases 8. Added ""carbon.options."" in load options parameters
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","39644b5e003bddf89c80ad539506b4a29b04b526","29","8","0","3901","494","82","4426","137","6577","1151","272","27","45","5345","0","23","20","482","apache-carbondata","39644b5e003bddf89c80ad539506b4a29b04b526","520","18.8","118","72745","39724","8734","5","1476","122","1925","18","3055","50","3.7","5","239","2095","17197","23","815","2716","52","2320","106","65","16572","1.4","292","485","1"
"apache-carbondata","95ce1da1e6a828255ca6385ae5ab16706e66483f","2017-06-12 05:36:25","Added set/reset commands in carbon to update/reset properties dynamically
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","95ce1da1e6a828255ca6385ae5ab16706e66483f","29","8","0","3887","490","82","4384","137","6563","1068","272","27","44","5334","0","23","20","480","apache-carbondata","95ce1da1e6a828255ca6385ae5ab16706e66483f","516","18.9","117","72241","39437","8673","5","1466","122","1909","18","3045","50","3.8","5","236","2078","17126","23","815","2716","52","2300","105","65","16423","1.4","288","481","1"
"apache-carbondata","28e2e171db578e2467be55939d2da9a5f1b70d09","2017-05-18 02:34:17","Adding session based properties

Added set command in carbon to update properties dynamically
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","28e2e171db578e2467be55939d2da9a5f1b70d09","29","8","0","3883","490","82","4382","137","6562","1067","272","27","44","5334","0","23","20","480","apache-carbondata","28e2e171db578e2467be55939d2da9a5f1b70d09","515","18.9","117","72206","39426","8671","5","1464","122","1907","18.1","3043","50","3.8","5","236","2076","17124","23","815","2716","52","2300","105","65","16392","1.4","288","480","1"
"apache-carbondata","917dae9ca9a36bd861fd1f72ec02e6687fbdf3f6","2017-06-22 23:15:10","Problem: Failure in data load when we first load the bad record and then valid record and bad record action is set to Fail

Analysis:
When we load bad record into the table and bad record action is set to ""FAIL"", then data load will fail. During load a bad record logger static map is maintained which holds the key for bad record. When data load fails due to bad record exception is thrown and key from bad record logger static map is not cleared because of which when valid data is loaded next time data load fails because the key still exists in the map.

Fix: Remove the bad record logger key from map even though data load fails.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","917dae9ca9a36bd861fd1f72ec02e6687fbdf3f6","29","8","0","3877","490","82","4378","137","6553","1066","272","27","44","5334","0","23","20","480","apache-carbondata","917dae9ca9a36bd861fd1f72ec02e6687fbdf3f6","514","18.8","117","72112","39376","8661","5","1464","122","1907","18.1","3036","50","3.8","5","236","2076","17103","23","815","2716","52","2300","105","65","16392","1.4","288","479","1"
"apache-carbondata","434f32ddbbd56cf59cbb8ca54229ad17451d2491","2017-06-24 03:38:35","fix double issue
","refs/heads/master","qiangcai@qq.com","apache-carbondata","434f32ddbbd56cf59cbb8ca54229ad17451d2491","29","8","0","3877","490","82","4378","137","6553","1066","272","27","44","5334","0","23","20","480","apache-carbondata","434f32ddbbd56cf59cbb8ca54229ad17451d2491","514","18.8","117","72112","39376","8661","5","1464","122","1907","18.1","3036","50","3.8","5","236","2076","17103","23","815","2716","52","2300","105","65","16392","1.4","288","479","1"
"apache-carbondata","1d8254b85c7a0613e2fc2698d2a642fc52b6335e","2017-06-17 01:07:08","fixed codec for UpscaleFloatingCodec
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","1d8254b85c7a0613e2fc2698d2a642fc52b6335e","29","8","0","3901","491","83","4380","148","6591","1070","272","27","44","5302","0","23","20","480","apache-carbondata","1d8254b85c7a0613e2fc2698d2a642fc52b6335e","515","18.8","128","72307","39517","8708","5","1466","132","1912","18.1","3041","51","4","5","247","2092","17157","23","815","2878","52","2520","105","65","16556","1.4","291","480","1"
"apache-carbondata","83aae9420b408540db217283e288c311179b0da6","2017-06-22 02:07:13","Problem:
1. Row count percentage not required with high cardinality threshold check
2. IUD returning incorrect results in case of update on high cardinality column

Analysis:
1. In case a column is identified as high cardinality column still it is not getting converted to no dictionary column because of another parameter check called rowCountPercentage. Default value of rowCountPercentage is 80%. Due to this even though high cardinality column is identified, if it is less than 80% of the total number of rows it will be treated as dictionary column. This can still lead to executor lost failure due to memory constraints.
2. RLE on a column is not being set correctly and due to incorrect code design RLE applicable on a column is decided by a different part of code from the one which is actually applying the RLE on a column. Because of this Footer is getting filled with incorrect RLE information and query is failing.

Fix:
1. Remove an unwanted check for rowCountPercentage.
2. RLE applicability on a column should be decided from a common place in the code.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","83aae9420b408540db217283e288c311179b0da6","29","8","0","3892","487","83","4378","148","6575","1070","270","27","44","5296","0","23","20","474","apache-carbondata","83aae9420b408540db217283e288c311179b0da6","515","18.9","128","72109","39369","8651","5","1458","124","1904","18","3024","50","3.9","5","245","2082","17096","23","805","2795","50","2520","105","65","16400","1.4","291","480","1"
"apache-carbondata","7d386a4140851686574d949a15774b5c8098302a","2017-06-19 23:32:38","add short int type support

fix style

fix testcase

fix style

fix testcase

fix

fix comment

fix commnet
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","7d386a4140851686574d949a15774b5c8098302a","29","8","0","3901","491","83","4380","148","6591","1070","272","27","44","5302","0","23","20","482","apache-carbondata","7d386a4140851686574d949a15774b5c8098302a","515","18.8","128","72307","39517","8708","5","1467","132","1913","18.1","3041","51","4","5","247","2093","17157","23","815","2878","52","2520","105","65","16557","1.4","291","480","1"
"apache-carbondata","ef77313f11d90bec30ed5e0ae0bf10a674d58b05","2017-06-09 02:33:30","[CARBONDATA-1149] Fix issue of mismatch type of partition column when specify partition info
","refs/heads/master","chenerlu@huawei.com","apache-carbondata","ef77313f11d90bec30ed5e0ae0bf10a674d58b05","29","8","0","3893","487","83","4386","148","6577","1070","270","27","44","5296","0","23","20","474","apache-carbondata","ef77313f11d90bec30ed5e0ae0bf10a674d58b05","515","18.8","128","72140","39395","8654","5","1458","124","1904","18","3025","50","3.9","5","245","2082","17105","23","805","2795","50","2520","105","65","16404","1.4","291","480","1"
"apache-carbondata","193a942e774dc6187cb3b841f0cce250e20f3b55","2017-06-22 00:05:00","Fixed comment
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","193a942e774dc6187cb3b841f0cce250e20f3b55","29","8","0","3893","487","83","4386","148","6577","1070","270","27","44","5296","0","23","20","474","apache-carbondata","193a942e774dc6187cb3b841f0cce250e20f3b55","515","18.8","128","72135","39390","8650","5","1458","124","1904","18","3025","50","3.9","5","245","2082","17102","23","805","2795","50","2520","105","65","16400","1.4","291","480","1"
"apache-carbondata","3319851bfe6d14369112d6bd0d4d3c1f670aa777","2017-06-21 01:44:44","Fixed issue of more records after update.
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","3319851bfe6d14369112d6bd0d4d3c1f670aa777","29","8","0","3893","487","83","4392","148","6577","1070","270","27","44","5296","0","23","20","474","apache-carbondata","3319851bfe6d14369112d6bd0d4d3c1f670aa777","515","18.8","128","72135","39390","8650","5","1458","124","1905","18","3025","50","3.9","5","245","2083","17102","23","805","2795","50","2520","105","65","16402","1.4","292","480","1"
"apache-carbondata","73ea854c1623fa22ea4816cc8d2aa1bc091c00e0","2017-06-21 04:31:29","Implicit Column Fix
","refs/heads/master","sounakr@gmail.com","apache-carbondata","73ea854c1623fa22ea4816cc8d2aa1bc091c00e0","29","8","0","3892","486","83","4384","148","6578","1070","270","27","44","5295","0","23","20","474","apache-carbondata","73ea854c1623fa22ea4816cc8d2aa1bc091c00e0","515","18.9","128","72113","39370","8646","5","1460","126","1906","18","3025","52","3.9","5","245","2084","17092","23","805","2841","50","2520","105","65","16437","1.4","291","480","1"
"apache-carbondata","51c60fdeb21bfeb4ad0ebc1fe19896d9ec30632a","2017-06-15 04:56:57","fix comment
","refs/heads/master","qiangcai@qq.com","apache-carbondata","51c60fdeb21bfeb4ad0ebc1fe19896d9ec30632a","29","8","0","3892","486","83","4384","148","6578","1070","270","27","44","5296","0","23","20","474","apache-carbondata","51c60fdeb21bfeb4ad0ebc1fe19896d9ec30632a","515","18.9","128","72113","39370","8646","5","1460","126","1906","18","3025","52","3.9","5","245","2084","17092","23","805","2841","50","2520","105","65","16437","1.4","291","480","1"
"apache-carbondata","5b4cf704ea25f5edd438c1a9491350bff88aa5e0","2017-06-08 02:47:07","fix single-pass issue for partition table
","refs/heads/master","david.caiq@gmail.com","apache-carbondata","5b4cf704ea25f5edd438c1a9491350bff88aa5e0","29","8","0","3892","486","83","4384","148","6578","1070","270","27","44","5295","0","23","20","474","apache-carbondata","5b4cf704ea25f5edd438c1a9491350bff88aa5e0","515","18.9","128","72111","39368","8646","5","1460","126","1906","18","3025","52","3.9","5","245","2084","17091","23","805","2841","50","2520","105","65","16437","1.4","291","480","1"
"apache-carbondata","236fa0eff9bfe7814a0864d48db0bfc4707644f2","2017-06-19 07:39:40","Handling multiple implicit columns
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","236fa0eff9bfe7814a0864d48db0bfc4707644f2","29","8","0","3891","486","83","4384","148","6578","1069","270","27","44","5293","0","23","20","474","apache-carbondata","236fa0eff9bfe7814a0864d48db0bfc4707644f2","515","18.9","128","72091","39352","8643","5","1460","126","1906","18","3025","52","3.9","5","245","2084","17081","23","805","2841","50","2520","105","65","16437","1.4","291","480","1"
"apache-carbondata","7359601b4a7808311bda33437333d627a6f8400d","2017-06-18 20:59:37","add unsafe column page
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","7359601b4a7808311bda33437333d627a6f8400d","29","8","0","3891","486","83","4384","148","6579","1069","270","27","44","5293","0","23","20","474","apache-carbondata","7359601b4a7808311bda33437333d627a6f8400d","515","18.9","128","72092","39353","8643","5","1460","126","1906","18","3025","52","3.9","5","245","2084","17082","23","805","2841","50","2520","105","65","16437","1.4","291","480","1"
"apache-carbondata","6a09ee84c6efde7675f1e49aaa1adf1a7ff1ba34","2017-06-13 06:56:06","rename RLE
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","6a09ee84c6efde7675f1e49aaa1adf1a7ff1ba34","29","8","0","3793","478","80","4360","143","6432","1043","273","27","44","5239","0","23","20","472","apache-carbondata","6a09ee84c6efde7675f1e49aaa1adf1a7ff1ba34","510","19","123","70983","38644","8446","5","1455","126","1887","17.8","2904","52","4","5","240","2060","16842","23","805","2835","50","2420","105","64","16262","1.4","278","475","1"
"apache-carbondata","b434346922632899b2bf77d5e4d5469caf63d40a","2017-06-04 06:02:48","Added data map interfaces

Fixed comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b434346922632899b2bf77d5e4d5469caf63d40a","29","8","0","3810","478","80","4368","143","6442","1044","276","27","44","5241","0","24","20","472","apache-carbondata","b434346922632899b2bf77d5e4d5469caf63d40a","512","19","123","71116","38708","8465","5","1459","128","1891","17.7","2915","54","4","5","240","2064","16863","23","805","2863","50","2420","105","64","16308","1.4","278","477","1"
"apache-carbondata","71934e915578b2022399d319fbecb50b2ee4fe35","2017-06-15 06:02:29","fix timestam format issue for partitioned table
","refs/heads/master","qiangcai@qq.com","apache-carbondata","71934e915578b2022399d319fbecb50b2ee4fe35","29","6","0","3771","478","80","4366","139","6425","1040","276","27","44","5235","0","24","20","472","apache-carbondata","71934e915578b2022399d319fbecb50b2ee4fe35","502","19","120","70612","38554","8449","5","1457","128","1888","18.1","2889","54","4.1","5","237","2057","16826","22","795","2863","49","2360","103","63","16291","1.4","278","468","1"
"apache-carbondata","de5346f3cd34f69ce25234ee3fb1cc146c3dc062","2017-06-09 04:01:34","partitioned by all primitive data type
","refs/heads/master","david.caiq@gmail.com","apache-carbondata","de5346f3cd34f69ce25234ee3fb1cc146c3dc062","29","6","0","3772","478","80","4364","139","6417","1032","276","27","44","5239","0","24","20","472","apache-carbondata","de5346f3cd34f69ce25234ee3fb1cc146c3dc062","502","19","120","70589","38535","8451","5","1457","128","1889","18.1","2889","54","4.1","5","237","2058","16826","22","795","2863","49","2360","103","63","16293","1.4","279","468","1"
"apache-carbondata","edda2483d074da7a26a5092fb896bea85689d8c5","2017-06-13 07:38:48","add EncodingStrategy

fix style“

fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","edda2483d074da7a26a5092fb896bea85689d8c5","29","6","0","3772","478","80","4364","139","6420","1032","276","27","44","5239","0","24","20","472","apache-carbondata","edda2483d074da7a26a5092fb896bea85689d8c5","502","19","120","70575","38521","8446","5","1456","128","1888","18","2889","54","4.1","5","237","2057","16820","22","795","2863","49","2360","103","63","16288","1.4","279","468","1"
"apache-carbondata","be0569576ae90c58d613bbf1e7e354acdedb4acc","2017-06-13 00:53:33","update logger class name

update logger class

update logger class

update logger class

update logger class

update logger class

update logger class

fix checkstyle issues
","refs/heads/master","xuchuanyin@126.com","apache-carbondata","be0569576ae90c58d613bbf1e7e354acdedb4acc","28","6","0","3971","492","76","4376","96","6764","1046","324","27","44","5333","0","23","51","466","apache-carbondata","be0569576ae90c58d613bbf1e7e354acdedb4acc","524","18.7","78","72719","39675","8640","5","1559","147","1972","17.7","3055","70","4.2","5","193","2098","17176","22","780","3023","48","1520","108","59","16978","1.4","265","488","1"
"apache-carbondata","82741c1fe1f60d102e6fc19a8ffc300067f06ba4","2017-06-10 03:15:44","Use sortBy operator in spark to load the data.

Modify the review comments.
","refs/heads/master","qiyadong2010@gmail.com","apache-carbondata","82741c1fe1f60d102e6fc19a8ffc300067f06ba4","28","6","0","3971","492","76","4376","96","6764","1046","324","27","44","5333","0","23","51","466","apache-carbondata","82741c1fe1f60d102e6fc19a8ffc300067f06ba4","524","18.7","78","72719","39675","8640","5","1559","147","1972","17.7","3055","70","4.2","5","193","2098","17176","22","780","3023","48","1520","108","59","16978","1.4","265","488","1"
"apache-carbondata","7656ad2a549ddb29dd95bcf7381b7aee16200ff9","2017-06-08 07:58:50","IUD Performance Changes
","refs/heads/master","sounakr@gmail.com","apache-carbondata","7656ad2a549ddb29dd95bcf7381b7aee16200ff9","28","6","0","3967","492","76","4372","96","6764","1046","324","27","44","5333","0","23","51","466","apache-carbondata","7656ad2a549ddb29dd95bcf7381b7aee16200ff9","524","18.7","78","72707","39672","8640","5","1559","147","1972","17.7","3055","70","4.2","5","192","2097","17176","22","750","3023","47","1520","108","59","16978","1.4","265","488","1"
"apache-carbondata","8a5ed819802ab5ad322fb20f40a19c5ccddf4312","2017-06-12 03:36:24","Fixed Synchronization issue and improve IUD performance
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","8a5ed819802ab5ad322fb20f40a19c5ccddf4312","28","6","0","3967","487","76","4372","96","6765","1045","324","27","44","5330","0","23","51","450","apache-carbondata","8a5ed819802ab5ad322fb20f40a19c5ccddf4312","524","18.7","78","72695","39663","8635","5","1559","147","1972","17.7","3055","70","4.2","5","192","2097","17171","22","750","3023","47","1520","108","59","16974","1.4","265","488","1"
"apache-carbondata","90000e6f7bab6b2cbf723614f1472f3c8db0c51c","2017-06-02 08:01:57","Adding the Pages support in the Delete Method.

correcting the size of the vector batch excluding the filtered rows.

changing page id from string to integer.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","90000e6f7bab6b2cbf723614f1472f3c8db0c51c","28","6","0","3953","489","76","4360","94","6737","1031","318","27","43","5324","0","23","54","450","apache-carbondata","90000e6f7bab6b2cbf723614f1472f3c8db0c51c","522","18.7","76","72329","39468","8589","5","1557","144","1967","17.7","3043","70","4.2","5","189","2089","17074","22","735","3006","46","1480","108","59","16871","1.4","262","486","1"
"apache-carbondata","dc83b2acc3c4d3dc0c46cb6c118e8d1c5aa21821","2017-06-07 21:03:53","extract interface
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","dc83b2acc3c4d3dc0c46cb6c118e8d1c5aa21821","28","6","0","3952","489","76","4354","94","6725","1030","318","27","43","5323","0","23","54","450","apache-carbondata","dc83b2acc3c4d3dc0c46cb6c118e8d1c5aa21821","522","18.7","76","72292","39435","8586","5","1558","144","1968","17.7","3044","70","4.2","5","189","2090","17057","22","735","3002","46","1480","108","59","16872","1.4","262","486","1"
"apache-carbondata","4a79a86ab06a3b053ac01094a2525a534a639d3a","2017-05-12 00:06:42","[CARBONDATA-1049] Avoid logging raw data into driver and executor log.// added isDebuggEnabled check

[CARBONDATA-1049] Avoid logging raw data into driver and executor log.
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","4a79a86ab06a3b053ac01094a2525a534a639d3a","28","6","0","3910","483","76","4336","93","6702","1029","341","27","43","5347","0","23","56","444","apache-carbondata","4a79a86ab06a3b053ac01094a2525a534a639d3a","518","18.8","75","72149","39291","8530","5","1549","146","1957","17.6","3018","72","4.2","5","188","2078","16982","22","735","3046","46","1460","107","60","16799","1.4","259","484","1"
"apache-carbondata","08f4b673d21bdec07c9c0a929d0c758dd5f672d0","2017-06-04 00:58:38","Test PR988 #1

Test PR988 #2

Test PR988 #3
","refs/heads/master","chenerlu@huawei.com","apache-carbondata","08f4b673d21bdec07c9c0a929d0c758dd5f672d0","28","6","0","3910","483","77","4336","93","6702","1029","341","27","43","5347","0","23","56","444","apache-carbondata","08f4b673d21bdec07c9c0a929d0c758dd5f672d0","518","18.8","75","72126","39267","8517","5","1549","148","1958","17.6","3018","72","4.3","5","188","2079","16969","22","735","3077","46","1460","107","60","16831","1.4","260","484","1"
"apache-carbondata","b8346b47d3a3a56cd773ecd1fb2116f825b3cb66","2017-06-08 06:06:30","fixed NullPointerException in partition column

fixed failing test cases

removed unused imports
","refs/heads/master","kunalkapoor642@gmail.com","apache-carbondata","b8346b47d3a3a56cd773ecd1fb2116f825b3cb66","28","6","0","3910","483","77","4336","93","6702","1029","341","27","43","5347","0","23","56","444","apache-carbondata","b8346b47d3a3a56cd773ecd1fb2116f825b3cb66","518","18.8","75","72126","39267","8517","5","1549","148","1958","17.6","3018","72","4.3","5","188","2079","16969","22","735","3077","46","1460","107","60","16831","1.4","260","484","1"
"apache-carbondata","f66b8a186bb1e0199835b7e2d47dda8b9443baab","2017-05-25 03:36:39","updated timeout message
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","f66b8a186bb1e0199835b7e2d47dda8b9443baab","28","6","0","3910","483","77","4336","93","6702","1029","341","27","43","5345","0","23","56","444","apache-carbondata","f66b8a186bb1e0199835b7e2d47dda8b9443baab","518","18.8","75","72118","39259","8513","5","1549","148","1958","17.6","3018","72","4.3","5","188","2079","16965","22","735","3077","46","1460","107","60","16831","1.4","260","484","1"
"apache-carbondata","d963a706c39c97993df84081a30837e4b78c7115","2017-05-31 03:19:54","Improve No dictionary column Include And Exclude filter
Fixed Data mismatch issue
Fixed Alter with Caps Decimal issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d963a706c39c97993df84081a30837e4b78c7115","28","6","0","3910","483","77","4336","93","6701","1029","341","27","43","5345","0","23","56","444","apache-carbondata","d963a706c39c97993df84081a30837e4b78c7115","518","18.8","75","72111","39252","8513","5","1549","148","1958","17.6","3018","72","4.3","5","188","2079","16963","22","735","3077","46","1460","107","60","16831","1.4","260","484","1"
"apache-carbondata","1c5b4a5558b99de41e29091fbae879d76665de3a","2017-05-31 08:24:49","Supported IUD for vector reader

Fixed commets
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","1c5b4a5558b99de41e29091fbae879d76665de3a","28","6","0","3912","477","77","4336","93","6703","1031","341","27","43","5335","0","23","55","444","apache-carbondata","1c5b4a5558b99de41e29091fbae879d76665de3a","518","18.8","75","72088","39232","8520","5","1553","148","1962","17.6","3018","72","4.3","5","188","2083","16959","22","735","3065","46","1460","107","60","16855","1.4","260","484","1"
"apache-carbondata","3ae44724870226fedf2ad90911c9306d3e56bc87","2017-05-25 06:14:30","Problem: Wrong results returned by the query in case inverted index is not created on a column

Fix: When inverted index does not exist for a column or column is not a sort column then
1. Block or blocklet cannot be pruned as data for that column is not sorted
2. While applying the filter linear search should be applied instead of binary search as binary search can be applied only on sorted data
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","3ae44724870226fedf2ad90911c9306d3e56bc87","28","6","0","3906","477","77","4336","93","6696","1028","340","27","43","5333","0","23","55","444","apache-carbondata","3ae44724870226fedf2ad90911c9306d3e56bc87","518","18.8","75","72029","39192","8510","5","1551","148","1960","17.6","3015","72","4.3","5","188","2081","16941","22","735","3065","46","1460","107","60","16845","1.4","260","484","1"
"apache-carbondata","a5e3643c4ac8ed8a02edfcba44c0cb56d1da991d","2017-05-23 23:04:43","use binarySearch to replace for clause to improve performance
","refs/heads/master","simafengyun1984@163.com","apache-carbondata","a5e3643c4ac8ed8a02edfcba44c0cb56d1da991d","28","6","0","3903","459","77","4330","93","6687","1027","340","27","43","5318","0","23","55","436","apache-carbondata","a5e3643c4ac8ed8a02edfcba44c0cb56d1da991d","518","18.8","75","71875","39077","8471","5","1523","148","1933","17.5","3012","72","4.2","5","188","2054","16882","22","735","3008","46","1460","107","60","16589","1.4","261","484","1"
"apache-carbondata","03bf99346c3c06a0c27cff496488d1296877029c","2017-05-29 08:36:23","Problem: Query failure while using unsafe for query execution numeric data type column specified as sort column

Analysis: When unsafe for query is enabled, while filling the data in column vector data is filled as bytes and not based on data type of the column because of which null pointer exception is thrown during result preparation in the query flow.

Fix: Convert the data based on its data type and then fill in the vector
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","03bf99346c3c06a0c27cff496488d1296877029c","28","6","0","3903","459","77","4330","93","6686","1027","340","27","43","5318","0","23","55","436","apache-carbondata","03bf99346c3c06a0c27cff496488d1296877029c","518","18.8","75","71866","39069","8468","5","1523","148","1933","17.5","3012","72","4.2","5","188","2054","16877","22","735","3008","46","1460","107","60","16589","1.4","261","484","1"
"apache-carbondata","f1f0e3ef02cce67abdaf274d1950793ea601b7ce","2017-05-18 04:12:49","ArrayIndexOutOfBoundException for DictionaryExclude and noInvertedIndex
","refs/heads/master","rahul.kumar@knoldus.in","apache-carbondata","f1f0e3ef02cce67abdaf274d1950793ea601b7ce","28","6","0","3903","453","77","4328","93","6685","1027","340","27","43","5316","0","23","55","436","apache-carbondata","f1f0e3ef02cce67abdaf274d1950793ea601b7ce","518","18.8","75","71836","39040","8460","5","1523","148","1933","17.5","3012","72","4.2","5","188","2054","16861","22","735","3008","46","1460","107","60","16589","1.4","261","484","1"
"apache-carbondata","353272efa51129df032d98c896f1bace837895e7","2017-05-27 05:02:24","add TablePage
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","353272efa51129df032d98c896f1bace837895e7","28","6","0","3903","453","77","4328","93","6684","1026","340","27","43","5316","0","23","55","436","apache-carbondata","353272efa51129df032d98c896f1bace837895e7","518","18.8","75","71819","39023","8456","5","1525","150","1935","17.5","3012","74","4.2","5","188","2056","16852","22","735","3048","46","1460","107","60","16629","1.4","261","484","1"
"apache-carbondata","3b948450b81fb663382ce41a981513250719df04","2017-05-23 08:16:37","change positon to position","refs/heads/master","simafengyun1984@163.com","apache-carbondata","3b948450b81fb663382ce41a981513250719df04","28","6","0","3899","453","77","4328","93","6678","1026","339","27","43","5316","0","23","55","436","apache-carbondata","3b948450b81fb663382ce41a981513250719df04","518","18.8","75","71821","39015","8452","5","1525","150","1935","17.5","3010","74","4.2","5","188","2056","16847","22","735","3048","46","1460","107","60","16629","1.4","261","484","1"
"apache-carbondata","ae4a30cf92975bb2508550839a97fc8bbd00db18","2017-05-20 02:14:11","[CARBONDATA-1073] Support INPUT_FILES

[CARBONDATA-1073] Fix code style

[CARBONDATA-1073] Fix code syle and UT

[CARBONDATA-1073] Fix for comments

[CARBONDATA-1073] Add UT
","refs/heads/master","linwzhong@gmail.com","apache-carbondata","ae4a30cf92975bb2508550839a97fc8bbd00db18","28","6","0","3899","453","77","4328","93","6678","1026","339","27","43","5316","0","23","55","436","apache-carbondata","ae4a30cf92975bb2508550839a97fc8bbd00db18","518","18.8","75","71821","39015","8452","5","1525","150","1935","17.5","3010","74","4.2","5","188","2056","16847","22","735","3048","46","1460","107","60","16629","1.4","261","484","1"
"apache-carbondata","51d32b2550cbcce5d62202989126bb6c4290173f","2017-05-21 10:42:59","close dictionary server on application end
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","51d32b2550cbcce5d62202989126bb6c4290173f","28","6","0","3899","453","77","4328","93","6678","1026","339","27","43","5314","0","23","55","436","apache-carbondata","51d32b2550cbcce5d62202989126bb6c4290173f","518","18.8","75","71813","39007","8450","5","1524","150","1934","17.5","3010","74","4.2","5","188","2055","16843","22","735","3048","46","1460","107","60","16619","1.4","261","484","1"
"apache-carbondata","dc0a2963f35f1ac1dccf3e471c4a76e11c6fc1a5","2017-05-24 11:53:05","tupleId is not working with vector reader in spark2x
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","dc0a2963f35f1ac1dccf3e471c4a76e11c6fc1a5","28","6","0","3899","453","77","4328","93","6678","1026","339","27","43","5316","0","23","55","436","apache-carbondata","dc0a2963f35f1ac1dccf3e471c4a76e11c6fc1a5","518","18.8","75","71815","39008","8450","5","1524","150","1934","17.5","3010","74","4.2","5","188","2055","16844","22","735","3048","46","1460","107","60","16619","1.4","261","484","1"
"apache-carbondata","4fa52727e2c351f6355c1b678060d689cfe1dccb","2017-05-22 07:08:58","move testcase and fix
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","4fa52727e2c351f6355c1b678060d689cfe1dccb","28","6","0","3898","453","77","4328","93","6668","1025","339","27","43","5300","0","23","55","436","apache-carbondata","4fa52727e2c351f6355c1b678060d689cfe1dccb","518","18.8","75","71780","38979","8445","5","1524","150","1934","17.4","3009","74","4.2","5","188","2055","16823","22","735","3048","46","1460","107","60","16619","1.4","261","484","1"
"apache-carbondata","3807b2f730584c2d8a8fdf42019146280b577f0e","2017-05-11 11:24:30","Added batch sort to load options and added test cases

Added sort_scope to load options

rebase

rebase
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","3807b2f730584c2d8a8fdf42019146280b577f0e","28","6","0","3898","453","77","4328","93","6668","1025","339","27","43","5300","0","23","55","436","apache-carbondata","3807b2f730584c2d8a8fdf42019146280b577f0e","518","18.8","75","71779","38978","8445","5","1524","150","1934","17.4","3009","74","4.2","5","188","2055","16822","22","735","3048","46","1460","107","60","16619","1.4","261","484","1"
"apache-carbondata","06555f039e24a0fb3b247068b98fa187069c395a","2017-05-19 02:04:41","Test Case Mismatch Fix
","refs/heads/master","sounakr@gmail.com","apache-carbondata","06555f039e24a0fb3b247068b98fa187069c395a","28","6","0","3898","453","77","4330","93","6668","1025","339","27","43","5300","0","23","55","436","apache-carbondata","06555f039e24a0fb3b247068b98fa187069c395a","518","18.8","75","71779","38978","8445","5","1524","150","1934","17.4","3009","74","4.2","5","188","2055","16822","22","735","3048","46","1460","107","60","16621","1.4","261","484","1"
"apache-carbondata","cdde3dd4b976e12987751f2eac0edba5aa4948b4","2017-05-03 20:26:05","prunepartition

fix comments

fix comments
","refs/heads/master","qiangcai@qq.com","apache-carbondata","cdde3dd4b976e12987751f2eac0edba5aa4948b4","28","6","0","3896","452","77","4330","93","6668","1025","339","27","43","5296","0","23","55","436","apache-carbondata","cdde3dd4b976e12987751f2eac0edba5aa4948b4","518","18.8","75","71747","38959","8438","5","1522","150","1932","17.4","3009","74","4.2","5","188","2053","16811","22","735","3048","46","1460","107","60","16598","1.4","261","484","1"
"apache-carbondata","484a4095e60691b30f1ba3da1fde7d703f42fbf2","2017-04-27 01:17:33","[CARBONDATA-989] decompress error while load 'gz' and 'bz2' data into table
","refs/heads/master","ranmx@fosun.com","apache-carbondata","484a4095e60691b30f1ba3da1fde7d703f42fbf2","28","6","0","3849","441","77","4312","92","6576","1016","339","27","43","5179","0","23","55","436","apache-carbondata","484a4095e60691b30f1ba3da1fde7d703f42fbf2","503","18.9","75","70920","38471","8289","5","1498","148","1907","17.5","2982","73","4.2","5","187","2028","16617","22","735","3012","46","1460","106","60","16193","1.4","261","475","1"
"apache-carbondata","8b3fa7f0d7a41299df311a2ac2423eb93d335a6b","2017-05-09 02:19:59","Fixed FilterUnsupportedException with outof range integer values
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","8b3fa7f0d7a41299df311a2ac2423eb93d335a6b","28","6","0","3849","441","77","4312","92","6576","1016","339","27","43","5177","0","23","55","436","apache-carbondata","8b3fa7f0d7a41299df311a2ac2423eb93d335a6b","503","18.9","75","70914","38465","8288","5","1498","148","1907","17.4","2982","73","4.2","5","187","2028","16614","22","735","3012","46","1460","106","60","16192","1.4","261","475","1"
"apache-carbondata","749dd451914644212adad0393e51725b8605ab1d","2017-05-18 01:18:34","updated null check for right expression in not in expression
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","749dd451914644212adad0393e51725b8605ab1d","28","6","0","3846","434","77","4310","92","6574","1016","339","27","43","5137","0","23","55","428","apache-carbondata","749dd451914644212adad0393e51725b8605ab1d","503","18.9","75","70852","38412","8274","5","1498","148","1907","17.4","2980","73","4.3","5","187","2028","16582","22","735","3012","46","1460","106","60","16184","1.4","261","475","1"
"apache-carbondata","ded550717e455f7ae2f179cef659fa4bbffc8788","2017-05-17 02:36:52","Query statistics issue in case of multiple blocklet and block
","refs/heads/master","akashnilugal@gmail.com","apache-carbondata","ded550717e455f7ae2f179cef659fa4bbffc8788","28","6","0","3846","434","77","4310","92","6573","1016","339","27","43","5137","0","23","55","428","apache-carbondata","ded550717e455f7ae2f179cef659fa4bbffc8788","503","18.9","75","70852","38412","8274","5","1498","148","1907","17.4","2980","73","4.3","5","187","2028","16582","22","735","3012","46","1460","106","60","16184","1.4","261","475","1"
"apache-carbondata","caa93291c3e4256b06e23b74405493c89ce6bd5c","2017-05-17 00:37:12","added check for starting dictionary server

moved single pass test suite to common module
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","caa93291c3e4256b06e23b74405493c89ce6bd5c","27","6","0","3834","434","77","4308","92","6561","1015","339","27","43","5125","0","23","55","426","apache-carbondata","caa93291c3e4256b06e23b74405493c89ce6bd5c","503","19","75","70759","38340","8268","5","1496","146","1906","17.4","2974","71","4.2","5","188","2026","16549","21","720","2984","45","1460","106","60","16153","1.4","261","475","1"
"apache-carbondata","b6b93f076d53a4ba87d1f0a2123c04189f2a76e9","2017-04-23 20:28:28","[CARBONDATA-937] Data loading for partition table(12-dev)  This closes #842

load data for partition table

fix comments

fix comments
","refs/heads/master","qiangcai@qq.com","apache-carbondata","b6b93f076d53a4ba87d1f0a2123c04189f2a76e9","27","6","0","3834","434","77","4308","92","6561","1015","339","27","43","5125","0","23","55","426","apache-carbondata","b6b93f076d53a4ba87d1f0a2123c04189f2a76e9","503","19","75","70757","38338","8267","5","1496","146","1906","17.4","2974","71","4.2","5","188","2026","16548","21","720","2984","45","1460","106","60","16153","1.4","261","475","1"
"apache-carbondata","86f6a81811239006dee7db55b19d794b7c373cb8","2017-05-08 08:20:13","[CARBONDATA-936] Create table with partition and add test case (12-dev)  This closes #896

create table with partition

fix comment

fix comments
","refs/heads/master","qiangcai@qq.com","apache-carbondata","86f6a81811239006dee7db55b19d794b7c373cb8","27","6","0","3791","430","77","4288","91","6530","1005","339","27","43","5114","0","23","55","426","apache-carbondata","86f6a81811239006dee7db55b19d794b7c373cb8","491","19","75","70373","38110","8193","5","1490","146","1898","17.4","2953","71","4.2","5","187","2018","16470","21","720","2984","45","1460","105","60","16067","1.4","260","470","1"
"apache-carbondata","98df130aaaa83de9e4fe1daf38b94d3b1b7d33f6","2017-05-04 08:32:07","[CARBONDATA-1015] Refactory write step and add ColumnPage in data load This closes #852
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","98df130aaaa83de9e4fe1daf38b94d3b1b7d33f6","27","6","0","3790","430","77","4270","91","6519","1006","339","27","43","5109","0","23","55","426","apache-carbondata","98df130aaaa83de9e4fe1daf38b94d3b1b7d33f6","491","19.1","75","70287","38029","8163","5","1486","146","1894","17.4","2949","71","4.2","5","187","2014","16429","21","720","2984","45","1460","105","60","16041","1.4","260","470","1"
"apache-carbondata","dae342bd57fe6d4704ad754b58438c1ec9d78516","2017-05-12 06:52:17","[CARBONDATA-936] Parse partition table ddl  This closes #882
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","dae342bd57fe6d4704ad754b58438c1ec9d78516","26","6","0","3724","430","78","4282","88","6495","999","331","29","46","5130","0","23","57","414","apache-carbondata","dae342bd57fe6d4704ad754b58438c1ec9d78516","484","19.2","72","69820","37756","8106","5","1482","146","1892","17.5","2918","71","4.3","5","180","2004","16337","20","690","2984","40","1400","102","58","16062","1.4","264","462","1"
"apache-carbondata","f4d081e81714d2d6795af1eab64a68164a4711dd","2017-04-17 23:52:18","[CARBONDATA-935] Define PartitionInfo model

fix javastyle error

modify partitioninfo and singlePartition

modify schema.thrift to add partitioningList

modify definition

variable style fix, remove partitionName and some comments

change import order

change comments

change partition info and create partition statistic

add get method in carbontable

remove partition in schema
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","f4d081e81714d2d6795af1eab64a68164a4711dd","26","6","0","3719","430","78","4282","88","6495","999","331","29","46","5130","0","23","57","414","apache-carbondata","f4d081e81714d2d6795af1eab64a68164a4711dd","484","19.2","72","69829","37754","8106","5","1482","146","1892","17.5","2918","71","4.3","5","180","2004","16337","20","690","2984","40","1400","102","58","16062","1.4","264","462","1"
"apache-carbondata","bf44c9f6ee4b059c384703ab12aebea4f4fed5e2","2017-05-01 23:58:16","fix issue of rebase
","refs/heads/master","qiangcai@qq.com","apache-carbondata","bf44c9f6ee4b059c384703ab12aebea4f4fed5e2","26","6","0","3679","430","78","4268","88","6477","990","331","29","46","5130","0","23","56","414","apache-carbondata","bf44c9f6ee4b059c384703ab12aebea4f4fed5e2","477","19.2","72","69457","37608","8095","5","1482","146","1892","17.8","2907","71","4.3","5","179","2003","16299","20","660","2984","39","1400","101","58","16062","1.4","264","455","1"
"apache-carbondata","f5c6f2880d4db863494ad9491c24438010c5340d","2017-04-08 09:40:17","fix sort_columns issue
","refs/heads/master","qiangcai@qq.com","apache-carbondata","f5c6f2880d4db863494ad9491c24438010c5340d","26","6","0","3678","424","78","4264","88","6476","990","331","29","46","5128","0","23","56","414","apache-carbondata","f5c6f2880d4db863494ad9491c24438010c5340d","477","19.2","72","69424","37577","8086","5","1481","146","1891","17.8","2906","71","4.3","5","179","2002","16282","20","660","2984","39","1400","101","58","16050","1.4","264","455","1"
"apache-carbondata","81149f659cee4fe1baa1192d8e3b757a48b5d16d","2017-05-01 18:43:23","[CARBONDATA-886] remove redundant variable
","refs/heads/master","qiangcai@qq.com","apache-carbondata","81149f659cee4fe1baa1192d8e3b757a48b5d16d","26","6","0","3678","424","78","4264","88","6476","987","331","29","46","5128","0","23","56","414","apache-carbondata","81149f659cee4fe1baa1192d8e3b757a48b5d16d","477","19.2","73","69416","37570","8095","5","1478","146","1888","17.8","2906","71","4.3","5","180","2000","16279","20","660","2984","39","1420","101","58","16035","1.4","264","455","1"
"apache-carbondata","9f94529112c8d955dd6ebfc26a890e784cd7b125","2017-04-18 02:12:14","[CARBONDATA-782] add SORT_COLUMNS options
","refs/heads/master","qiangcai@qq.com","apache-carbondata","9f94529112c8d955dd6ebfc26a890e784cd7b125","26","6","0","3678","424","78","4276","88","6505","1001","331","29","46","5131","0","23","56","414","apache-carbondata","9f94529112c8d955dd6ebfc26a890e784cd7b125","477","19.2","73","69453","37607","8095","5","1480","148","1916","17.8","2906","73","4.3","5","180","2028","16312","20","660","3010","39","1420","101","58","16127","1.4","290","455","1"
"apache-carbondata","a5b92876eac8a2b64ebcd1a6d9607b59e321a601","2017-05-03 21:46:19","Like Filter Pushdown

No Dictionary Handling in Greater and Less Than Expression
","refs/heads/master","sounakr@gmail.com","apache-carbondata","a5b92876eac8a2b64ebcd1a6d9607b59e321a601","22","6","0","3650","410","78","4216","84","6446","986","331","29","44","5094","0","23","56","412","apache-carbondata","a5b92876eac8a2b64ebcd1a6d9607b59e321a601","477","19.2","69","68799","37184","7942","5","1458","148","1892","17.5","2875","73","4.4","5","177","2000","16099","18","660","3010","39","1340","101","58","15928","1.4","289","455","1"
"apache-carbondata","2d1c729c68fb2f50f55e5b258d8d134994d807d7","2017-05-06 20:09:28","Fixed relative store path issue while update and delete
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","2d1c729c68fb2f50f55e5b258d8d134994d807d7","22","6","0","3646","410","78","4216","84","6446","988","331","29","44","5102","0","23","56","412","apache-carbondata","2d1c729c68fb2f50f55e5b258d8d134994d807d7","477","19.2","69","68833","37216","7958","5","1468","144","1902","17.5","2875","73","4.2","5","177","2010","16111","18","660","2894","39","1340","101","58","15990","1.4","289","455","1"
"apache-carbondata","58751fd573be920193f4256c6a204b4c4986aabf","2017-05-02 04:47:28","added check for null value in expression result
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","58751fd573be920193f4256c6a204b4c4986aabf","22","6","0","3646","410","78","4216","83","6446","988","331","29","44","5102","0","23","56","412","apache-carbondata","58751fd573be920193f4256c6a204b4c4986aabf","477","19.2","68","68824","37208","7954","5","1466","144","1900","17.5","2875","73","4.2","5","176","2007","16107","18","660","2894","39","1320","101","58","15966","1.4","289","455","1"
"apache-carbondata","ea5e80cf1d1720d716b6ad9e63ac4e6d9141b244","2017-05-02 08:09:09","fixed cast exception for new column with date datatype
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","ea5e80cf1d1720d716b6ad9e63ac4e6d9141b244","22","6","0","3641","410","78","4216","83","6445","988","331","29","44","5102","0","23","56","412","apache-carbondata","ea5e80cf1d1720d716b6ad9e63ac4e6d9141b244","477","19.2","68","68802","37198","7949","5","1466","144","1900","17.5","2875","73","4.2","5","176","2007","16100","18","660","2894","39","1320","101","58","15961","1.4","289","455","1"
"apache-carbondata","b731123c25dc2800e5264381f353d1409cdf7b8f","2017-04-25 20:34:37","Fix CarbonSessionExample

Fix CarbonSessionExample

Fix CarbonSessionExample
","refs/heads/master","erlu@erludeMacBook-Pro.local","apache-carbondata","b731123c25dc2800e5264381f353d1409cdf7b8f","22","6","0","3641","410","78","4216","83","6445","988","331","29","44","5100","0","23","56","412","apache-carbondata","b731123c25dc2800e5264381f353d1409cdf7b8f","477","19.2","68","68797","37193","7948","5","1466","144","1900","17.5","2875","73","4.2","5","176","2007","16098","18","660","2894","39","1320","101","58","15961","1.4","289","455","1"
"apache-carbondata","33a3858a8c28551dd37f4a530cb52d97d888f810","2017-04-21 01:21:04","Use map to store SegmentProperties and reuse SegmentProperties.

Add comment.
","refs/heads/master","qiyadong2010@gmail.com","apache-carbondata","33a3858a8c28551dd37f4a530cb52d97d888f810","22","6","0","3641","410","78","4216","83","6444","988","331","29","44","5099","0","23","56","412","apache-carbondata","33a3858a8c28551dd37f4a530cb52d97d888f810","477","19.2","68","68795","37191","7947","5","1465","144","1899","17.5","2875","73","4.2","5","176","2006","16097","18","660","2894","39","1320","101","58","15956","1.4","289","455","1"
"apache-carbondata","4a11fbd2c0aaa2a7808c18efba5926c5dd001c1b","2017-04-25 03:03:30","change columnSchenma to columnSchema","refs/heads/master","simafengyun1984@163.com","apache-carbondata","4a11fbd2c0aaa2a7808c18efba5926c5dd001c1b","22","6","0","3631","403","78","4214","83","6435","982","330","29","44","5099","0","23","56","412","apache-carbondata","4a11fbd2c0aaa2a7808c18efba5926c5dd001c1b","476","19.2","68","68730","37140","7932","5","1463","144","1897","17.4","2871","73","4.2","5","176","2004","16076","18","660","2894","39","1320","101","58","15950","1.4","289","455","1"
"apache-carbondata","105e3a0d7b58282f7228e4d6c96fd2dc97ef973f","2017-04-24 01:56:45","Range Filter Check Rectification

Modify ByteUtil Compare

Direct Dictionary test Case Addition
","refs/heads/master","sounakr@gmail.com","apache-carbondata","105e3a0d7b58282f7228e4d6c96fd2dc97ef973f","22","6","0","3631","403","78","4214","83","6435","982","330","29","44","5099","0","23","56","412","apache-carbondata","105e3a0d7b58282f7228e4d6c96fd2dc97ef973f","476","19.2","68","68730","37140","7932","5","1463","144","1897","17.4","2871","73","4.2","5","176","2004","16076","18","660","2894","39","1320","101","58","15950","1.4","289","455","1"
"apache-carbondata","8a1cd7dd6896e96755b2acb7086a75075b66b9b5","2017-04-26 19:31:58","Remove fs, it may not be initialized when create a instance using AbstractDFSCarbonFile(FileStatus fileStatus).
Fixed spelling mistakes
","refs/heads/master","liuhongqiang@live.cn","apache-carbondata","8a1cd7dd6896e96755b2acb7086a75075b66b9b5","22","6","0","3631","403","78","4222","83","6433","990","330","29","44","5102","0","23","56","436","apache-carbondata","8a1cd7dd6896e96755b2acb7086a75075b66b9b5","476","19.2","68","68752","37162","7949","5","1463","144","1905","17.5","2871","73","4.2","5","176","2012","16087","18","660","2895","39","1320","101","58","15978","1.4","297","455","1"
"apache-carbondata","8fc9c7bf67c1e5678cfa955266dfe005fed4a5d5","2017-04-21 08:12:10","Improve Carbon index file loading file in case of big cluster
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","8fc9c7bf67c1e5678cfa955266dfe005fed4a5d5","22","6","0","3632","403","78","4214","83","6433","990","330","29","44","5097","0","23","56","436","apache-carbondata","8fc9c7bf67c1e5678cfa955266dfe005fed4a5d5","476","19.2","68","68746","37156","7949","5","1465","144","1907","17.5","2871","73","4.2","5","176","2014","16080","18","660","2895","39","1320","101","58","15988","1.4","297","455","1"
"apache-carbondata","9d01f9b0f4767a6c6d799c04a9753f8527803748","2017-04-21 05:29:52","fixed decimal precision issue
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","9d01f9b0f4767a6c6d799c04a9753f8527803748","22","6","0","3631","403","78","4210","83","6423","990","330","29","44","5085","0","23","56","436","apache-carbondata","9d01f9b0f4767a6c6d799c04a9753f8527803748","476","19.2","68","68709","37135","7943","5","1465","144","1907","17.5","2869","73","4.2","5","176","2014","16075","18","660","2895","39","1320","101","58","15988","1.4","297","455","1"
"apache-carbondata","4f011e21be8529a665145cfb9d43d8811811766f","2017-04-18 04:11:30","fixed table not found exception in rename table after lock acquire failure
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","4f011e21be8529a665145cfb9d43d8811811766f","22","6","0","3631","403","78","4210","83","6423","990","330","29","44","5085","0","23","56","436","apache-carbondata","4f011e21be8529a665145cfb9d43d8811811766f","476","19.2","68","68709","37135","7943","5","1465","144","1907","17.5","2869","73","4.2","5","176","2014","16075","18","660","2895","39","1320","101","58","15988","1.4","297","455","1"
"apache-carbondata","5e40f165a3b252fa7e8602a1d67571bfb0fcfcbd","2017-04-06 06:44:50","[CARBONDATA-881] Load status is successful even though system is fail to write status into tablestatus file
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","5e40f165a3b252fa7e8602a1d67571bfb0fcfcbd","22","6","0","3631","403","78","4210","83","6423","990","330","29","44","5083","0","23","56","436","apache-carbondata","5e40f165a3b252fa7e8602a1d67571bfb0fcfcbd","476","19.2","68","68707","37133","7943","5","1465","144","1909","17.5","2869","73","4.2","5","178","2016","16073","18","660","2895","39","1320","101","58","16008","1.4","297","455","1"
"apache-carbondata","f890d0082716f2f5adb1aa823391dd6332986f42","2017-04-20 11:53:31","changes done:
1. Corrected temp store location path formation for compaction through sort step.
2. Correct filter query bug on datatype changed for a decimal column.
3. Corrected data type change validations. New precision should always be greater than existing precision and new scale value can be same as old scale value.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","f890d0082716f2f5adb1aa823391dd6332986f42","22","6","0","3631","403","78","4210","83","6423","990","330","29","44","5083","0","23","56","436","apache-carbondata","f890d0082716f2f5adb1aa823391dd6332986f42","476","19.2","68","68704","37130","7940","5","1465","144","1912","17.5","2869","73","4.2","5","181","2019","16070","18","660","2895","39","1320","101","58","16036","1.4","297","455","1"
"apache-carbondata","1744278620bacf4f1ad13a61c8cde93f9c400f94","2017-04-11 02:25:56","Added getAll dictionary to codegen of dictionary decoder.
Clear dictionary after task completion.
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","1744278620bacf4f1ad13a61c8cde93f9c400f94","22","6","0","3631","403","78","4210","83","6424","990","330","29","44","5076","0","23","56","436","apache-carbondata","1744278620bacf4f1ad13a61c8cde93f9c400f94","476","19.2","68","68701","37127","7939","5","1465","144","1912","17.4","2869","73","4.2","5","181","2019","16068","18","660","2895","39","1320","101","58","16036","1.4","297","455","1"
"apache-carbondata","e2408551aca873b632b3eaaf6ad4d2ac52ebc8ee","2017-04-20 05:25:12","Fixed:
1. Data mismatch issue
2. Memory Leak issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","e2408551aca873b632b3eaaf6ad4d2ac52ebc8ee","22","6","0","3631","403","78","4210","83","6424","990","330","29","44","5076","0","23","56","436","apache-carbondata","e2408551aca873b632b3eaaf6ad4d2ac52ebc8ee","476","19.2","68","68699","37126","7939","5","1465","144","1912","17.4","2869","73","4.2","5","181","2019","16068","18","660","2895","39","1320","101","58","16036","1.4","297","455","1"
"apache-carbondata","bfa306b8cc2bad6fa4e45d51c54723f11b0732d1","2017-04-20 03:04:20","Fix Unsafe merge sort issue
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","bfa306b8cc2bad6fa4e45d51c54723f11b0732d1","22","6","0","3629","403","78","4210","83","6423","990","330","29","44","5075","0","23","56","436","apache-carbondata","bfa306b8cc2bad6fa4e45d51c54723f11b0732d1","476","19.2","68","68685","37118","7939","5","1466","144","1913","17.4","2868","73","4.2","5","181","2020","16065","18","660","2895","39","1320","101","58","16048","1.4","297","455","1"
"apache-carbondata","013db609a51c4ca92aa24952ee92fccb2f365c22","2017-04-18 02:13:41","Added validations in Unsafe dataload.

Fixed Style

Fixed Carbon Example
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","013db609a51c4ca92aa24952ee92fccb2f365c22","22","6","0","3630","407","78","4224","83","6435","990","330","29","44","5079","0","23","56","442","apache-carbondata","013db609a51c4ca92aa24952ee92fccb2f365c22","476","19.2","68","68748","37167","7953","5","1474","146","1921","17.5","2869","74","4.3","5","181","2028","16095","18","660","2961","39","1320","101","58","16132","1.4","297","455","1"
"apache-carbondata","0729379a43d72d0e2abd2e15ab3ad5d224faedc6","2017-04-15 04:31:48","fixed variable length filter query with empty data
","refs/heads/master","vpp9380@gmail.com","apache-carbondata","0729379a43d72d0e2abd2e15ab3ad5d224faedc6","22","6","0","3630","407","78","4222","82","6435","990","330","29","44","5077","0","23","56","442","apache-carbondata","0729379a43d72d0e2abd2e15ab3ad5d224faedc6","476","19.2","68","68716","37140","7949","5","1474","146","1920","17.5","2868","74","4.3","5","180","2027","16083","18","660","2961","39","1320","101","58","16122","1.4","297","455","1"
"apache-carbondata","92352f3a695e99702564287921b57e72aa7f3a07","2017-04-15 04:31:48","BigDecimal and VariableLength Dimension fixes
","refs/heads/master","vpp9380@gmail.com","apache-carbondata","92352f3a695e99702564287921b57e72aa7f3a07","22","6","0","3630","407","78","4222","82","6435","990","330","29","44","5077","0","23","56","442","apache-carbondata","92352f3a695e99702564287921b57e72aa7f3a07","476","19.2","68","68716","37140","7949","5","1474","146","1920","17.5","2868","74","4.3","5","180","2027","16083","18","660","2961","39","1320","101","58","16122","1.4","297","455","1"
"apache-carbondata","3d21ccba668d3c42c9bd2d276d45c55d23e0b7fe","2017-04-15 01:12:29","Drop table IS is throwing exception
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","3d21ccba668d3c42c9bd2d276d45c55d23e0b7fe","22","6","0","3630","407","78","4222","82","6435","990","330","29","44","5077","0","23","56","442","apache-carbondata","3d21ccba668d3c42c9bd2d276d45c55d23e0b7fe","476","19.2","68","68717","37141","7949","5","1474","146","1920","17.5","2868","74","4.3","5","180","2027","16083","18","660","2961","39","1320","101","58","16122","1.4","297","455","1"
"apache-carbondata","1e8d26c29d6025d083bde62a535b415993606219","2017-04-11 04:24:03","Problem: Is null query on a newly added measure column is not returning proper results.

Analysis: When is null query is executed on newly added measure column, control goes to RowLevelFilterExecuterImpl class, where measure existence is checked. In case the measure is not found, bitset group is not getting populated with default values due to which that block is not returning any result.

Solution: When query is on a restructured block where newly added column does not exist, create the default bitset group so that based on default value existence default bitset group is created and results are returned based on that.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","1e8d26c29d6025d083bde62a535b415993606219","22","6","0","3630","407","78","4222","82","6435","990","330","29","44","5077","0","23","56","442","apache-carbondata","1e8d26c29d6025d083bde62a535b415993606219","476","19.2","68","68716","37140","7949","5","1474","146","1920","17.5","2868","74","4.3","5","180","2027","16083","18","660","2961","39","1320","101","58","16122","1.4","297","455","1"
"apache-carbondata","673f8c2263c94e3475552de4da06327029f06eb3","2017-04-10 23:51:35","Problem: After drop table dictionary and BTree instances are not getting cleared from driver memory. Due to this memory will keep growing and after some time GC problems will occur. In real case scenarios usually driver memory is on lower side hence it is more prone to GC problems.

Solution:
1. When a table is being clear BTree and dictionary instances from LRU cache.
2. Clear the access count for each segment immediately after block pruning rather then loading all the segments first and at lats clearing access count for all the segments together.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","673f8c2263c94e3475552de4da06327029f06eb3","24","6","0","3630","407","78","4222","82","6435","990","330","29","44","5073","0","23","56","442","apache-carbondata","673f8c2263c94e3475552de4da06327029f06eb3","476","19.2","68","68706","37132","7948","5","1476","146","1922","17.5","2868","74","4.3","5","180","2029","16078","18","660","2961","39","1320","101","58","16132","1.4","297","455","1"
"apache-carbondata","8c5c00c0c169d74adb72f13b8a781c893a6ad791","2017-04-07 06:26:16","fixed cast exception for integer data types in RestructureBasedVectorResultCollector

fixed cast exception for double datatype
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","8c5c00c0c169d74adb72f13b8a781c893a6ad791","24","6","0","3630","407","78","4212","82","6424","989","330","29","44","5070","0","23","56","442","apache-carbondata","8c5c00c0c169d74adb72f13b8a781c893a6ad791","476","19.2","68","68656","37097","7942","5","1476","146","1922","17.5","2866","74","4.3","5","180","2029","16061","18","660","2961","39","1320","101","58","16132","1.4","297","455","1"
"apache-carbondata","bcd28391a6052954994513b0583397bc9c50ae8d","2017-04-05 00:06:45","NullPointer is getting thrown when rename table and select query is fired concurrently
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","bcd28391a6052954994513b0583397bc9c50ae8d","24","6","0","3629","407","78","4210","82","6419","987","330","29","44","5064","0","23","56","442","apache-carbondata","bcd28391a6052954994513b0583397bc9c50ae8d","476","19.2","68","68594","37052","7932","5","1473","146","1919","17.4","2864","74","4.3","5","180","2026","16035","18","660","2961","39","1320","101","58","16107","1.4","297","455","1"
"apache-carbondata","81ccec2ab75c7504d7b5689c7098cf925acb54b9","2017-04-11 04:42:30","fix some spelling mistakes in SegmentProperties.java

fix some spelling mistakes in SegmentProperties.java
","refs/heads/master","cgf1993@foxmail.com","apache-carbondata","81ccec2ab75c7504d7b5689c7098cf925acb54b9","24","6","0","3628","407","78","4210","82","6418","987","330","29","44","5064","0","23","56","442","apache-carbondata","81ccec2ab75c7504d7b5689c7098cf925acb54b9","476","19.2","68","68590","37049","7930","5","1473","146","1919","17.4","2864","74","4.3","5","180","2026","16032","18","660","2961","39","1320","101","58","16107","1.4","297","455","1"
"apache-carbondata","8f59a326ea4028ff7987e98826b00926df804ea7","2017-03-05 07:02:35","Removed unnecessary array copy and bitset checking

OPtimized code

Added table_blocksize option.

Removed unnecessary plan from optimized plan.

Fixed test

FIxed comment

Rebased
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","8f59a326ea4028ff7987e98826b00926df804ea7","24","6","0","3628","407","78","4210","82","6418","987","330","29","44","5064","0","23","56","442","apache-carbondata","8f59a326ea4028ff7987e98826b00926df804ea7","476","19.2","68","68590","37049","7930","5","1475","148","1921","17.4","2864","76","4.4","5","180","2028","16032","18","660","2999","39","1320","101","58","16147","1.5","297","455","1"
"apache-carbondata","086b06d119d4fb855fa944ecf79f3f637855cb56","2017-04-07 09:23:00","clean issue in java/scala doc
","refs/heads/master","qiangcai@qq.com","apache-carbondata","086b06d119d4fb855fa944ecf79f3f637855cb56","24","6","0","3621","406","76","4200","82","6408","985","330","29","44","5036","0","24","56","442","apache-carbondata","086b06d119d4fb855fa944ecf79f3f637855cb56","476","19.2","68","68477","36953","7898","5","1463","152","1909","17.4","2858","76","4.4","5","180","2016","15992","18","660","3047","39","1320","101","58","16018","1.4","297","455","1"
"apache-carbondata","6c73d88578b0c5675b26502768974f958594a820","2017-04-07 08:19:14","clean code
","refs/heads/master","qiangcai@qq.com","apache-carbondata","6c73d88578b0c5675b26502768974f958594a820","24","6","0","3617","406","76","4200","82","6408","985","330","29","44","5036","0","24","56","442","apache-carbondata","6c73d88578b0c5675b26502768974f958594a820","476","19.2","68","68481","36954","7898","5","1463","152","1909","17.4","2858","76","4.4","5","180","2016","15992","18","660","3047","39","1320","101","58","16018","1.4","297","455","1"
"apache-carbondata","2a4f09b7ab125581c7caa2bf57513abc07ac3c7f","2017-03-15 02:08:31","added support to revert changes if query fails
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","2a4f09b7ab125581c7caa2bf57513abc07ac3c7f","24","6","0","3618","406","76","4200","82","6408","985","330","29","44","5036","0","24","56","442","apache-carbondata","2a4f09b7ab125581c7caa2bf57513abc07ac3c7f","476","19.2","68","68484","36954","7898","5","1463","152","1909","17.4","2858","76","4.4","5","180","2016","15992","18","660","3047","39","1320","101","58","16018","1.4","297","455","1"
"apache-carbondata","22be34503df33016da4820bf91fb403fa975ff1c","2017-04-03 10:24:18","fixed null pointer exception for DictionaryBasedVectorResultCollector during alter table
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","22be34503df33016da4820bf91fb403fa975ff1c","24","6","0","3618","406","76","4198","82","6406","985","330","29","44","5038","0","24","56","442","apache-carbondata","22be34503df33016da4820bf91fb403fa975ff1c","476","19.2","68","68478","36948","7896","5","1461","152","1907","17.4","2858","76","4.4","5","180","2014","15988","18","660","3047","39","1320","101","58","15981","1.4","297","455","1"
"apache-carbondata","cc59b247aff7a6fd5d164d83dfe01890cfcdb2e1","2017-03-15 06:54:05","Compaction lock should also be acquired during alter operation as alter and compaction on same table should not be allowed concurrently.

Handling for compaction for restructure case. Handled to completely sort the data again if any restructured block is selected for compaction

Handled review comments
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","cc59b247aff7a6fd5d164d83dfe01890cfcdb2e1","24","6","0","3618","406","76","4198","82","6406","985","330","29","44","5033","0","24","56","442","apache-carbondata","cc59b247aff7a6fd5d164d83dfe01890cfcdb2e1","476","19.2","68","68472","36942","7894","5","1461","152","1907","17.3","2858","76","4.4","5","180","2014","15983","18","660","3047","39","1320","101","58","15981","1.4","297","455","1"
"apache-carbondata","7ae1cd8fe77a391cb5f5addec4e19fbff5b06820","2017-03-31 03:33:17","fixed issue with meta lock not getting deleted for rename table
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","7ae1cd8fe77a391cb5f5addec4e19fbff5b06820","24","6","0","3617","406","76","4198","82","6408","985","330","29","44","5033","0","24","57","442","apache-carbondata","7ae1cd8fe77a391cb5f5addec4e19fbff5b06820","476","19.2","68","68462","36937","7893","5","1463","152","1909","17.3","2858","76","4.5","5","180","2016","15982","18","660","3047","39","1320","101","58","16001","1.4","297","455","1"
"apache-carbondata","3af2d650372b8e0e85b03133229c1b7c15e4dafc","2017-03-23 22:03:02","[CARBONDATA-814] bad record log file writing is not correct
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","3af2d650372b8e0e85b03133229c1b7c15e4dafc","24","6","0","3616","406","76","4198","81","6406","985","330","29","44","5032","0","24","57","442","apache-carbondata","3af2d650372b8e0e85b03133229c1b7c15e4dafc","476","19.2","68","68444","36927","7894","5","1464","152","1911","17.3","2856","76","4.5","5","181","2018","15979","18","660","3047","39","1320","101","58","16021","1.4","297","455","1"
"apache-carbondata","df3dea90b088e1de2725cbb5cef1c8f90209d9fe","2017-04-05 08:28:48","While executing drop table , invalidating the table from hive metastore by running the command externally
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","df3dea90b088e1de2725cbb5cef1c8f90209d9fe","24","6","0","3615","406","76","4198","81","6406","985","330","29","44","5032","0","24","57","442","apache-carbondata","df3dea90b088e1de2725cbb5cef1c8f90209d9fe","476","19.2","68","68437","36920","7894","5","1464","152","1911","17.3","2856","76","4.5","5","181","2018","15978","18","660","3047","39","1320","101","58","16021","1.4","297","455","1"
"apache-carbondata","b5ba4c6ea2d864f099bd4112e2cd5260e615a0a8","2017-04-04 07:29:18","Changes done:
1. Support creation and deletion of dictionary files during alter add and drop columns through RDD to parallelize the task and increase the performance
2. Support clean up of dictionary files in case any failure occurs during alter add columns operation
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","b5ba4c6ea2d864f099bd4112e2cd5260e615a0a8","24","6","0","3615","406","76","4198","81","6407","985","330","29","44","5031","0","24","57","442","apache-carbondata","b5ba4c6ea2d864f099bd4112e2cd5260e615a0a8","476","19.2","68","68431","36914","7890","5","1463","152","1908","17.3","2856","76","4.5","5","179","2015","15973","18","660","3047","39","1320","101","58","15991","1.4","297","455","1"
"apache-carbondata","8cca0afc5db16557146dfaa33e14c2823d895966","2017-03-29 22:51:21","refactor write step
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","8cca0afc5db16557146dfaa33e14c2823d895966","24","6","0","3615","406","76","4196","81","6408","985","330","29","44","5031","0","24","57","442","apache-carbondata","8cca0afc5db16557146dfaa33e14c2823d895966","476","19.2","68","68436","36921","7892","5","1464","152","1909","17.3","2856","76","4.5","5","179","2016","15977","18","660","3047","39","1320","101","58","16001","1.4","297","455","1"
"apache-carbondata","43319298eb122846286e16fdbd145594e4633aa4","2017-03-31 05:40:31","CARBONDATA-843
problem: null pointer exception was thrown when floor operation is done on decimal column.
analysis: when floor operation was done on decimal column, scale was greater than precision.During floor operation , we tried to change the precision of the data.
solution: When sending to the spark layer for performing floor operation, we need to send the precision and scale to the spark layer which are taken from the CarbonMeasure
","refs/heads/master","akash.r.nilugal@huawei.com","apache-carbondata","43319298eb122846286e16fdbd145594e4633aa4","24","6","0","3620","406","76","4198","81","6408","985","330","29","44","5030","0","24","58","442","apache-carbondata","43319298eb122846286e16fdbd145594e4633aa4","478","19.2","66","68526","36946","7895","5","1465","152","1910","17.3","2859","76","4.4","5","177","2015","15980","18","660","3047","39","1290","101","58","15975","1.4","297","457","1"
"apache-carbondata","c52fd93d23e8786beb49452b146532231fecb935","2017-03-27 08:13:09","fix query stats format problem
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","c52fd93d23e8786beb49452b146532231fecb935","24","6","0","3620","406","76","4198","81","6408","985","330","29","44","5030","0","24","58","442","apache-carbondata","c52fd93d23e8786beb49452b146532231fecb935","478","19.2","66","68525","36945","7895","5","1465","152","1910","17.3","2859","76","4.4","5","177","2015","15980","18","660","3047","39","1290","101","58","15975","1.4","297","457","1"
"apache-carbondata","71fe32a474caff36b33db19a8aaca711522d2e2d","2017-03-21 10:05:07","Fixed data loading issue with duplicate column
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","71fe32a474caff36b33db19a8aaca711522d2e2d","24","6","0","3620","406","76","4198","81","6415","985","330","29","44","5030","0","24","58","442","apache-carbondata","71fe32a474caff36b33db19a8aaca711522d2e2d","478","19.2","66","68526","36946","7895","5","1465","152","1910","17.3","2859","76","4.4","5","177","2015","15981","18","660","3047","39","1290","101","58","15975","1.4","297","457","1"
"apache-carbondata","e6b60907f0be2efd89884b81490a112ef71fd9cd","2017-03-26 03:40:47","Removed kettle related code and refactored

Removed carbonplugins

Added back method

Fixed test

Fixed test
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","e6b60907f0be2efd89884b81490a112ef71fd9cd","24","6","0","3620","406","76","4198","81","6415","985","330","29","44","5030","0","24","58","442","apache-carbondata","e6b60907f0be2efd89884b81490a112ef71fd9cd","478","19.2","66","68525","36945","7893","5","1464","152","1909","17.3","2859","76","4.4","5","177","2014","15979","18","660","3047","39","1290","101","58","15964","1.4","297","457","1"
"apache-carbondata","852ab804bcb47b890c5f73feae9a4d2e3b8ef321","2017-03-23 22:14:32","Fixed NPE for double data type without fraction

added test case for double data type
","refs/heads/master","kunal.kapoor@knoldus.in","apache-carbondata","852ab804bcb47b890c5f73feae9a4d2e3b8ef321","24","6","0","3633","412","76","4216","81","6455","991","329","29","44","5060","0","24","58","442","apache-carbondata","852ab804bcb47b890c5f73feae9a4d2e3b8ef321","479","19.2","66","68882","37171","7938","5","1473","152","1920","17.3","2867","76","4.4","5","178","2026","16096","19","665","3047","40","1290","101","59","16063","1.4","297","458","1"
"apache-carbondata","b615892a8908e983e8b4dc0cb26618249a5d3c6f","2017-03-27 07:57:17","[CARBONDATA-818] Make the file_name in carbonindex exactly This closes #696
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","b615892a8908e983e8b4dc0cb26618249a5d3c6f","24","6","0","3633","412","76","4216","81","6460","993","329","29","44","5063","0","24","60","442","apache-carbondata","b615892a8908e983e8b4dc0cb26618249a5d3c6f","479","19.2","66","68903","37189","7941","5","1473","149","1920","17.3","2870","76","4.4","5","178","2026","16105","19","665","3006","40","1290","101","59","16033","1.4","297","458","1"
"apache-carbondata","6a9c79c281532c10d8f1bdd00da18c6367f9435b","2017-03-23 07:07:38","Fixed message fails with outofbound exception in dictionary server
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","6a9c79c281532c10d8f1bdd00da18c6367f9435b","24","6","0","3633","412","76","4216","81","6460","993","329","29","44","5063","0","24","60","442","apache-carbondata","6a9c79c281532c10d8f1bdd00da18c6367f9435b","479","19.2","66","68896","37186","7940","5","1473","149","1920","17.3","2869","76","4.4","5","178","2026","16104","19","665","3006","40","1290","101","59","16033","1.4","297","458","1"
"apache-carbondata","c41bdc04d49e762e801dd1ec769268cbf4bbde23","2017-03-26 04:20:17","Fixed colgrp testcases for vectorized set to true
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","c41bdc04d49e762e801dd1ec769268cbf4bbde23","24","6","0","3631","412","76","4216","81","6458","993","329","29","44","5063","0","24","60","442","apache-carbondata","c41bdc04d49e762e801dd1ec769268cbf4bbde23","479","19.2","66","68883","37178","7940","5","1473","149","1920","17.3","2869","76","4.4","5","178","2026","16098","19","665","3006","40","1290","101","59","16033","1.4","297","458","1"
"apache-carbondata","00e902c5c8a182b28ad36e4bf2528a6e53830140","2017-03-23 05:45:22","change vectorized reader default to true
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","00e902c5c8a182b28ad36e4bf2528a6e53830140","24","6","0","3631","412","76","4216","81","6458","993","329","29","44","5061","0","24","60","442","apache-carbondata","00e902c5c8a182b28ad36e4bf2528a6e53830140","479","19.2","66","68882","37177","7940","5","1474","151","1921","17.3","2869","77","4.4","5","178","2027","16098","19","665","3044","40","1290","101","59","16063","1.4","297","458","1"
"apache-carbondata","da4d39eb26d2baff1acf3e41b6991b5239ccef3b","2017-03-25 00:38:23","Store fileName insteads of filePath in carbonindex.
","refs/heads/master","qiyadong2010@gmail.com","apache-carbondata","da4d39eb26d2baff1acf3e41b6991b5239ccef3b","24","6","0","3631","412","76","4216","81","6458","993","329","29","44","5061","0","24","60","442","apache-carbondata","da4d39eb26d2baff1acf3e41b6991b5239ccef3b","479","19.2","66","68889","37180","7941","5","1474","151","1921","17.3","2870","77","4.4","5","178","2027","16099","19","665","3044","40","1290","101","59","16065","1.4","297","458","1"
"apache-carbondata","542fcb921ac32eeb8b26e484dbd60b9b5fb16e8c","2017-03-23 06:44:13","Refactor dictionary based result collector class.
Initialization of variables is moved to constructor. So that initialization is done only once on object creation instead of running a business logic.
","refs/heads/master","srinath.thota@outlook.com","apache-carbondata","542fcb921ac32eeb8b26e484dbd60b9b5fb16e8c","24","6","0","3631","412","76","4216","81","6458","993","329","29","44","5061","0","24","60","442","apache-carbondata","542fcb921ac32eeb8b26e484dbd60b9b5fb16e8c","479","19.2","66","68882","37177","7940","5","1474","151","1921","17.3","2869","77","4.4","5","178","2027","16098","19","665","3044","40","1290","101","59","16065","1.4","297","458","1"
"apache-carbondata","c2e4eb24ddcb94fcb5d1bdb6e09110ae89accb8e","2017-03-15 09:06:16","[CARBONDATA-792] Range Filter Optimization
","refs/heads/master","sounakr@gmail.com","apache-carbondata","c2e4eb24ddcb94fcb5d1bdb6e09110ae89accb8e","24","6","0","3629","412","76","4216","81","6461","992","329","29","44","5061","0","24","60","442","apache-carbondata","c2e4eb24ddcb94fcb5d1bdb6e09110ae89accb8e","479","19.2","66","68879","37177","7940","5","1474","151","1921","17.3","2869","77","4.5","5","178","2027","16097","19","665","3068","40","1290","101","59","16065","1.4","297","458","1"
"apache-carbondata","040982b6a04ac6a195cbb4738398b24e9c38f851","2017-03-21 00:40:31","change currenr to current","refs/heads/master","simafengyun1984@163.com","apache-carbondata","040982b6a04ac6a195cbb4738398b24e9c38f851","22","6","0","3478","387","76","4148","81","6270","919","328","29","44","4868","0","21","53","274","apache-carbondata","040982b6a04ac6a195cbb4738398b24e9c38f851","464","19.2","66","66923","36044","7607","5","1398","144","1804","17.2","2800","74","4.4","5","178","1910","15608","19","665","2963","40","1290","100","59","15265","1.4","256","443","1"
"apache-carbondata","4f915d102a5f6186aed5a74cfe23a0a81ea62aee","2017-03-20 04:43:02","When data contains long max and min values for a measure column with bigInt datatype, the delta compression selected is DATA_BYTE which is incorrect. For selecting the delta compression min value is decremented from max value and here the min value is negative, so it performs addition operation and goes out of long range. When a long value goes out of range it starts again from the long max negative value which results in wrong compression selection.
This leads to data loss and incorrect query results.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","4f915d102a5f6186aed5a74cfe23a0a81ea62aee","22","6","0","3478","387","76","4148","81","6270","919","328","29","44","4868","0","21","53","274","apache-carbondata","4f915d102a5f6186aed5a74cfe23a0a81ea62aee","464","19.2","66","66923","36044","7607","5","1398","144","1804","17.2","2800","74","4.4","5","178","1910","15608","19","665","2963","40","1290","100","59","15265","1.4","256","443","1"
"apache-carbondata","b13ead9c8ef419db7f2807b3828653ba9b0d853a","2017-03-01 08:27:32","Added batch sort to improve the loading performance

Fixed comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b13ead9c8ef419db7f2807b3828653ba9b0d853a","22","6","0","3476","387","76","4148","81","6271","919","328","29","44","4868","0","21","53","274","apache-carbondata","b13ead9c8ef419db7f2807b3828653ba9b0d853a","464","19.2","66","66915","36040","7606","5","1397","144","1803","17.2","2800","74","4.4","5","178","1909","15605","19","665","2963","40","1290","100","59","15250","1.4","256","443","1"
"apache-carbondata","248c5bb640c55c56982148c2435fc9026068287d","2017-03-17 23:54:03","Fixed exists query in carbon2.1
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","248c5bb640c55c56982148c2435fc9026068287d","22","6","0","3471","385","76","4132","83","6253","921","328","29","44","4851","0","21","53","268","apache-carbondata","248c5bb640c55c56982148c2435fc9026068287d","464","19.2","68","66861","36002","7599","5","1395","142","1803","17.2","2798","73","4.3","5","182","1911","15585","19","665","2897","40","1330","100","59","15380","1.4","256","443","1"
"apache-carbondata","3eedfa015933f984d2d7c41fd7844949df612d7a","2017-03-17 07:01:59","Added statistics for scan and read Time
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","3eedfa015933f984d2d7c41fd7844949df612d7a","22","6","0","3471","385","76","4132","83","6253","921","328","29","44","4851","0","21","53","268","apache-carbondata","3eedfa015933f984d2d7c41fd7844949df612d7a","464","19.2","68","66861","36002","7599","5","1395","142","1803","17.2","2798","73","4.3","5","182","1911","15585","19","665","2897","40","1330","100","59","15380","1.4","256","443","1"
"apache-carbondata","b282e50d95bcf0249b29eb3dd4327f3227dad411","2017-03-16 12:18:26","Modified optimizer to place decoder on top of limit in case of sort and limit.

Fixed comments.
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b282e50d95bcf0249b29eb3dd4327f3227dad411","22","6","0","3470","385","76","4124","83","6243","919","328","29","44","4829","0","21","53","268","apache-carbondata","b282e50d95bcf0249b29eb3dd4327f3227dad411","464","19.2","68","66831","35972","7599","5","1395","142","1799","17.2","2798","73","4.3","5","182","1907","15566","19","665","2897","40","1330","100","59","15371","1.4","252","443","1"
"apache-carbondata","3251c8941c2ba088cfcf3bd9ca9e6a7563e6bf67","2017-03-08 02:04:00","[CARBONDATA-784] Bad record making configurable empty data not a bad record.
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","3251c8941c2ba088cfcf3bd9ca9e6a7563e6bf67","22","6","0","3470","385","76","4124","83","6243","919","328","29","44","4829","0","21","53","268","apache-carbondata","3251c8941c2ba088cfcf3bd9ca9e6a7563e6bf67","464","19.2","66","66824","35969","7598","5","1395","142","1799","17.2","2798","73","4.3","5","180","1905","15565","19","665","2897","40","1300","100","59","15371","1.4","252","443","1"
"apache-carbondata","1f3efe339221f59ad3513eae6fcdb73115c1e6bc","2017-03-16 10:05:06","Fixed memory leak in offhep during query
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","1f3efe339221f59ad3513eae6fcdb73115c1e6bc","22","6","0","3468","385","76","4120","83","6243","919","328","29","44","4829","0","21","53","268","apache-carbondata","1f3efe339221f59ad3513eae6fcdb73115c1e6bc","464","19.2","66","66821","35968","7598","5","1395","142","1799","17.2","2798","73","4.3","5","180","1905","15565","19","665","2897","40","1300","100","59","15371","1.4","252","443","1"
"apache-carbondata","6b1ab2a85cf9ef11fc0a9189853e38e1e515d727","2017-03-16 04:45:16","Fixed data mismatch due to min/max calculation in V3 format

Fixed data mismatch due to min/max calculation in V3 format
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","6b1ab2a85cf9ef11fc0a9189853e38e1e515d727","22","6","0","3467","378","76","4106","82","6237","920","328","29","44","4791","0","21","54","266","apache-carbondata","6b1ab2a85cf9ef11fc0a9189853e38e1e515d727","464","19.2","65","66719","35889","7569","5","1391","142","1793","17.1","2795","73","4.3","5","179","1898","15514","19","665","2897","40","1280","100","59","15319","1.4","250","443","1"
"apache-carbondata","06efc20f9851cbecaff46b553c8bd10f53316e17","2017-03-15 21:52:49","Fix for spark version 1.6.2 test cases
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","06efc20f9851cbecaff46b553c8bd10f53316e17","22","6","0","3467","371","76","4106","82","6234","920","328","29","44","4781","0","21","54","266","apache-carbondata","06efc20f9851cbecaff46b553c8bd10f53316e17","464","19.2","65","66702","35875","7565","5","1390","142","1792","17.1","2795","73","4.3","5","179","1897","15503","19","665","2897","40","1280","100","59","15306","1.4","250","443","1"
"apache-carbondata","6b3b16c5971bd383f7ed4bb3ae2164b378044020","2017-03-14 22:20:49","Handled review comments
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","6b3b16c5971bd383f7ed4bb3ae2164b378044020","22","6","0","3467","372","76","4108","82","6234","915","328","29","44","4786","0","21","54","266","apache-carbondata","6b3b16c5971bd383f7ed4bb3ae2164b378044020","464","19.2","65","66746","35914","7588","5","1383","140","1785","17.1","2796","71","4.3","5","177","1888","15524","19","605","2859","38","1280","100","59","15275","1.4","250","443","1"
"apache-carbondata","35739e5eb24f3c4ff94a04d970ed889d9810c6f0","2017-03-13 04:20:52","Changes done to support split of schema string and store it in the table properties
Added more testcases for alter table validations.
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","35739e5eb24f3c4ff94a04d970ed889d9810c6f0","22","6","0","3426","382","76","4098","82","6269","929","328","29","44","4789","0","24","53","266","apache-carbondata","35739e5eb24f3c4ff94a04d970ed889d9810c6f0","462","19.1","65","66644","35950","7597","5","1397","146","1800","17.2","2777","71","4.5","5","179","1904","15615","18","655","3007","39","1280","100","58","15484","1.4","252","441","1"
"apache-carbondata","fc1af96307fbd2344007740441951638e676f1f4","2017-03-10 03:49:45","support compaction for restructure
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","fc1af96307fbd2344007740441951638e676f1f4","22","6","0","3424","382","76","4094","82","6267","929","328","29","44","4741","0","24","53","266","apache-carbondata","fc1af96307fbd2344007740441951638e676f1f4","462","19.1","65","66630","35932","7594","5","1397","146","1800","17.2","2775","71","4.5","5","179","1904","15604","18","655","3007","39","1280","100","58","15484","1.4","252","441","1"
"apache-carbondata","70256e7749d72d13d28e48170b93878a8af61b3e","2017-03-09 21:23:44","Following changes are done as part of this commit.

1. Support alter table result preparation.
2. Support reading data with different block key generators.
3. Support addition of a new column.
4. Support deletion of a column.
5. Support change in data type form INT to BIGINT
6. Support Change of decimal datatype from lower to higher precision.
7. Support filtering on newly added columns.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","70256e7749d72d13d28e48170b93878a8af61b3e","23","6","0","3428","382","76","4116","82","6274","932","328","29","44","4762","0","24","52","266","apache-carbondata","70256e7749d72d13d28e48170b93878a8af61b3e","462","19.2","65","66716","35990","7609","5","1401","146","1805","17.3","2778","71","4.5","5","179","1909","15622","18","655","3007","39","1280","100","58","15512","1.4","253","441","1"
"apache-carbondata","fc3b61606606f430f19d77ce3adab2ccaaca1d07","2017-03-03 01:57:37","[CARBONDATA-744] he property ""spark.carbon.custom.distribution"" should be change to carbon.custom.block.distribution and should be part of CarbonProperties
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","fc3b61606606f430f19d77ce3adab2ccaaca1d07","20","6","0","3345","363","75","3832","81","6009","891","323","29","44","4504","0","19","48","268","apache-carbondata","fc3b61606606f430f19d77ce3adab2ccaaca1d07","455","19.4","65","64650","34534","7290","5","1342","128","1738","16.8","2722","67","4.1","5","177","1841","14877","17","645","2637","38","1280","100","59","14536","1.4","246","434","1"
"apache-carbondata","bfc7e64fed9329531b96b12d772e6714ba42ba22","2017-03-15 05:08:19","Fixed null filter issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","bfc7e64fed9329531b96b12d772e6714ba42ba22","20","6","0","3343","363","75","3828","81","6009","891","323","29","44","4504","0","19","48","268","apache-carbondata","bfc7e64fed9329531b96b12d772e6714ba42ba22","455","19.4","65","64648","34532","7290","5","1342","128","1738","16.8","2722","67","4.1","5","177","1841","14877","17","645","2637","38","1280","100","59","14534","1.4","246","434","1"
"apache-carbondata","f1f458100f4f1ec0d5a29bac4cdc7dfcce1298a3","2017-03-14 02:02:56","Fixed filter not null issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","f1f458100f4f1ec0d5a29bac4cdc7dfcce1298a3","20","6","0","3343","363","75","3828","81","6009","891","323","29","44","4504","0","19","48","268","apache-carbondata","f1f458100f4f1ec0d5a29bac4cdc7dfcce1298a3","455","19.4","65","64648","34532","7290","5","1342","128","1738","16.8","2722","67","4.1","5","177","1841","14877","17","645","2637","38","1280","100","59","14534","1.4","246","434","1"
"apache-carbondata","9e11e13c52eab3959c6bc1b4dafb587fbbb85965","2017-03-08 07:12:48","bad record fail action
","refs/heads/master","akash.r.nilugal@huawei.com","apache-carbondata","9e11e13c52eab3959c6bc1b4dafb587fbbb85965","20","6","0","3343","363","75","3828","82","6009","892","323","29","44","4502","0","19","48","268","apache-carbondata","9e11e13c52eab3959c6bc1b4dafb587fbbb85965","455","19.4","65","64629","34517","7286","5","1342","128","1740","16.8","2722","67","4.1","5","178","1843","14868","17","645","2637","38","1280","100","59","14549","1.4","247","434","1"
"apache-carbondata","ebf13dc7d52c1ac07f6653399ad1e1e17cd96877","2017-03-12 08:58:36","Size based blocklet
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","ebf13dc7d52c1ac07f6653399ad1e1e17cd96877","20","6","0","3343","363","75","3828","82","6009","892","323","29","44","4502","0","19","48","268","apache-carbondata","ebf13dc7d52c1ac07f6653399ad1e1e17cd96877","455","19.4","65","64625","34516","7286","5","1342","128","1740","16.8","2722","67","4.1","5","178","1843","14868","17","645","2637","38","1280","100","59","14549","1.4","247","434","1"
"apache-carbondata","5172ec4845f437a5553c1a0b33e096bcb8b279b5","2017-03-06 22:37:48","Fixed loading issues in TPC-DS data
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","5172ec4845f437a5553c1a0b33e096bcb8b279b5","20","6","0","3340","363","76","3830","82","5989","891","323","29","44","4458","0","19","48","268","apache-carbondata","5172ec4845f437a5553c1a0b33e096bcb8b279b5","455","19.4","65","64538","34448","7278","5","1338","128","1734","16.8","2721","67","4.1","5","178","1837","14816","17","645","2637","38","1280","100","56","14546","1.4","248","434","1"
"apache-carbondata","7a0fcb25010ab60bd9f382089e89f06985cdcc16","2017-03-10 03:13:24","Fixed RLE Encoding Issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","7a0fcb25010ab60bd9f382089e89f06985cdcc16","20","6","0","3340","363","76","3830","82","5989","891","323","29","44","4458","0","19","48","268","apache-carbondata","7a0fcb25010ab60bd9f382089e89f06985cdcc16","455","19.4","65","64538","34448","7278","5","1338","128","1734","16.8","2721","67","4.1","5","178","1837","14816","17","645","2637","38","1280","100","56","14546","1.4","248","434","1"
"apache-carbondata","399e9687eee3544141a44d49374b2b2fb3219710","2017-03-11 18:51:36","put if clause out of the for clause and add test case

remove blank row

remove blank row

add test comment

add  test comment

add comments for test case make it is easy to read

add comments for baseFilteredValue
","refs/heads/master","simafengyun1984@163.com","apache-carbondata","399e9687eee3544141a44d49374b2b2fb3219710","20","6","0","3340","363","76","3830","82","5987","890","323","29","44","4462","0","19","48","268","apache-carbondata","399e9687eee3544141a44d49374b2b2fb3219710","455","19.4","65","64526","34439","7276","5","1338","128","1734","16.8","2720","67","4.1","5","178","1837","14809","17","645","2641","38","1280","100","56","14546","1.4","248","434","1"
"apache-carbondata","bedaa59ef298fdf12be4641d239b14c05368ea5b","2017-03-08 21:13:22","use binary search to improve the performance in method
setFilterdIndexToBitSet

add binary range search and add test case

revert previous change

format changed code

change code format to pass check style

revert the code to use inverted index

add comments and change variables definition style
","refs/heads/master","mayun@10.100.56.61","apache-carbondata","bedaa59ef298fdf12be4641d239b14c05368ea5b","20","6","0","3340","363","76","3830","82","5987","890","323","29","44","4462","0","19","48","268","apache-carbondata","bedaa59ef298fdf12be4641d239b14c05368ea5b","455","19.4","65","64529","34439","7275","5","1338","128","1734","16.8","2720","67","4.1","5","178","1837","14809","17","645","2641","38","1280","100","56","14546","1.4","248","434","1"
"apache-carbondata","dbe35de430c05b72d427e695e980be5f920e6de6","2017-03-08 01:20:58","[CARBONDATA-739] Avoid creating multipul instance of directDictionaryGenerator

remove one empty line

use array to replace arraylist

fix format error { is not preceded with whitespace
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","dbe35de430c05b72d427e695e980be5f920e6de6","20","6","0","3338","363","76","3828","82","5976","886","323","29","44","4462","0","19","48","268","apache-carbondata","dbe35de430c05b72d427e695e980be5f920e6de6","455","19.4","65","64436","34391","7256","5","1333","126","1729","16.7","2717","66","4.1","5","178","1832","14780","17","645","2620","38","1280","100","56","14516","1.4","248","434","1"
"apache-carbondata","b41e48f1a41394eb0307ecf7308b3422029e7720","2017-03-07 04:54:13","Adding Header And Making Footer Optional
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","b41e48f1a41394eb0307ecf7308b3422029e7720","20","6","0","3338","363","76","3828","82","5977","886","323","29","44","4461","0","19","48","268","apache-carbondata","b41e48f1a41394eb0307ecf7308b3422029e7720","455","19.4","65","64435","34392","7255","5","1333","126","1729","16.7","2717","66","4.1","5","178","1832","14778","17","645","2620","38","1280","100","56","14515","1.4","248","434","1"
"apache-carbondata","374b00f8fd96672a689149e98c069f00d1b25cb1","2017-03-08 05:19:10","Fix Date and Timestamp format issues

Fix Date and Timestamp format issues

Fix comments

fix scala style issues
","refs/heads/master","chenliang613@huawei.com","apache-carbondata","374b00f8fd96672a689149e98c069f00d1b25cb1","20","6","0","3329","363","76","3824","82","5962","883","323","29","44","4454","0","19","48","268","apache-carbondata","374b00f8fd96672a689149e98c069f00d1b25cb1","453","19.3","65","64208","34307","7241","5","1333","129","1728","16.8","2706","66","4.1","5","178","1831","14749","17","645","2647","38","1280","100","55","14543","1.4","248","432","1"
"apache-carbondata","d246dae22554472c336b4507672b915ffcb2eac7","2017-03-08 21:51:39","remove useless classes
","refs/heads/master","whucaolu@gmail.com","apache-carbondata","d246dae22554472c336b4507672b915ffcb2eac7","20","6","0","3329","363","76","3824","82","5962","883","323","29","44","4454","0","19","48","268","apache-carbondata","d246dae22554472c336b4507672b915ffcb2eac7","453","19.3","65","64206","34307","7241","5","1333","129","1728","16.8","2706","66","4.1","5","178","1831","14749","17","645","2647","38","1280","100","55","14543","1.4","248","432","1"
"apache-carbondata","c79bd5255a3dac9ea7db698f23046d56e95d399f","2017-02-28 02:28:02","Dictionary performance issue with multiple task in same executor
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","c79bd5255a3dac9ea7db698f23046d56e95d399f","20","6","0","3356","363","76","3824","82","5988","891","323","29","44","4457","0","19","48","268","apache-carbondata","c79bd5255a3dac9ea7db698f23046d56e95d399f","455","19.3","65","64451","34459","7287","5","1336","129","1731","16.8","2722","66","4.1","5","178","1834","14814","17","645","2647","38","1280","101","55","14567","1.4","248","434","1"
"apache-carbondata","b16c30885e706764bbcd87adaf850a88b1411698","2017-02-28 03:21:50","FixedTestcasefailureIssue

Fixed failure for V1 format
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","b16c30885e706764bbcd87adaf850a88b1411698","20","6","0","3355","363","76","3822","82","5989","892","323","29","44","4457","0","19","48","268","apache-carbondata","b16c30885e706764bbcd87adaf850a88b1411698","455","19.3","65","64429","34445","7285","5","1334","129","1730","16.8","2722","66","4.1","5","178","1833","14805","17","645","2661","38","1280","101","55","14534","1.4","249","434","1"
"apache-carbondata","96a75b30ae327475d22db152eaed7853dca9799c","2016-09-08 00:48:03","Save useInvertedIndex info into thrift store

Save useInvertedIndex info into thrift store

Fix the judge of no_dic_col

add commont

style

Add comment
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","96a75b30ae327475d22db152eaed7853dca9799c","20","6","0","3351","363","76","3822","82","5997","885","320","29","44","4459","0","18","46","268","apache-carbondata","96a75b30ae327475d22db152eaed7853dca9799c","454","19.2","65","64378","34451","7286","5","1336","127","1732","16.8","2720","64","4.1","5","178","1835","14811","17","645","2621","38","1280","101","55","14506","1.4","249","433","1"
"apache-carbondata","acddd69ceae015db2d5e9f3f891506df23696b33","2017-02-26 08:23:39","fix compile issue for spark1.5 integration
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","acddd69ceae015db2d5e9f3f891506df23696b33","20","6","0","3350","363","76","3822","82","5997","884","320","29","44","4459","0","18","46","268","apache-carbondata","acddd69ceae015db2d5e9f3f891506df23696b33","454","19.3","65","64371","34441","7280","5","1336","127","1732","16.8","2718","64","4.1","5","178","1835","14806","17","645","2621","38","1280","101","55","14506","1.4","249","433","1"
"apache-carbondata","2cf1104db43a5591fe2bcabb97ba02202428132a","2017-02-23 00:44:41","Added V3 Format Writer and Reader Code

Added code to support V3 Writer + Reader
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","2cf1104db43a5591fe2bcabb97ba02202428132a","20","6","0","3350","363","76","3822","82","5997","884","320","29","42","4459","0","18","46","268","apache-carbondata","2cf1104db43a5591fe2bcabb97ba02202428132a","454","19.3","65","64372","34442","7280","5","1336","127","1732","16.8","2718","64","4.1","5","178","1835","14806","17","645","2621","38","1280","101","55","14506","1.4","249","433","1"
"apache-carbondata","87dade7aaf25c5334620f7a4a56d62b3361e4755","2017-02-20 17:15:09","Optimized and upgraded Dictionary Server

Added multi dictionary clients for each thread

removed comment

Fixed comments

Fixed comments

Fixed style
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","87dade7aaf25c5334620f7a4a56d62b3361e4755","20","4","0","3258","361","75","3628","82","5775","876","270","29","42","4112","0","18","41","262","apache-carbondata","87dade7aaf25c5334620f7a4a56d62b3361e4755","444","19.2","65","62207","33184","7099","5","1291","120","1681","16.8","2661","57","3.9","5","178","1784","14174","17","645","2422","38","1280","99","51","14045","1.4","247","423","1"
"apache-carbondata","72cb415a1e1126882c38ecfead01dc6b7bb4cc07","2017-02-03 02:41:06","WIP Added code for new V3 format to optimize scan

Fixed testcases

Fixed style

Fixed issue

Added read a head blocklet PR to it

fixed style

Refactored code

Added read a head blocklet

Optimized decoder

Updated code of V3 format interfaces

OPtimized greater than and less than filters

Fixed col group queries

Refactored V1 format with new interface

Fixed complex query

Fixed comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","72cb415a1e1126882c38ecfead01dc6b7bb4cc07","20","4","0","3249","361","75","3640","73","5771","877","270","29","40","4122","0","18","42","262","apache-carbondata","72cb415a1e1126882c38ecfead01dc6b7bb4cc07","443","19.3","61","62149","33126","7074","5","1297","120","1688","16.7","2655","57","3.9","5","175","1788","14148","18","670","2422","39","1200","99","51","14136","1.4","247","423","1"
"apache-carbondata","d024b9fc05c76255f3cc1f343783d528c36eccd4","2017-02-21 02:42:42","[CARBONDATA-716] fix invalid hdfs lock path if config viewfs
","refs/heads/master","hexiaoqiao@meituan.com","apache-carbondata","d024b9fc05c76255f3cc1f343783d528c36eccd4","20","4","0","3135","352","73","3578","66","5566","863","252","29","37","3942","0","16","42","262","apache-carbondata","d024b9fc05c76255f3cc1f343783d528c36eccd4","440","19.6","57","60946","32208","6860","5","1293","108","1682","16.3","2587","57","3.6","5","172","1779","13691","19","700","2215","40","1120","99","51","14015","1.5","244","420","1"
"apache-carbondata","c5aba5f518a8ea5d5907273c1782df4f9015746a","2017-02-08 08:22:03","fix memory issue for dataloading

fix comment

fix comments
","refs/heads/master","qiangcai@qq.com","apache-carbondata","c5aba5f518a8ea5d5907273c1782df4f9015746a","20","4","0","3135","352","73","3578","66","5566","863","252","29","37","3942","0","16","42","262","apache-carbondata","c5aba5f518a8ea5d5907273c1782df4f9015746a","440","19.6","57","60941","32206","6859","5","1293","108","1682","16.3","2587","57","3.6","5","172","1779","13691","19","700","2215","40","1120","99","51","14015","1.5","244","420","1"
"apache-carbondata","256dbed257b76c3be836f43d9b6981e71e2d45a5","2017-01-15 09:38:25","add WhitespaceAround and ParenPad
","refs/heads/master","qiangcai@qq.com","apache-carbondata","256dbed257b76c3be836f43d9b6981e71e2d45a5","20","4","0","3135","352","73","3574","66","5565","863","252","29","37","3941","0","16","42","262","apache-carbondata","256dbed257b76c3be836f43d9b6981e71e2d45a5","440","19.6","57","60915","32186","6855","5","1293","108","1682","16.3","2586","57","3.6","5","172","1779","13683","19","700","2215","40","1120","99","51","14013","1.5","244","420","1"
"apache-carbondata","e5d26701caced3d793d1f43823744e5c2e303ae4","2017-01-18 22:41:16","code cleanup
","refs/heads/master","jihongma@apache.org","apache-carbondata","e5d26701caced3d793d1f43823744e5c2e303ae4","20","4","0","3135","352","73","3574","66","5565","863","252","29","37","3941","0","16","42","262","apache-carbondata","e5d26701caced3d793d1f43823744e5c2e303ae4","440","19.6","57","60917","32186","6855","5","1294","108","1683","16.3","2586","57","3.6","5","172","1780","13683","19","700","2215","40","1120","99","51","14018","1.5","244","420","1"
"apache-carbondata","5e94cffdc7ad528d602c4fb1a6114607a92c9a91","2017-01-21 07:03:45","Code clean
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","5e94cffdc7ad528d602c4fb1a6114607a92c9a91","20","4","0","3142","353","73","3572","66","5592","870","252","29","37","3963","0","16","42","262","apache-carbondata","5e94cffdc7ad528d602c4fb1a6114607a92c9a91","440","19.7","57","61149","32284","6881","5","1297","106","1686","16.4","2608","57","3.7","5","172","1783","13732","19","700","2239","40","1120","99","51","14033","1.4","244","420","1"
"apache-carbondata","f94bae5eb68646987685ab740161b9d8820d8f69","2017-01-20 08:35:30","Fixed Compatibility issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","f94bae5eb68646987685ab740161b9d8820d8f69","20","4","0","3143","353","73","3576","66","5596","871","252","29","37","3965","0","16","42","262","apache-carbondata","f94bae5eb68646987685ab740161b9d8820d8f69","440","19.7","57","61171","32303","6889","5","1300","106","1689","16.4","2609","57","3.7","5","172","1786","13743","19","700","2239","40","1120","99","51","14123","1.5","244","420","1"
"apache-carbondata","9e24a3dd726a0aba87e00e1becff4cb8817519eb","2017-01-19 15:15:16","Reverting big decimal compression as it has below issue
when big decimal scale value is more then 18 then result is not accurate

Fixed big decimal reader issue
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","9e24a3dd726a0aba87e00e1becff4cb8817519eb","20","4","0","3143","353","73","3576","66","5596","870","252","29","37","3963","0","16","42","262","apache-carbondata","9e24a3dd726a0aba87e00e1becff4cb8817519eb","440","19.7","57","61161","32295","6883","5","1298","106","1687","16.4","2609","57","3.7","5","172","1784","13740","19","700","2239","40","1120","99","51","14102","1.5","244","420","1"
"apache-carbondata","c33e5b29f196a7f409a993a0c489950e91747cd9","2017-01-20 05:19:36","Fixed Date issue when date is less the 1970
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","c33e5b29f196a7f409a993a0c489950e91747cd9","20","4","0","3123","352","74","3602","67","5555","875","255","29","38","3970","0","16","40","258","apache-carbondata","c33e5b29f196a7f409a993a0c489950e91747cd9","440","19.6","58","61121","32297","6889","5","1279","88","1668","16.4","2611","46","3.2","5","173","1766","13792","20","700","1972","40","1140","100","51","13752","1.4","243","420","1"
"apache-carbondata","733968b4e0cdba12c928554a04f836c7b36477f3","2017-01-05 05:15:51","[CARBONDATA-341] CarbonTableIdentifier being passed to the query flow has wrong tableid
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","733968b4e0cdba12c928554a04f836c7b36477f3","20","4","0","3122","352","74","3600","67","5555","875","255","29","38","3970","0","16","40","258","apache-carbondata","733968b4e0cdba12c928554a04f836c7b36477f3","440","19.6","58","61120","32296","6889","5","1279","88","1667","16.4","2611","46","3.2","5","173","1765","13792","20","700","1972","40","1140","100","51","13750","1.4","242","420","1"
"apache-carbondata","6650c635d6a25942cd4fa8552a1dda141a84b5e2","2017-01-17 02:03:10","CleanupTask : Removed
1. Author names
2. DTS ids
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","6650c635d6a25942cd4fa8552a1dda141a84b5e2","20","4","0","3123","352","74","3600","67","5555","875","255","29","38","3970","0","16","40","258","apache-carbondata","6650c635d6a25942cd4fa8552a1dda141a84b5e2","440","19.5","58","61112","32296","6889","5","1279","88","1667","16.4","2611","46","3.2","5","173","1765","13792","20","700","1972","40","1140","100","51","13750","1.4","242","420","1"
"apache-carbondata","4543de6220191289335946fcc2284a542e5d562c","2017-01-19 07:53:13","Fixed random test case failure
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","4543de6220191289335946fcc2284a542e5d562c","20","4","0","3123","352","74","3600","67","5555","875","255","29","38","3970","0","16","40","258","apache-carbondata","4543de6220191289335946fcc2284a542e5d562c","440","19.5","58","61116","32296","6889","5","1279","88","1667","16.4","2611","46","3.2","5","173","1765","13792","20","700","1972","40","1140","100","51","13750","1.4","242","420","1"
"apache-carbondata","ea04fce1d6df2a56ec8e40f6dd4716ab61b8d6f8","2017-01-11 04:29:31","Date filter fix issue-CARBONDATA-603
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","ea04fce1d6df2a56ec8e40f6dd4716ab61b8d6f8","20","4","0","3123","352","74","3600","67","5555","875","255","29","38","3969","0","16","40","258","apache-carbondata","ea04fce1d6df2a56ec8e40f6dd4716ab61b8d6f8","440","19.6","58","61116","32294","6888","5","1279","88","1667","16.4","2611","46","3.2","5","173","1765","13791","20","700","1972","40","1140","100","51","13750","1.4","242","420","1"
"apache-carbondata","7d5a031c2b90023d0b332f64bf6088dce61b26b2","2017-01-17 09:53:59","Make no kettle flow as default

Added use_kettle property to carbon properties

Fixed style

Fixed error

Fixed comment
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7d5a031c2b90023d0b332f64bf6088dce61b26b2","20","4","0","3119","352","74","3592","67","5546","873","255","29","38","3962","0","16","40","258","apache-carbondata","7d5a031c2b90023d0b332f64bf6088dce61b26b2","440","19.6","58","61052","32248","6873","5","1275","88","1664","16.4","2610","46","3.3","5","173","1762","13765","20","700","1999","40","1140","100","51","13691","1.4","243","420","1"
"apache-carbondata","9587515136c373896c0c748777dc693f4ee2984c","2017-01-17 05:27:44","Added support file:// for using local file

Added support file:// for using local file with fs.defaultFS is configured

Fixed testcase
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9587515136c373896c0c748777dc693f4ee2984c","20","4","0","3117","352","74","3590","67","5546","873","255","29","38","3962","0","16","40","258","apache-carbondata","9587515136c373896c0c748777dc693f4ee2984c","440","19.6","58","61048","32246","6873","5","1275","88","1664","16.4","2610","46","3.3","5","173","1762","13765","20","700","1999","40","1140","100","51","13689","1.4","243","420","1"
"apache-carbondata","9f99dfb15e377dcbb1fa5eacb26975365c38ac27","2017-01-17 00:39:25","if the compaction type is not minor or major need to give error message to user.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","9f99dfb15e377dcbb1fa5eacb26975365c38ac27","20","4","0","3113","352","74","3590","67","5544","857","255","29","37","3953","0","16","40","258","apache-carbondata","9f99dfb15e377dcbb1fa5eacb26975365c38ac27","440","19.6","58","61007","32219","6865","5","1260","88","1649","16.3","2608","46","3.3","5","173","1747","13744","20","700","1999","40","1140","100","51","13614","1.4","243","420","1"
"apache-carbondata","e7ff93820d9f78d36bef7bfb0c63438ca2d8c82b","2017-01-13 03:38:55","manage parsing for integer value
","refs/heads/master","anurag@knoldus.com","apache-carbondata","e7ff93820d9f78d36bef7bfb0c63438ca2d8c82b","20","4","0","3111","352","74","3590","67","5544","857","255","29","37","3953","0","16","40","258","apache-carbondata","e7ff93820d9f78d36bef7bfb0c63438ca2d8c82b","440","19.6","58","61003","32217","6865","5","1260","88","1649","16.3","2608","46","3.3","5","173","1747","13744","20","700","1999","40","1140","100","51","13614","1.4","243","420","1"
"apache-carbondata","41347d8bfe7133ddf04dd88b0c5dca6819ae14bd","2017-01-14 22:41:11","fix unapproved licenses

fix comment

unify java license header with scala
","refs/heads/master","qiangcai@qq.com","apache-carbondata","41347d8bfe7133ddf04dd88b0c5dca6819ae14bd","20","4","0","3111","352","74","3590","67","5543","857","255","29","37","3952","0","16","40","258","apache-carbondata","41347d8bfe7133ddf04dd88b0c5dca6819ae14bd","440","19.6","58","60997","32210","6862","5","1260","88","1649","16.3","2608","46","3.3","5","173","1747","13739","20","700","1999","40","1140","100","51","13611","1.4","243","420","1"
"apache-carbondata","ce09aaaf76c313b21f535eca9b53e99fb88668fa","2017-01-16 05:18:23","move core package

change update package name

fix style

fix compile
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","ce09aaaf76c313b21f535eca9b53e99fb88668fa","20","4","0","3108","352","74","3590","67","5543","857","255","29","37","3952","0","16","40","258","apache-carbondata","ce09aaaf76c313b21f535eca9b53e99fb88668fa","440","19.6","58","61668","32210","6862","5","1260","88","1649","16.3","2608","46","3.2","5","173","1747","13739","20","700","1999","40","1140","100","51","13611","1.4","243","420","1"
"apache-carbondata","a45ace20368f939980d64ffedd1b08774ce61a81","2017-01-12 20:50:26","fixed offheap crash issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","a45ace20368f939980d64ffedd1b08774ce61a81","20","4","0","3141","352","74","3604","73","5569","885","257","29","41","3962","0","16","40","258","apache-carbondata","a45ace20368f939980d64ffedd1b08774ce61a81","451","19.6","58","62068","32343","6889","5","1265","88","1656","16.2","2626","46","3.2","5","173","1754","13787","20","700","1999","40","1140","109","52","13636","1.4","244","425","1"
"apache-carbondata","8100d949e4264651b09b42a173aa17085369cd82","2017-01-12 10:46:33","Fixed testcase issues in spark 1.6 and 2.1 of no kettle. And also refactored insert into flow of no kettle
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","8100d949e4264651b09b42a173aa17085369cd82","20","4","0","3139","352","74","3604","73","5567","882","257","29","41","3962","0","16","39","258","apache-carbondata","8100d949e4264651b09b42a173aa17085369cd82","451","19.6","58","62040","32321","6887","5","1265","88","1656","16.2","2625","46","3.2","5","173","1754","13780","20","700","1999","40","1140","109","52","13636","1.4","244","425","1"
"apache-carbondata","51425d49b2ba210b505ecc6fd69cf69e763409cd","2017-01-08 09:47:19","Fixed carbondata file version issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","51425d49b2ba210b505ecc6fd69cf69e763409cd","20","4","0","3139","352","74","3600","73","5567","882","257","29","41","3962","0","16","39","258","apache-carbondata","51425d49b2ba210b505ecc6fd69cf69e763409cd","451","19.6","58","62030","32319","6887","5","1265","88","1656","16.2","2625","46","3.2","5","173","1754","13780","20","700","1999","40","1140","109","52","13634","1.4","244","425","1"
"apache-carbondata","9e12ff2c6c3abdee571b0667b8d4821030c09cb3","2017-01-12 18:59:15","fix default profile
","refs/heads/master","qiangcai@qq.com","apache-carbondata","9e12ff2c6c3abdee571b0667b8d4821030c09cb3","20","4","0","3139","352","74","3600","73","5566","882","257","29","41","3962","0","16","39","258","apache-carbondata","9e12ff2c6c3abdee571b0667b8d4821030c09cb3","451","19.6","58","62029","32318","6887","5","1265","88","1656","16.2","2625","46","3.2","5","173","1754","13779","20","700","1999","40","1140","109","52","13634","1.4","244","425","1"
"apache-carbondata","7934d7b8ac03fd98064a213ee01b2b64bece6309","2017-01-11 09:17:42","Fixed measure selection with out table order gives wrong result

Fixed comment
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7934d7b8ac03fd98064a213ee01b2b64bece6309","20","4","0","3118","345","74","3584","73","5512","880","257","17","40","3953","0","16","39","258","apache-carbondata","7934d7b8ac03fd98064a213ee01b2b64bece6309","450","19.7","56","61645","32057","6811","5","1257","88","1634","16.1","2610","46","3.2","5","171","1729","13593","19","685","1999","39","1110","109","51","13545","1.4","231","424","1"
"apache-carbondata","6592cf4d66a10f174fa1e16352cd2e533310027e","2017-01-10 23:32:23","[CARBONDATA-607] Cleanup ValueCompressionHolder class and all sub-classes
","refs/heads/master","jihongma@apache.org","apache-carbondata","6592cf4d66a10f174fa1e16352cd2e533310027e","20","4","0","3117","345","74","3584","73","5512","880","257","17","40","3953","0","16","39","258","apache-carbondata","6592cf4d66a10f174fa1e16352cd2e533310027e","450","19.7","56","61638","32051","6811","5","1257","88","1634","16.1","2610","46","3.2","5","171","1729","13591","19","685","1999","39","1110","109","51","13545","1.4","231","424","1"
"apache-carbondata","7bed18ec95d69de4605d18f09273896b1de2eb67","2017-01-10 00:22:37","Remove the duplicated class CarbonDataWriterException.java
","refs/heads/master","chenliang613@apache.org","apache-carbondata","7bed18ec95d69de4605d18f09273896b1de2eb67","20","4","0","3181","345","74","3590","73","5590","873","240","17","36","3967","0","16","11","258","apache-carbondata","7bed18ec95d69de4605d18f09273896b1de2eb67","452","19.5","56","62176","32485","6935","5","1224","87","1607","16.3","2664","43","3.3","5","173","1704","13761","19","695","2031","41","1110","109","56","13372","1.4","232","425","1"
"apache-carbondata","7af06e6fcef15d0e046ede3cd93b4cb19439d5ab","2017-01-06 01:36:02","Fixed NLP while droping the table with HDFS lock

Fixed comment
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7af06e6fcef15d0e046ede3cd93b4cb19439d5ab","20","4","0","3183","345","74","3592","73","5594","874","240","17","36","3967","0","16","11","260","apache-carbondata","7af06e6fcef15d0e046ede3cd93b4cb19439d5ab","453","19.5","56","62258","32508","6940","5","1227","87","1611","16.3","2669","43","3.3","5","173","1708","13768","19","695","2031","41","1110","110","56","13402","1.4","233","426","1"
"apache-carbondata","c3a462cc7db2f701c241b5ba7522d92dfce8ce09","2017-01-06 00:46:58","change case for default file format as V2 if property is not given

remove style checks in CarbonDataWriterFactory
","refs/heads/master","phalodi@gmail.com","apache-carbondata","c3a462cc7db2f701c241b5ba7522d92dfce8ce09","20","4","0","3183","345","74","3592","73","5593","874","240","17","36","3968","0","16","11","260","apache-carbondata","c3a462cc7db2f701c241b5ba7522d92dfce8ce09","453","19.5","56","62250","32500","6939","5","1227","87","1611","16.3","2669","43","3.3","5","173","1708","13765","19","695","2031","41","1110","110","56","13402","1.4","233","426","1"
"apache-carbondata","8d9babe3cb783b21791c577d1b22cc331e5ce967","2016-12-13 19:33:41","Added support for offheap storage in query
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","8d9babe3cb783b21791c577d1b22cc331e5ce967","20","4","0","3183","345","74","3592","73","5593","871","240","17","36","3968","0","16","11","260","apache-carbondata","8d9babe3cb783b21791c577d1b22cc331e5ce967","453","19.5","56","62259","32508","6947","5","1227","87","1608","16.3","2669","43","3.3","5","173","1705","13769","19","695","2031","41","1110","110","56","13387","1.4","230","426","1"
"apache-carbondata","af2f204e4fbc38b973a26106879c92c0618fba02","2016-12-29 06:43:29","reuse test case for integration module

fix comments
","refs/heads/master","qiangcai@qq.com","apache-carbondata","af2f204e4fbc38b973a26106879c92c0618fba02","21","4","0","3030","353","72","3558","70","5417","871","254","17","36","4064","0","16","9","230","apache-carbondata","af2f204e4fbc38b973a26106879c92c0618fba02","435","18.9","53","60473","31966","6742","5","1222","91","1601","16.5","2506","47","3.3","5","170","1695","13763","18","695","2018","41","1050","107","56","13393","1.4","229","408","1"
"apache-carbondata","9b8090baeaf7a86de8c21043517a6dcc3fa5031d","2017-01-05 06:26:45","Comments on test cases
Handle Null Pointer in Spark2 Empty Table Test Case
test cases were failing due to nullpointer. corrected that.
fixing style issues.
Handled review comments & clean up tasks
IUD Rebase - 05/01
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","9b8090baeaf7a86de8c21043517a6dcc3fa5031d","21","4","0","3030","352","72","3558","70","5417","871","254","17","36","4063","0","16","9","230","apache-carbondata","9b8090baeaf7a86de8c21043517a6dcc3fa5031d","435","18.9","53","60470","31963","6740","5","1221","91","1600","16.5","2506","47","3.3","5","170","1694","13761","18","695","2018","41","1050","107","56","13386","1.4","229","408","1"
"apache-carbondata","c9c68a1c69a29401d95ce8fcdfb2fc57bcd9a638","2017-01-05 01:14:13","Update Test Case Modification and Rectify TimeStamp retrieval from file

(cherry picked from commit 0ae0d9f56023d672236a7ca8965df93a06404757)
","refs/heads/master","sounakr@gmail.com","apache-carbondata","c9c68a1c69a29401d95ce8fcdfb2fc57bcd9a638","21","4","0","3037","352","72","3572","71","5445","873","254","20","41","4072","0","21","12","230","apache-carbondata","c9c68a1c69a29401d95ce8fcdfb2fc57bcd9a638","438","18.9","53","60559","32074","6764","5","1224","91","1612","16.5","2519","47","3.3","5","168","1704","13800","18","665","2018","39","1050","107","56","13424","1.4","238","411","1"
"apache-carbondata","8dda2a8d20bc4e505c597011dad2d70a51ce3377","2017-01-03 08:57:17","commenting the delete test case having subquery.
supporting spark version 2.0.
correcting rebase error.
rebased with latest code.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","8dda2a8d20bc4e505c597011dad2d70a51ce3377","21","4","0","3043","352","74","3578","71","5454","875","254","20","41","4077","0","21","12","230","apache-carbondata","8dda2a8d20bc4e505c597011dad2d70a51ce3377","439","18.9","53","60602","32101","6768","5","1224","91","1617","16.4","2523","47","3.3","5","168","1709","13811","18","665","2018","39","1050","107","56","13449","1.4","243","412","1"
"apache-carbondata","803c32edcb820d747ea5c9e5fe7d9bab0492200f","2017-01-02 08:39:30","corrected the IUD query processing flow
","refs/heads/master","sounakr@gmail.com","apache-carbondata","803c32edcb820d747ea5c9e5fe7d9bab0492200f","21","4","0","3044","350","73","3582","71","5454","874","254","20","43","4059","0","23","11","230","apache-carbondata","803c32edcb820d747ea5c9e5fe7d9bab0492200f","439","18.9","53","60577","32081","6762","5","1225","91","1616","16.4","2523","47","3.3","5","168","1708","13799","18","665","2018","39","1050","107","56","13439","1.4","241","412","1"
"apache-carbondata","002279ec24f7b4cbbec2413346aa0f10bff4c72c","2017-01-01 23:34:47","IUD checkstyle and scalasytle fixes
","refs/heads/master","carbondatacontributions@gmail.com","apache-carbondata","002279ec24f7b4cbbec2413346aa0f10bff4c72c","21","4","0","3043","350","74","3574","71","5439","874","254","20","39","4047","0","19","11","226","apache-carbondata","002279ec24f7b4cbbec2413346aa0f10bff4c72c","439","18.9","53","60495","32020","6747","5","1224","91","1615","16.4","2518","47","3.3","5","168","1707","13782","18","665","2020","39","1050","107","56","13448","1.4","241","412","1"
"apache-carbondata","cdae9ed4d1ac37422d3e1d1d7257b753a29afbc2","2017-01-01 23:06:11","IUD horizontal compaction of update and delete delta files support
","refs/heads/master","sounakr@gmail.com","apache-carbondata","cdae9ed4d1ac37422d3e1d1d7257b753a29afbc2","21","4","0","3042","350","74","3566","65","5434","874","254","20","41","4046","0","21","10","226","apache-carbondata","cdae9ed4d1ac37422d3e1d1d7257b753a29afbc2","439","18.9","51","60455","31996","6738","5","1222","91","1615","16.4","2517","47","3.3","5","168","1705","13767","16","665","2020","39","1010","107","56","13432","1.4","243","412","1"
"apache-carbondata","d0b4a981d80dce839a7339f4c02192f26051acb8","2017-01-01 22:11:37","IUD Integration to query flow
","refs/heads/master","g.ramana.v@gmail.com","apache-carbondata","d0b4a981d80dce839a7339f4c02192f26051acb8","21","4","0","3039","349","74","3558","65","5431","873","254","20","41","4044","0","21","10","226","apache-carbondata","d0b4a981d80dce839a7339f4c02192f26051acb8","439","18.9","51","60413","31971","6736","5","1222","91","1614","16.3","2515","47","3.3","5","168","1704","13760","16","665","2020","39","1010","107","56","13427","1.4","242","412","1"
"apache-carbondata","427b202c04f26c89a56ef12fc3bbff0263198a2b","2017-01-01 22:00:59","IUD query flow support for update and delete delta files
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","427b202c04f26c89a56ef12fc3bbff0263198a2b","21","4","0","3033","349","74","3552","65","5418","871","254","20","39","4027","0","19","10","224","apache-carbondata","427b202c04f26c89a56ef12fc3bbff0263198a2b","439","18.9","51","60338","31910","6725","5","1220","91","1610","16.3","2513","47","3.3","5","168","1700","13734","16","665","2020","39","1010","107","56","13398","1.4","240","412","1"
"apache-carbondata","3e045d8395c094882a5880a57dd617c55130a18e","2017-01-01 21:53:34","IUD delete flow support
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","3e045d8395c094882a5880a57dd617c55130a18e","21","4","0","3001","349","74","3512","63","5384","867","255","20","39","4021","0","19","10","224","apache-carbondata","3e045d8395c094882a5880a57dd617c55130a18e","434","18.9","51","60032","31730","6698","5","1217","91","1605","16.5","2492","47","3.4","5","166","1695","13685","16","665","2020","39","1010","106","56","13341","1.4","240","407","1"
"apache-carbondata","0d42f52d9176135d52bd03243b5de19703b4c1ef","2017-01-01 21:47:24","IUD update flow support
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","0d42f52d9176135d52bd03243b5de19703b4c1ef","19","4","0","2827","328","63","3294","44","5058","829","251","18","33","3834","0","19","7","202","apache-carbondata","0d42f52d9176135d52bd03243b5de19703b4c1ef","415","18.9","30","57382","30046","6306","5","1148","87","1492","16.1","2362","45","3.3","5","134","1558","12930","14","620","1904","36","590","106","56","12379","1.4","206","391","1"
"apache-carbondata","ff84a2edfe439c93d4571fc582d811091258a638","2016-12-30 05:14:39","IUD implicit tupleid
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","ff84a2edfe439c93d4571fc582d811091258a638","17","2","0","2739","310","59","3126","39","4812","784","251","13","29","3648","0","18","6","192","apache-carbondata","ff84a2edfe439c93d4571fc582d811091258a638","403","19","21","55119","28689","5992","5","1103","83","1404","15.7","2290","42","3.3","5","109","1460","12282","13","590","1835","35","410","102","55","11541","1.3","180","381","1"
"apache-carbondata","75aa0835fdeed1430d1609f0bf7d6064138d5243","2017-01-05 05:43:34","[CARBONDATA-597] Unable to fetch data with ""select"" query
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","75aa0835fdeed1430d1609f0bf7d6064138d5243","16","2","0","2734","309","64","3118","40","4855","779","249","13","27","3629","0","16","4","196","apache-carbondata","75aa0835fdeed1430d1609f0bf7d6064138d5243","402","19.1","21","54496","28618","5996","5","1095","83","1410","15.9","2299","42","3.4","5","109","1465","12261","13","560","1835","34","410","101","55","11623","1.4","193","377","1"
"apache-carbondata","ddcc9c14409a5fd35104f46873ad41977b874470","2017-01-03 18:22:56","cleanup WriterCompressModel

minor fix

remove accidentally added file

fix test

fix test failure
","refs/heads/master","jihongma@apache.org","apache-carbondata","ddcc9c14409a5fd35104f46873ad41977b874470","16","2","0","2734","309","64","3118","40","4857","780","249","13","27","3632","0","16","4","196","apache-carbondata","ddcc9c14409a5fd35104f46873ad41977b874470","402","19.1","21","54502","28622","5996","5","1095","83","1411","15.9","2299","42","3.4","5","109","1466","12261","13","560","1835","34","410","101","55","11625","1.4","194","377","1"
"apache-carbondata","eaadc88a5525ae283dfc328026c01f09e7aba20f","2017-01-04 04:56:40","clean up core
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","eaadc88a5525ae283dfc328026c01f09e7aba20f","16","2","0","2734","309","64","3118","40","4857","781","251","13","27","3634","0","16","4","196","apache-carbondata","eaadc88a5525ae283dfc328026c01f09e7aba20f","402","19.1","21","54516","28629","5995","5","1095","83","1411","15.9","2298","42","3.4","5","109","1466","12265","13","560","1835","34","410","101","55","11625","1.4","194","377","1"
"apache-carbondata","7b8b19598bf61001b2c4e07debbe26868f64d95c","2016-12-29 22:44:14","fix testcase

clean

clean

clean

fix comment
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","7b8b19598bf61001b2c4e07debbe26868f64d95c","16","8","0","2968","327","66","3378","53","5200","860","301","25","36","3780","0","16","45","196","apache-carbondata","7b8b19598bf61001b2c4e07debbe26868f64d95c","417","19.4","26","58380","30557","6341","5","1167","91","1531","16.2","2419","44","3.4","5","126","1597","13101","14","630","1995","40","500","103","60","12410","1.4","230","391","1"
"apache-carbondata","d53feefd60dbedd48ec9582751ac694316cf97f2","2017-01-03 09:27:21","[CARBONDATA-484] fixed impacted test cases + refactored design and fixed review comments
","refs/heads/master","g.ramana.v@gmail.com","apache-carbondata","d53feefd60dbedd48ec9582751ac694316cf97f2","16","8","0","2968","327","66","3378","53","5200","860","301","25","36","3780","0","16","45","196","apache-carbondata","d53feefd60dbedd48ec9582751ac694316cf97f2","417","19.4","26","58372","30549","6341","5","1167","91","1531","16.2","2419","44","3.4","5","126","1597","13101","14","630","1995","40","500","103","60","12410","1.4","230","391","1"
"apache-carbondata","b6ab4ef654ee148a8b9cddf89554e1f46a5759f7","2016-10-04 21:45:09","[CARBONDATA-484] Implement LRU cache for B-Tree + fixed impacted test cases
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","b6ab4ef654ee148a8b9cddf89554e1f46a5759f7","16","8","0","2963","327","66","3378","53","5196","860","301","25","36","3771","0","16","45","196","apache-carbondata","b6ab4ef654ee148a8b9cddf89554e1f46a5759f7","417","19.4","26","58353","30534","6337","5","1169","91","1533","16.2","2416","44","3.4","5","126","1599","13093","14","630","1995","40","500","103","60","12420","1.4","230","391","1"
"apache-carbondata","808999cd69af007e2005b154a34d8751c32a32c1","2016-12-30 06:41:26","coverity and fortify fixes
","refs/heads/master","vincent.chenfei@huawei.com","apache-carbondata","808999cd69af007e2005b154a34d8751c32a32c1","16","8","0","2941","333","64","3302","52","5109","865","301","20","36","3747","0","16","44","196","apache-carbondata","808999cd69af007e2005b154a34d8751c32a32c1","413","19.4","25","57654","30141","6272","5","1176","91","1530","16.2","2375","44","3.5","5","126","1595","12964","13","630","1995","40","480","103","59","12500","1.4","221","387","1"
"apache-carbondata","05b26549e929c2a461b0d18e5b58d3cd61bec1d5","2016-11-15 05:45:17","WIP provide dictionary server/client framework

complete the netty communication

netty

implement methods, and use new dictionarygenerator

trigger msg: initial, generate, size

add msg: write dictionary

fix write mutil dictionary file

ObjectDecoder

fixerror

fix query error

remove no used files

shutdown dictionary server and client

fixDictServerCloseBug and format code

testOnePass

fix second load

fix complex

fix multil level complex

optimize DictionaryKey

fix testcase

fix testcase and get dict cache

 fix checkstyle

remove some useless judgement conditions

fix complex test case

fix testcase

fix mutil task

fix print

use json for serialize, and fix write dictionary issues

fix duplicate dictionary

write dictionary once

multi thread write dictionary

add testcase

RemoveUselessCode

fix comments

fix nullpointerexception

optimize

support predef column dictionary

use kryo
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","05b26549e929c2a461b0d18e5b58d3cd61bec1d5","16","8","0","2941","333","64","3302","52","5110","866","301","20","36","3747","0","16","44","196","apache-carbondata","05b26549e929c2a461b0d18e5b58d3cd61bec1d5","413","19.5","25","57647","30134","6271","5","1176","91","1530","16.2","2375","44","3.5","5","126","1595","12959","13","630","1995","40","480","103","59","12500","1.4","221","387","1"
"apache-carbondata","be6bb16d5f31ba8376c3c15da39752d663ad35d6","2016-12-24 01:36:53","fix statistics code and adapt query stastistics to spark2

fix style

add non filter blocket num
","refs/heads/master","eason@easondeMacBook-Pro.local","apache-carbondata","be6bb16d5f31ba8376c3c15da39752d663ad35d6","16","8","0","2874","333","64","3254","34","4988","854","301","20","14","3683","0","16","43","196","apache-carbondata","be6bb16d5f31ba8376c3c15da39752d663ad35d6","403","19.6","21","56572","29543","6195","5","1161","91","1514","16.4","2338","44","3.5","5","118","1571","12715","12","545","1995","36","400","99","59","12363","1.4","221","377","1"
"apache-carbondata","cbf8797776c2f3be48efe029d858b37a37d29848","2016-11-27 03:28:55","Added partitioner

Added bucketing in load

Added headers

Bucketing is handled in load and query flow

Fixed test case

Rebased with master

rebased

Added bucketing in spark layer

Rebased and fixed scala style

Added test cases for bucketing in all scenerios. And fixed review comments

rebased and fixed issues

Rebased and fixed comments

Rebased and fixed testcases

Rebased and fixed testcases

Fixed comments

Rebased

Fixed compilation issue
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","cbf8797776c2f3be48efe029d858b37a37d29848","16","8","0","2873","333","64","3246","34","4985","854","301","20","14","3675","0","16","43","196","apache-carbondata","cbf8797776c2f3be48efe029d858b37a37d29848","403","19.6","21","56552","29525","6195","5","1160","91","1513","16.4","2338","44","3.5","5","118","1570","12708","12","545","1995","36","400","99","59","12353","1.4","221","377","1"
"apache-carbondata","d9fc651fdbe377b47f26efa98a8ba3e89762719d","2016-12-24 01:10:56","[CARBONDATA-560] In QueryExecutionException, can not use executorService.shutdownNow() to shut down immediately.

In QueryExecutionException, can not use executorService.shutdownNow() to shut down immediately.

fix compilation error

fix QueryExecutionException processing
","refs/heads/master","chenliang613@apache.org","apache-carbondata","d9fc651fdbe377b47f26efa98a8ba3e89762719d","16","8","0","2840","333","63","3232","34","4943","830","301","17","14","3654","0","16","43","196","apache-carbondata","d9fc651fdbe377b47f26efa98a8ba3e89762719d","395","19.6","21","56252","29350","6150","5","1156","91","1501","16.4","2320","44","3.5","5","118","1558","12640","12","545","1995","36","400","97","59","12288","1.4","213","374","1"
"apache-carbondata","b50866b3a2e3eb7d704c6fa9f6e6fcdfc5e5de21","2016-12-21 23:09:53","extract command to common

fix

fix testcase

remove redundant QueryTest

fix comment
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","b50866b3a2e3eb7d704c6fa9f6e6fcdfc5e5de21","16","8","0","2840","333","63","3232","34","4943","830","301","17","14","3653","0","16","43","196","apache-carbondata","b50866b3a2e3eb7d704c6fa9f6e6fcdfc5e5de21","395","19.7","21","56246","29344","6148","5","1156","91","1501","16.4","2320","44","3.5","5","117","1557","12637","12","530","1995","35","400","97","59","12288","1.4","213","374","1"
"apache-carbondata","b0b6bcbe5116a9f7fc70ee59a5b2008c8c025955","2016-12-21 11:59:45","code cleanup for bigint compression

minor fix

style fix

address comments
","refs/heads/master","jihongma@Jihongs-MacBook-Pro.local","apache-carbondata","b0b6bcbe5116a9f7fc70ee59a5b2008c8c025955","16","8","0","2838","333","63","3234","34","4946","831","301","17","14","3653","0","16","43","196","apache-carbondata","b0b6bcbe5116a9f7fc70ee59a5b2008c8c025955","395","19.7","21","56259","29345","6149","5","1156","91","1501","16.4","2321","44","3.5","5","117","1557","12635","12","530","1995","35","400","97","59","12288","1.4","213","374","1"
"apache-carbondata","7f46e8c8731080dfe94e27ecd7bcc06cfb2c13f8","2016-12-17 22:49:24","CARBONDATA-453 Implement DAT(Double Array Trie) for Dictionary

CARBONDATA-453 Add some code comment

CARBONDATA-453 Fix incorrect code style

CARBONDATA-453 Remove some test code
","refs/heads/master","hexiaoqiao@meituan.com","apache-carbondata","7f46e8c8731080dfe94e27ecd7bcc06cfb2c13f8","16","8","0","2840","327","63","3238","34","4948","833","301","17","14","3653","0","16","43","194","apache-carbondata","7f46e8c8731080dfe94e27ecd7bcc06cfb2c13f8","395","19.6","21","56264","29361","6153","5","1161","95","1507","16.5","2322","46","3.7","5","117","1563","12649","12","530","2087","35","400","97","59","12371","1.4","214","374","1"
"apache-carbondata","fc1d620e729746271c70159636e0cc05ac46d99e","2016-11-15 18:49:35","fix load bug when table name has '_'
","refs/heads/master","liujunjie9@huawei.com","apache-carbondata","fc1d620e729746271c70159636e0cc05ac46d99e","16","8","0","2819","320","63","3222","34","4894","831","301","5","13","3644","0","16","43","194","apache-carbondata","fc1d620e729746271c70159636e0cc05ac46d99e","394","19.7","19","55880","29100","6077","5","1153","95","1485","16.3","2307","46","3.7","5","115","1538","12463","11","515","2087","34","370","97","58","12282","1.4","201","373","1"
"apache-carbondata","376d69ff72c88d541022d3cea98ef1d6a7542ee6","2016-12-06 09:54:05","add initial check in for vector reader

Added vector reader in carbon

Fixed check style

Added batch reader support in spark layer

rebased

Fixed issues

Added testcases

fixed testcase

fixed comments

fixed style

fixed testcase

Fixed review comments

Fixed testcase and comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","376d69ff72c88d541022d3cea98ef1d6a7542ee6","16","8","0","2819","320","63","3218","34","4893","831","301","5","13","3642","0","16","43","194","apache-carbondata","376d69ff72c88d541022d3cea98ef1d6a7542ee6","394","19.7","19","55874","29097","6077","5","1153","95","1485","16.3","2307","46","3.7","5","115","1538","12462","11","515","2087","34","370","97","58","12282","1.4","201","373","1"
"apache-carbondata","f031394a8c608097b69ab530e35bae1435ebd020","2016-11-21 06:14:06","remove unnecessary file name check in dictionary cache

fix testcase

fix comment
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","f031394a8c608097b69ab530e35bae1435ebd020","16","8","0","2690","319","63","3194","34","4664","805","300","5","13","3474","0","14","29","194","apache-carbondata","f031394a8c608097b69ab530e35bae1435ebd020","378","20.1","17","54563","28187","5901","5","1131","85","1460","16.2","2228","44","3.5","5","112","1510","12043","11","500","1933","33","340","95","58","11918","1.4","198","364","1"
"apache-carbondata","0df4c8b6ad96e0ba3d0a88f9442e74ad18b5d0a8","2016-12-18 17:23:51","remove unused code for CarbonCommonConstants.java

remove unused code for CarbonCommonConstants.java","refs/heads/master","jarray888@users.noreply.github.com","apache-carbondata","0df4c8b6ad96e0ba3d0a88f9442e74ad18b5d0a8","16","8","0","2689","319","63","3194","34","4666","804","300","5","13","3470","0","14","29","190","apache-carbondata","0df4c8b6ad96e0ba3d0a88f9442e74ad18b5d0a8","378","20.1","17","54562","28185","5899","5","1127","85","1456","16.2","2227","44","3.5","5","112","1506","12039","11","500","1933","33","340","95","58","11906","1.4","198","364","1"
"apache-carbondata","462f64226428fc255938d8752226cda262ad0ae4","2016-12-08 03:06:33","fixUnionIssue and add test case
","refs/heads/master","qiangcai@qq.com","apache-carbondata","462f64226428fc255938d8752226cda262ad0ae4","16","8","0","2692","319","63","3212","34","4666","804","300","5","13","3470","0","14","29","190","apache-carbondata","462f64226428fc255938d8752226cda262ad0ae4","378","20.1","19","54579","28191","5899","5","1129","85","1460","16.2","2227","44","3.5","5","114","1512","12039","11","500","1933","33","380","95","58","11932","1.4","200","364","1"
"apache-carbondata","d73f4bfe82e8be8970f41ce04707859e5b9bcce9","2016-12-06 22:29:29","support datatype: date and char
","refs/heads/master","qiangcai@qq.com","apache-carbondata","d73f4bfe82e8be8970f41ce04707859e5b9bcce9","16","8","0","2692","318","63","3210","34","4664","804","300","5","13","3442","0","14","29","190","apache-carbondata","d73f4bfe82e8be8970f41ce04707859e5b9bcce9","378","20.1","19","54554","28169","5893","5","1128","85","1459","16.2","2227","44","3.5","5","114","1511","12028","11","500","1933","33","380","95","58","11925","1.4","200","364","1"
"apache-carbondata","f1f9348d0d7150c95500f8f10d3fd3adde47ecb2","2016-12-06 10:59:04","Added unsafe on-heap/off-heap sort to improve loading performance

fixed testcase

fixed row duplicated issue.

rebased and changed the default value

Added file header for code porting.
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","f1f9348d0d7150c95500f8f10d3fd3adde47ecb2","17","8","0","2679","316","63","3206","34","4648","803","300","5","13","3417","0","14","29","188","apache-carbondata","f1f9348d0d7150c95500f8f10d3fd3adde47ecb2","377","20.2","19","54295","27976","5789","5","1114","81","1445","15.9","2217","42","3.2","5","114","1497","11941","11","500","1755","33","380","95","58","11711","1.4","200","363","1"
"apache-carbondata","63d66264cb60338845c87f7f627019bb843844aa","2016-12-03 13:05:38","rebased code.
fixed review comment.

BigDecimal compression
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","63d66264cb60338845c87f7f627019bb843844aa","17","6","0","2637","316","63","3184","33","4633","796","300","5","13","3410","0","14","29","184","apache-carbondata","63d66264cb60338845c87f7f627019bb843844aa","371","20.2","17","53937","27830","5767","5","1106","81","1433","16.2","2202","42","3.3","5","112","1483","11894","10","500","1755","33","340","93","58","11552","1.4","197","357","1"
"apache-carbondata","c1c9ac529c026d10a2de168dedda98f7f302e44a","2016-12-12 19:06:54","support octal escape delimited

style

style

add testcase load csv with delimiter char \017

add testcase load csv with delimiter char \017
","refs/heads/master","palwei@sina.com","apache-carbondata","c1c9ac529c026d10a2de168dedda98f7f302e44a","17","6","0","2582","316","62","3138","33","4535","785","291","5","13","3379","0","14","29","184","apache-carbondata","c1c9ac529c026d10a2de168dedda98f7f302e44a","367","20.3","17","53358","27471","5725","5","1101","79","1420","16.3","2168","40","3.2","5","112","1470","11749","10","500","1709","33","340","92","54","11439","1.4","193","352","1"
"apache-carbondata","b9db4ac8d5aa814b8ea4d02d7a426f688501df33","2016-09-23 00:07:12","[CARBONDATA-270]
[Description] Double data type value comparison optimization,EqualsToExpression evaluation for double values first check for the equality of nan values and then the double value comparison happens, since nan comparison scenarios are rare we can push the comparison of nan after the double value comparison. while comparing dictionary value which is type double should also will preserve the -0.0 and 0.0 equality
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","b9db4ac8d5aa814b8ea4d02d7a426f688501df33","17","6","0","2582","316","62","3138","33","4535","785","291","5","13","3378","0","14","29","184","apache-carbondata","b9db4ac8d5aa814b8ea4d02d7a426f688501df33","367","20.3","17","53373","27486","5738","5","1102","79","1421","16.3","2168","40","3.2","5","112","1471","11756","10","500","1709","33","340","92","54","11453","1.4","193","352","1"
"apache-carbondata","f67ec0125247e98d7925866fd3062ee3ddf16e28","2016-12-09 01:28:59","use carbon property to get the store path

remove nouse imports

fix style

asle set kettle home in carbon property
","refs/heads/master","wangfei_hello@126.com","apache-carbondata","f67ec0125247e98d7925866fd3062ee3ddf16e28","17","6","0","2581","316","62","3134","33","4535","785","291","5","13","3378","0","14","29","180","apache-carbondata","f67ec0125247e98d7925866fd3062ee3ddf16e28","367","20.3","17","53358","27478","5731","5","1102","79","1421","16.3","2167","40","3.2","5","111","1470","11753","10","495","1727","32","340","92","54","11453","1.4","193","352","1"
"apache-carbondata","5ef67ac88d2c967129e5c5dd98055efcd1d1f1e9","2016-11-08 00:05:28","made changes in the test cases

add test cases with different dim split,dimension and exception handling
","refs/heads/master","anurag@knoldus.com","apache-carbondata","5ef67ac88d2c967129e5c5dd98055efcd1d1f1e9","17","6","0","2581","316","62","3134","33","4535","785","291","5","13","3378","0","14","29","180","apache-carbondata","5ef67ac88d2c967129e5c5dd98055efcd1d1f1e9","367","20.3","17","53357","27477","5731","5","1102","79","1421","16.3","2167","40","3.2","5","111","1470","11752","10","495","1727","32","340","92","54","11453","1.4","193","352","1"
"apache-carbondata","f853998fba87791889654b3a43a9577f9907200a","2016-12-07 01:33:24","new code for carbondata-513, fix conflicts

fix checkstyle
","refs/heads/master","tongsuo@huawei.com","apache-carbondata","f853998fba87791889654b3a43a9577f9907200a","17","6","0","2581","316","62","3134","33","4535","785","291","5","13","3378","0","14","29","180","apache-carbondata","f853998fba87791889654b3a43a9577f9907200a","367","20.3","17","53357","27477","5731","5","1102","79","1421","16.3","2167","40","3.2","5","111","1470","11752","10","495","1727","32","340","92","54","11453","1.4","193","352","1"
"apache-carbondata","dc57aec5f1d3d7158e93226af1415db49c7f2f1c","2016-12-06 23:14:13","make timestamp formatter static

make thread safe
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","dc57aec5f1d3d7158e93226af1415db49c7f2f1c","17","6","0","2581","316","62","3134","33","4540","786","291","5","13","3374","0","15","29","180","apache-carbondata","dc57aec5f1d3d7158e93226af1415db49c7f2f1c","367","20.3","17","53368","27488","5729","5","1103","79","1422","16.3","2167","40","3.2","5","111","1471","11761","10","495","1727","32","340","92","54","11458","1.4","193","352","1"
"apache-carbondata","391feea333e70efef08c3b3a7ea304d4f5012634","2016-12-06 07:16:57","Clean up CarbonUtil

Clean up CarbonUtil code

fix style
","refs/heads/master","jarray888@users.noreply.github.com","apache-carbondata","391feea333e70efef08c3b3a7ea304d4f5012634","17","6","0","2580","316","62","3132","33","4543","787","291","5","13","3376","0","15","29","180","apache-carbondata","391feea333e70efef08c3b3a7ea304d4f5012634","367","20.3","17","53401","27516","5746","5","1106","79","1425","16.3","2168","40","3.2","5","111","1474","11776","10","495","1727","32","340","92","54","11501","1.4","193","352","1"
"apache-carbondata","360edc8ddea8d7d79c7d9ac973aa7f6869a00359","2016-12-05 21:13:46","change package name

add ReadCompressModel

change to mantissa

change to mantissa

remove compType

change compression type

fix style

fix testcase

fix testcase

fix
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","360edc8ddea8d7d79c7d9ac973aa7f6869a00359","18","6","0","2585","321","62","3152","34","4579","793","291","5","13","3406","0","15","30","180","apache-carbondata","360edc8ddea8d7d79c7d9ac973aa7f6869a00359","368","20.2","17","53654","27714","5824","5","1125","79","1446","16.5","2177","40","3.2","5","113","1495","11892","10","495","1727","32","340","92","54","11771","1.4","193","352","1"
"apache-carbondata","25b4ba2c9918c894f44761cf170d85f0a4e2a021","2016-12-05 07:42:22","modify compress interface

fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","25b4ba2c9918c894f44761cf170d85f0a4e2a021","18","6","0","2613","322","62","3176","34","4624","799","301","5","13","3491","0","15","40","180","apache-carbondata","25b4ba2c9918c894f44761cf170d85f0a4e2a021","373","20.3","17","54360","28012","5877","5","1151","82","1475","16.5","2197","40","3.2","5","115","1526","12008","10","505","1766","34","340","91","55","11932","1.4","195","356","1"
"apache-carbondata","e5ee02c863229317f58240acafa044a451ccba60","2016-12-04 02:17:44","support smallint

fix DataTypeUtilTest issue
","refs/heads/master","261810726@qq.com","apache-carbondata","e5ee02c863229317f58240acafa044a451ccba60","18","6","0","2632","321","62","3330","33","4774","815","307","5","13","3788","0","15","40","192","apache-carbondata","e5ee02c863229317f58240acafa044a451ccba60","392","20.4","16","55905","28755","5977","5","1184","82","1513","16.2","2230","40","3.2","5","115","1564","12328","10","510","1766","35","320","96","55","12233","1.4","200","369","1"
"apache-carbondata","7f54160f6ff6a584519121bff2536d3ed38c5026","2016-12-02 20:44:07","fix spark2 decimal

code clean

comment fix

comment fix
","refs/heads/master","wangfei_hello@126.com","apache-carbondata","7f54160f6ff6a584519121bff2536d3ed38c5026","18","6","0","2632","321","62","3330","33","4774","815","307","5","13","3788","0","15","40","192","apache-carbondata","7f54160f6ff6a584519121bff2536d3ed38c5026","392","20.4","16","55902","28752","5974","5","1184","82","1513","16.2","2230","40","3.2","5","115","1564","12328","10","510","1766","35","320","96","55","12232","1.4","200","369","1"
"apache-carbondata","ff7793beb079847a57a5d3d5b33a37c1976e53fb","2016-11-28 02:07:11","Problem: Block distribution is wrong in case of dynamic allocation=true

Analysis: In case when dynamic allocation is true and configured max executors are more than the initial executors then carbon is not able to request the max number of executors configured. Due to this resources are getting under utilized and case when number of blocks increases, the distribution of blocks is limited to the number of nodes and the number of tasks launched are less. This leads to under utilization of resources and hence impacts the query and load performance.

Fix: Request for starting the maximum number of configured executors in case dynamic allocation is true.

Impact area: Query and data load flow performance due to under utilization of resources.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","ff7793beb079847a57a5d3d5b33a37c1976e53fb","18","6","0","2630","321","62","3328","33","4768","814","307","5","13","3786","0","15","40","192","apache-carbondata","ff7793beb079847a57a5d3d5b33a37c1976e53fb","392","20.4","16","55870","28724","5961","5","1183","82","1512","16.2","2228","40","3.2","5","115","1563","12313","10","510","1766","35","320","96","55","12227","1.4","200","369","1"
"apache-carbondata","63434fac5f4dc2d7eb9d03819401e243744a5f48","2016-11-27 04:09:36","Optimize data loading

Handled broadcast fails.

Updated as per comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","63434fac5f4dc2d7eb9d03819401e243744a5f48","18","6","0","2625","321","62","3318","33","4768","814","307","5","13","3786","0","15","40","192","apache-carbondata","63434fac5f4dc2d7eb9d03819401e243744a5f48","392","20.4","16","55824","28701","5958","5","1183","82","1512","16.1","2227","40","3.2","5","115","1563","12304","10","510","1766","35","320","96","55","12227","1.4","200","369","1"
"apache-carbondata","7904716b9396b9ba660e4cb08ef0cba1821f3166","2016-12-01 20:10:58","fix compatibility
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","7904716b9396b9ba660e4cb08ef0cba1821f3166","18","6","0","2625","321","62","3318","33","4768","814","307","5","13","3786","0","15","40","192","apache-carbondata","7904716b9396b9ba660e4cb08ef0cba1821f3166","392","20.4","16","55824","28701","5958","5","1183","82","1512","16.1","2227","40","3.2","5","115","1563","12304","10","510","1766","35","320","96","55","12227","1.4","200","369","1"
"apache-carbondata","0ef3fb81883e782fffef0beae01a429684893960","2016-12-01 07:02:16","add file format version enum
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","0ef3fb81883e782fffef0beae01a429684893960","18","6","0","2625","321","62","3318","33","4768","814","307","5","13","3786","0","15","40","192","apache-carbondata","0ef3fb81883e782fffef0beae01a429684893960","392","20.4","16","55819","28699","5956","5","1183","82","1512","16.1","2227","40","3.2","5","115","1563","12303","10","510","1766","35","320","96","55","12227","1.4","200","369","1"
"apache-carbondata","5f1abef794d22110f2b40fc0fabad19c7f215f0b","2016-11-28 21:20:45","Insert into carbon table new
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","5f1abef794d22110f2b40fc0fabad19c7f215f0b","18","6","0","2618","321","62","3320","33","4767","817","307","5","13","3785","0","15","40","192","apache-carbondata","5f1abef794d22110f2b40fc0fabad19c7f215f0b","391","20.4","16","55744","28646","5935","5","1185","82","1515","16.1","2221","40","3.2","5","113","1566","12290","10","510","1766","35","320","96","55","12232","1.4","203","368","1"
"apache-carbondata","20af74ba719141002c68bc5e82bc05131e47a2d9","2016-07-23 12:13:58","Implement BigInt value compression

fix for review comment
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","20af74ba719141002c68bc5e82bc05131e47a2d9","18","6","0","2610","321","62","3302","33","4742","820","307","5","13","3771","0","15","40","192","apache-carbondata","20af74ba719141002c68bc5e82bc05131e47a2d9","391","20.4","15","55642","28576","5923","5","1181","82","1510","16.1","2215","40","3.2","5","111","1559","12260","10","480","1766","34","300","96","55","12213","1.4","202","368","1"
"apache-carbondata","d54dc647c69496ecaa7e0c8a9cc3d8e9028ab73f","2016-10-27 10:24:49","Improve first time query performance

Rebased
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d54dc647c69496ecaa7e0c8a9cc3d8e9028ab73f","18","6","0","2575","310","62","3284","33","4639","800","307","5","13","3758","0","15","31","190","apache-carbondata","d54dc647c69496ecaa7e0c8a9cc3d8e9028ab73f","388","20.7","15","54876","28015","5744","5","1128","69","1443","15.7","2169","32","2.8","5","111","1492","11960","10","480","1521","34","300","95","54","11654","1.4","189","365","1"
"apache-carbondata","db9816189575e7c1b30e05c36e804dfaefcde129","2016-11-26 02:22:22","Fix the bug of storePath substring on windows
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","db9816189575e7c1b30e05c36e804dfaefcde129","18","6","0","2536","301","62","3168","33","4489","782","307","5","14","3576","0","15","32","190","apache-carbondata","db9816189575e7c1b30e05c36e804dfaefcde129","382","20.7","15","53538","27200","5629","5","1084","63","1386","15.7","2138","29","2.6","5","110","1435","11514","10","480","1404","34","300","91","47","11039","1.4","184","359","1"
"apache-carbondata","5f6a56cac26be7e5307a01296ce9351b60be0e66","2016-11-25 02:07:20","change ScanRdd to use RecordReader

fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","5f6a56cac26be7e5307a01296ce9351b60be0e66","18","6","0","2536","301","62","3166","33","4488","782","307","5","14","3574","0","15","32","190","apache-carbondata","5f6a56cac26be7e5307a01296ce9351b60be0e66","382","20.7","15","53537","27199","5629","5","1084","63","1386","15.7","2138","29","2.6","5","110","1435","11513","10","480","1404","34","300","91","47","11039","1.4","184","359","1"
"apache-carbondata","f88737d44092cb0b24e3cc127509b2577a690c13","2016-11-24 21:00:32","make carbon compilable with -Pspark-2.0

change scala version

add spark-common module dependency

fix testcase

fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","f88737d44092cb0b24e3cc127509b2577a690c13","18","6","0","2535","301","62","3170","33","4490","782","307","5","14","3574","0","15","34","190","apache-carbondata","f88737d44092cb0b24e3cc127509b2577a690c13","382","20.7","15","53543","27205","5629","5","1089","63","1391","15.7","2138","29","2.6","5","110","1440","11513","10","480","1404","34","300","91","47","11069","1.4","184","359","1"
"apache-carbondata","251f7fc26cef2d0822618925437046efc4b8653c","2016-11-17 08:16:26","remove useless file CarbonFileFolderComparator.java
","refs/heads/master","261810726@qq.com","apache-carbondata","251f7fc26cef2d0822618925437046efc4b8653c","18","6","0","2535","301","62","3170","33","4490","782","307","5","14","3574","0","15","34","190","apache-carbondata","251f7fc26cef2d0822618925437046efc4b8653c","382","20.7","15","53543","27205","5629","5","1089","63","1391","15.7","2138","29","2.6","5","110","1440","11513","10","480","1404","34","300","91","47","11069","1.4","184","359","1"
"apache-carbondata","f6f0d4caecd7e3fd326de309e3bf43b7095d1e9c","2016-11-17 04:59:49","Time Stamp Filter issue with other than yyyy-mm-dd format
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","f6f0d4caecd7e3fd326de309e3bf43b7095d1e9c","18","6","0","2537","301","62","3174","33","4496","782","307","5","14","3578","0","15","34","194","apache-carbondata","f6f0d4caecd7e3fd326de309e3bf43b7095d1e9c","383","20.7","15","53595","27225","5634","5","1089","63","1391","15.7","2139","29","2.6","5","110","1440","11524","10","480","1404","34","300","91","47","11069","1.4","184","360","1"
"apache-carbondata","70537a6cf8d04dcb4be216e4b54f72974e2f3ae1","2016-10-27 22:04:51","implement test cases for core.load module

code formatted using formatter

replace assert with assertEquals

manage test case for timestamp
","refs/heads/master","anurag@knoldus.com","apache-carbondata","70537a6cf8d04dcb4be216e4b54f72974e2f3ae1","18","6","0","2537","301","62","3174","33","4496","782","307","5","14","3577","0","15","34","194","apache-carbondata","70537a6cf8d04dcb4be216e4b54f72974e2f3ae1","383","20.7","15","53592","27222","5634","5","1089","63","1391","15.7","2139","29","2.6","5","110","1440","11524","10","480","1404","34","300","91","47","11069","1.4","184","360","1"
"apache-carbondata","6635bbebf4386b0762a348670b48991b82d1996a","2016-11-03 01:04:48","removeUselessFiles
","refs/heads/master","xlion.pku@gmail.com","apache-carbondata","6635bbebf4386b0762a348670b48991b82d1996a","18","6","0","2537","301","62","3174","33","4496","782","307","5","14","3577","0","15","34","194","apache-carbondata","6635bbebf4386b0762a348670b48991b82d1996a","383","20.7","15","53592","27222","5634","5","1089","63","1391","15.7","2139","29","2.6","5","110","1440","11524","10","480","1404","34","300","91","47","11069","1.4","184","360","1"
"apache-carbondata","496cde46ddd43c14a07172a913550f6fd47bd7c5","2016-11-09 09:08:47","Data load integration of all steps for removing kettle
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","496cde46ddd43c14a07172a913550f6fd47bd7c5","22","6","0","2581","309","62","3188","33","4530","783","307","5","14","3700","0","15","34","194","apache-carbondata","496cde46ddd43c14a07172a913550f6fd47bd7c5","390","20.5","15","54073","27519","5706","5","1097","63","1406","15.5","2161","29","2.6","5","110","1455","11645","10","480","1404","34","300","92","48","11171","1.4","190","367","1"
"apache-carbondata","a65ca7ccb1dbe240c32ede1d0bc01f1e427c424b","2016-11-08 22:41:05","CARBONDATA-383 Optimize hdfsStoreLocation/hdfsStorePath parameters' name since Carbon not only support hdfs path
","refs/heads/master","hexiaoqiao@meituan.com","apache-carbondata","a65ca7ccb1dbe240c32ede1d0bc01f1e427c424b","22","6","0","2580","309","61","3186","33","4527","781","306","4","14","3700","0","15","34","194","apache-carbondata","a65ca7ccb1dbe240c32ede1d0bc01f1e427c424b","390","20.5","15","54009","27481","5693","5","1097","63","1403","15.5","2155","29","2.6","5","110","1452","11623","10","480","1404","34","300","92","46","11166","1.4","189","367","1"
"apache-carbondata","84c57ac4c060a4f41838922d3a337f6067cd4caa","2016-11-02 19:11:07","In case while copying store to hdfs, if stream didn't closed properly, file doesn't get copied to HDFS
So we need to propogate exception to executor so that task can be launched again.
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","84c57ac4c060a4f41838922d3a337f6067cd4caa","22","6","0","2580","309","61","3186","33","4527","781","306","4","14","3700","0","15","34","194","apache-carbondata","84c57ac4c060a4f41838922d3a337f6067cd4caa","390","20.5","15","54009","27481","5693","5","1097","63","1403","15.5","2155","29","2.6","5","110","1452","11623","10","480","1404","34","300","92","46","11166","1.4","189","367","1"
"apache-carbondata","6ee44644071272ab07969f06d92b67661959afe4","2016-11-03 00:50:35","CARBONDATA-367 Add support alluxio(tachyon) file system

CARBONDATA-367 Add support alluxio(tachyon) file system

Rename ALLUXIOCarbonFile.java to AlluxioCarbonFile.java
","refs/heads/master","chenliang613@apache.org","apache-carbondata","6ee44644071272ab07969f06d92b67661959afe4","22","6","0","2580","309","61","3186","33","4526","781","306","4","14","3700","0","15","34","194","apache-carbondata","6ee44644071272ab07969f06d92b67661959afe4","390","20.5","15","54000","27478","5692","5","1098","63","1405","15.5","2154","29","2.6","5","111","1454","11622","10","480","1404","34","300","92","46","11186","1.4","189","367","1"
"apache-carbondata","041dab09f09c31aae95f1de954a7261bde53830c","2016-11-02 10:02:42","fixed block loading issue in case of blocklet distribution
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","041dab09f09c31aae95f1de954a7261bde53830c","22","6","0","2570","309","61","3184","33","4516","779","306","4","14","3689","0","15","34","194","apache-carbondata","041dab09f09c31aae95f1de954a7261bde53830c","389","20.6","15","53839","27358","5641","5","1093","57","1398","15.4","2146","28","2.5","5","109","1447","11576","10","480","1329","34","300","92","46","11051","1.3","189","366","1"
"apache-carbondata","77c90b80bd4ce889ca4a2e1205253aa0635094db","2016-11-01 10:05:48","CARBONDATA-355 Remove unnecessary method argument columnIdentifier of PathService.getCarbonTablePath

CARBONDATA-355 Remove unnecessary method argument columnIdentifier of PathService.getCarbonTablePath

CARBONDATA-355 Update comment of PathService#getCarbonTablePath
","refs/heads/master","hexiaoqiao@meituan.com","apache-carbondata","77c90b80bd4ce889ca4a2e1205253aa0635094db","22","6","0","2570","303","61","3182","33","4517","778","306","4","14","3688","0","15","34","194","apache-carbondata","77c90b80bd4ce889ca4a2e1205253aa0635094db","389","20.6","15","53828","27353","5640","5","1092","57","1397","15.4","2146","28","2.5","5","110","1447","11575","10","482","1329","35","300","92","46","11029","1.3","189","366","1"
"apache-carbondata","813e958b163fcc7416de9fc142a0bc5e96d9079f","2016-11-01 20:20:56","SpellingMistakes
","refs/heads/master","xlion.pku@gmail.com","apache-carbondata","813e958b163fcc7416de9fc142a0bc5e96d9079f","22","6","0","2570","303","61","3182","33","4518","778","306","4","14","3688","0","15","34","194","apache-carbondata","813e958b163fcc7416de9fc142a0bc5e96d9079f","389","20.6","15","53835","27358","5640","5","1092","57","1397","15.4","2146","28","2.5","5","110","1447","11575","10","482","1329","35","300","92","46","11029","1.3","189","366","1"
"apache-carbondata","72d076acbfad0b6beb07471f3d5148d2f63e2191","2016-09-29 07:33:18","Lionx0929

mend
","refs/heads/master","xlion.pku@gmail.com","apache-carbondata","72d076acbfad0b6beb07471f3d5148d2f63e2191","22","6","0","2595","303","61","3182","33","4524","783","316","4","14","3688","0","15","34","194","apache-carbondata","72d076acbfad0b6beb07471f3d5148d2f63e2191","391","20.6","15","54048","27430","5640","5","1092","57","1397","15.3","2146","28","2.5","5","110","1447","11587","10","482","1329","35","300","92","46","11029","1.3","189","368","1"
"apache-carbondata","e85bb694a0d00fc307d4571ec86e3f8b4e18f88a","2016-10-25 18:21:51","InvertedIndexSpellingMistakes
","refs/heads/master","xlion.pku@gmail.com","apache-carbondata","e85bb694a0d00fc307d4571ec86e3f8b4e18f88a","22","6","0","2590","303","61","3180","33","4524","787","316","4","14","3685","0","15","34","194","apache-carbondata","e85bb694a0d00fc307d4571ec86e3f8b4e18f88a","391","20.6","16","54027","27413","5636","5","1093","57","1402","15.3","2142","28","2.5","5","111","1453","11584","10","482","1329","35","320","92","46","11059","1.3","193","368","1"
"apache-carbondata","ecfdc91d6990258c2f6d9ede4f023e1a16687a6e","2016-10-26 01:01:35","Removed the unused value inside the method
","refs/heads/master","shiv4nsh@gmail.com","apache-carbondata","ecfdc91d6990258c2f6d9ede4f023e1a16687a6e","22","6","0","2590","303","61","3180","33","4524","787","316","4","14","3685","0","15","34","194","apache-carbondata","ecfdc91d6990258c2f6d9ede4f023e1a16687a6e","391","20.6","16","54027","27413","5636","5","1093","57","1402","15.3","2142","28","2.5","5","111","1453","11584","10","482","1329","35","320","92","46","11059","1.3","193","368","1"
"apache-carbondata","5b51d4838f87da1e8e01d52a98f06d77e4a9fc61","2016-10-19 18:36:12","CARBONDATA-330: Fix compiler warnings

CARBONDATA-330: Fix compiler warnings

CARBONDATA-330: Fix compiler warnings & Review comments

CARBONDATA-330: Fix Scala style checking violation
","refs/heads/master","aniket.adnaik@huawei.com","apache-carbondata","5b51d4838f87da1e8e01d52a98f06d77e4a9fc61","22","6","0","2590","303","61","3180","33","4526","787","316","4","14","3685","0","15","34","194","apache-carbondata","5b51d4838f87da1e8e01d52a98f06d77e4a9fc61","391","20.6","16","54027","27413","5636","5","1094","57","1403","15.3","2142","28","2.5","5","111","1454","11584","10","482","1329","35","320","92","46","11064","1.3","193","368","1"
"apache-carbondata","d96f09a2bec50d8c78e815420444defedab9c039","2016-10-16 22:03:35","Added Encoder processor for dataloding.

Fixed review comments

Fixed review comments

Rebased and fixed comments.

Fixed comments.

Fixed compilation issue

Fixed checkstyle issue

Fixed compile error after merging of PR 247
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","d96f09a2bec50d8c78e815420444defedab9c039","22","6","0","2590","303","61","3180","33","4526","787","316","4","14","3685","0","15","34","194","apache-carbondata","d96f09a2bec50d8c78e815420444defedab9c039","391","20.6","16","54027","27413","5636","5","1094","57","1403","15.3","2142","28","2.5","5","111","1454","11584","10","482","1329","35","320","92","46","11064","1.3","193","368","1"
"apache-carbondata","e5f1a99ba3c02655d769352474a4b85c66821a0a","2016-09-27 04:21:03","[CARBONDATA-278] IS NULL and IS NOT NULL shall be push down to carbon layer since carbon layer can process these filters faster using block/block-let pruning ,
 also while processing filters in executors carbon is applying binary search for applying filter values.
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","e5f1a99ba3c02655d769352474a4b85c66821a0a","22","6","0","2589","303","61","3176","36","4521","787","316","4","17","3685","0","15","34","192","apache-carbondata","e5f1a99ba3c02655d769352474a4b85c66821a0a","390","20.6","18","53957","27387","5630","5","1091","57","1399","15.3","2136","28","2.5","5","113","1452","11576","10","482","1329","35","360","92","46","11034","1.3","192","367","1"
"apache-carbondata","cd61beb59dd27006906d5e6e088acaeb0379d75a","2016-10-11 20:21:44","add block size info in descFormatted and executor log
","refs/heads/master","liujunjie9@huawei.com","apache-carbondata","cd61beb59dd27006906d5e6e088acaeb0379d75a","22","6","0","2589","303","61","3176","36","4521","788","316","4","17","3681","0","15","34","192","apache-carbondata","cd61beb59dd27006906d5e6e088acaeb0379d75a","390","20.6","18","53956","27385","5629","5","1090","57","1398","15.3","2136","28","2.5","5","113","1451","11576","10","482","1329","35","360","92","46","11023","1.3","192","367","1"
"apache-carbondata","f63b1ffcf55abd5995df276889002654a4926e3d","2016-10-14 10:09:58","Added InputProcessorStep to read data from csv reader iterator.

Fixed typo error

Fixed review comments

Fixed review comments

Added license header
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","f63b1ffcf55abd5995df276889002654a4926e3d","22","6","0","2592","303","61","3176","36","4520","787","316","4","17","3681","0","15","34","192","apache-carbondata","f63b1ffcf55abd5995df276889002654a4926e3d","390","20.6","18","53927","27371","5626","5","1090","57","1398","15.3","2135","28","2.5","5","113","1451","11569","10","482","1329","35","360","92","46","11023","1.3","192","367","1"
"apache-carbondata","f9c532d81128ae40c788f350f878f76692f86863","2016-10-09 20:33:05","Add scan_blocklet_num for query statistics

Style

Only struct once

Add valid_scan_blocklet_num

order

Using query stat model

Fix

Fix

Finish all

Finish all

Finish all

Put model into construct mrthod

Fix style

Fix review comments

Rebase
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","f9c532d81128ae40c788f350f878f76692f86863","22","6","0","2592","303","61","3172","36","4520","787","316","4","17","3677","0","15","34","192","apache-carbondata","f9c532d81128ae40c788f350f878f76692f86863","390","20.6","18","53883","27347","5622","5","1090","57","1398","15.3","2133","28","2.5","5","113","1451","11559","10","482","1329","35","360","92","46","11023","1.3","192","367","1"
"apache-carbondata","11198c4a845da1ca460819da02a01bb7f719f575","2016-09-13 07:44:47","add codec and testcase
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","11198c4a845da1ca460819da02a01bb7f719f575","22","6","0","2579","303","61","3136","36","4510","785","316","4","17","3657","0","15","33","192","apache-carbondata","11198c4a845da1ca460819da02a01bb7f719f575","389","20.7","18","53782","27279","5619","5","1087","57","1393","15.4","2132","28","2.5","5","113","1446","11531","10","482","1329","35","360","92","46","10996","1.3","190","366","1"
"apache-carbondata","274b8db060391b271248ede5bd77e3518759b57a","2016-10-15 08:39:27","[CARBONDATA-319]
Bad Records logging for column data type is not proper in case of long, carbon system while creating the table metadata uses BIGINT instead of LONG , internally it converts the bigint to long type and processes , while processing the data if any long type data is having issue it will be logged into the bad record with data type Long which is not proper since as per the metadata the datatype of column is BIGINT.
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","274b8db060391b271248ede5bd77e3518759b57a","22","6","0","2579","303","61","3136","36","4508","785","316","4","17","3656","0","15","33","192","apache-carbondata","274b8db060391b271248ede5bd77e3518759b57a","389","20.7","18","53774","27271","5617","5","1087","57","1393","15.3","2132","28","2.5","5","113","1446","11525","10","482","1329","35","360","92","46","10996","1.3","190","366","1"
"apache-carbondata","e44f7a9cd0441e46437418b71d83fbdb1ebda7cf","2016-10-13 10:38:43","add dictionary interface

remove size()

add PreCreatedDictionary.java

add size()

fix comment
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","e44f7a9cd0441e46437418b71d83fbdb1ebda7cf","22","6","0","2576","303","61","3132","36","4506","785","316","4","17","3656","0","15","33","192","apache-carbondata","e44f7a9cd0441e46437418b71d83fbdb1ebda7cf","389","20.7","18","53741","27245","5616","5","1086","57","1392","15.3","2131","28","2.5","5","113","1445","11509","10","482","1329","35","360","92","46","10995","1.3","190","366","1"
"apache-carbondata","0f730162dc4d93f117ac772eb910dbca6f9c9bd4","2016-10-13 02:47:52","Problem: Data loading fails if parsing a double value returns infinity

Analysis: During data load, if a value specified is too big for a double DataType column then while parsing that value as double result is returned as ""Infinity"". Due to this while we calculate min and max value for measures in carbon data writer step it throws an exception.

Fix: If result is Infinity or NAN for double value parsing then make the value as null and add it to bad records.

Impact area: Data load which contains non parseable values for a datatype.
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","0f730162dc4d93f117ac772eb910dbca6f9c9bd4","22","6","0","2564","303","61","3130","33","4502","783","316","4","14","3656","0","15","33","190","apache-carbondata","0f730162dc4d93f117ac772eb910dbca6f9c9bd4","386","20.6","16","53604","27214","5611","5","1084","57","1390","15.5","2123","28","2.5","5","111","1441","11501","10","482","1329","35","320","91","46","10992","1.3","190","363","1"
"apache-carbondata","70c55c6838d3ca49a058267c93056f8f819019b2","2016-10-11 06:00:34","Add license header for FalseExpression.java

Add license header for FalseExpression.java","refs/heads/master","amy-309@163.com","apache-carbondata","70c55c6838d3ca49a058267c93056f8f819019b2","22","6","0","2564","303","61","3130","33","4501","783","316","4","14","3656","0","15","33","190","apache-carbondata","70c55c6838d3ca49a058267c93056f8f819019b2","386","20.6","16","53600","27210","5608","5","1083","57","1389","15.4","2123","28","2.5","5","111","1440","11498","10","482","1329","35","320","91","46","10981","1.3","190","363","1"
"apache-carbondata","8a0c5f59523ef6d4e5f4485fcb4097e354543325","2016-10-08 23:40:02","fix Path Not Found when Table has ]DbName
","refs/heads/master","liujunjie9@huawei.com","apache-carbondata","8a0c5f59523ef6d4e5f4485fcb4097e354543325","22","6","0","2563","303","61","3130","33","4501","783","316","4","14","3656","0","15","33","190","apache-carbondata","8a0c5f59523ef6d4e5f4485fcb4097e354543325","386","20.6","16","53581","27210","5608","5","1083","57","1389","15.4","2123","28","2.5","5","111","1440","11498","10","482","1329","35","320","91","46","10981","1.3","190","363","1"
"apache-carbondata","4e1154d538a96d8862a2b66815cb5db1dc7e3ed5","2016-10-09 01:41:20","use recoder for all statistic log
","refs/heads/master","foryou2030@126.com","apache-carbondata","4e1154d538a96d8862a2b66815cb5db1dc7e3ed5","22","6","0","2563","303","61","3130","33","4501","783","316","4","14","3656","0","15","33","190","apache-carbondata","4e1154d538a96d8862a2b66815cb5db1dc7e3ed5","386","20.6","16","53579","27208","5608","5","1083","57","1389","15.4","2123","28","2.5","5","111","1440","11498","10","482","1329","35","320","91","46","10981","1.3","190","363","1"
"apache-carbondata","781a66c3eab2749d680c566719be43fa00fd37ed","2016-09-11 14:05:17","[CARBONDATA-233] bad record logger support for non parseable numeric and timestamp data
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","781a66c3eab2749d680c566719be43fa00fd37ed","22","6","0","2563","303","61","3130","33","4501","783","316","4","14","3656","0","15","33","190","apache-carbondata","781a66c3eab2749d680c566719be43fa00fd37ed","386","20.6","16","53574","27204","5606","5","1083","57","1389","15.4","2123","28","2.5","5","111","1440","11496","10","482","1329","35","320","91","46","10981","1.3","190","363","1"
"apache-carbondata","395f4a6bab096838d8b6af93cae099b36da3aacc","2016-09-19 05:55:52","add configurable on-off for query statistics

remove duplicate code

add querid for job

rename method, remove lock, fix checkstyle

rename, lowcase

multi segments will generate multi load_blocks_time, so need to accumulate them
","refs/heads/master","foryou2030@126.com","apache-carbondata","395f4a6bab096838d8b6af93cae099b36da3aacc","22","6","0","2563","303","61","3128","33","4501","783","316","4","14","3656","0","15","33","190","apache-carbondata","395f4a6bab096838d8b6af93cae099b36da3aacc","386","20.6","16","53568","27203","5606","5","1083","57","1389","15.4","2123","28","2.5","5","111","1440","11496","10","482","1329","35","320","91","46","10981","1.3","190","363","1"
"apache-carbondata","793d6901a67e4c78683c14205dce94f03ea2ce42","2016-09-22 01:19:29","Set block_size for table on table level

Fix review comments

Fix example

Fix style

Fix style

set min to 256

set min to 1

Changes done to support different block size for different tables. Modified code to fix review comments.
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","793d6901a67e4c78683c14205dce94f03ea2ce42","22","6","0","2540","301","55","3122","33","4489","761","316","4","12","3642","0","15","32","190","apache-carbondata","793d6901a67e4c78683c14205dce94f03ea2ce42","383","20.7","16","53336","27112","5582","5","1061","57","1366","15.5","2099","28","2.5","5","111","1417","11479","10","482","1329","35","320","91","46","10856","1.3","189","360","1"
"apache-carbondata","fad5e1f840f66ff1d618f7a89b963918130a0698","2016-10-03 21:30:28","change INPUT_DIR to tablePath instead of storePath and add example
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","fad5e1f840f66ff1d618f7a89b963918130a0698","22","6","0","2532","301","55","3120","33","4486","760","316","4","12","3640","0","15","32","190","apache-carbondata","fad5e1f840f66ff1d618f7a89b963918130a0698","383","20.7","16","53302","27095","5583","5","1061","57","1370","15.5","2099","28","2.5","5","111","1421","11472","10","482","1328","35","320","91","50","10860","1.3","189","360","1"
"apache-carbondata","77ca195004f98a265c33a511b83ee7a4dc0c2d6e","2016-09-23 03:48:52","Fixed non filter data mismatch issue.
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","77ca195004f98a265c33a511b83ee7a4dc0c2d6e","22","6","0","2530","301","55","3118","33","4484","760","316","4","12","3638","0","15","32","190","apache-carbondata","77ca195004f98a265c33a511b83ee7a4dc0c2d6e","383","20.7","16","53290","27085","5581","5","1061","57","1370","15.5","2097","28","2.5","5","111","1421","11469","10","482","1328","35","320","91","50","10860","1.3","189","360","1"
"apache-carbondata","e1f217a9d719de5f67417038dc3a6ba0de015567","2016-09-20 11:57:43","configurable blocklet distribution
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","e1f217a9d719de5f67417038dc3a6ba0de015567","22","6","0","2530","301","55","3116","33","4484","760","316","4","12","3638","0","15","32","190","apache-carbondata","e1f217a9d719de5f67417038dc3a6ba0de015567","383","20.7","16","53286","27081","5580","5","1061","57","1370","15.5","2097","28","2.5","5","111","1421","11466","10","482","1328","35","320","91","50","10860","1.3","189","360","1"
"apache-carbondata","5a3d5bb84c9f7689428f60d776e90523f6582319","2016-09-20 06:49:31","fixed limit query issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","5a3d5bb84c9f7689428f60d776e90523f6582319","22","6","0","2530","301","55","3100","33","4484","760","316","4","12","3638","0","15","32","190","apache-carbondata","5a3d5bb84c9f7689428f60d776e90523f6582319","383","20.7","14","53276","27079","5580","5","1059","57","1366","15.5","2097","28","2.5","5","109","1415","11466","10","482","1328","35","280","91","50","10836","1.3","187","360","1"
"apache-carbondata","fa722bd876fa5faa43ecf4b0404f9d0e581d56ae","2016-09-13 02:12:13","removed no used carbon common constants

remove those same values but different name
","refs/heads/master","foryou2030@126.com","apache-carbondata","fa722bd876fa5faa43ecf4b0404f9d0e581d56ae","22","6","0","2530","301","55","3100","33","4483","761","316","4","12","3637","0","15","32","190","apache-carbondata","fa722bd876fa5faa43ecf4b0404f9d0e581d56ae","383","20.7","14","53261","27070","5578","5","1060","57","1367","15.5","2095","28","2.5","5","109","1416","11465","10","482","1328","35","280","91","50","10833","1.3","187","360","1"
"apache-carbondata","9695807367f6b9fdb813d7a6874e20a0cd2498a7","2016-09-17 20:00:35","inspection

code inspection optiminization

style

style
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","9695807367f6b9fdb813d7a6874e20a0cd2498a7","22","6","0","2536","301","56","3118","33","4483","761","316","4","12","3637","0","15","32","190","apache-carbondata","9695807367f6b9fdb813d7a6874e20a0cd2498a7","383","20.7","14","53326","27090","5578","5","1060","57","1367","15.5","2095","28","2.5","5","109","1416","11465","10","482","1328","35","280","91","50","10835","1.3","187","360","1"
"apache-carbondata","7e81407714ad8878e50b075df3283ea3984271e5","2016-09-17 15:31:10","[CARBONDATA-250] Filter result is not proper when Double data type values with 0.0 and -0.0 will be used.
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","7e81407714ad8878e50b075df3283ea3984271e5","22","6","0","2536","301","56","3118","33","4483","761","316","4","12","3638","0","15","32","190","apache-carbondata","7e81407714ad8878e50b075df3283ea3984271e5","383","20.7","14","53328","27092","5579","5","1060","57","1367","15.5","2095","28","2.5","5","109","1416","11466","10","482","1328","35","280","91","50","10835","1.3","187","360","1"
"apache-carbondata","b87c743405987b81e793140d223c5935ac45e8ec","2016-09-17 06:25:36","equalsAndHashCodeIssue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","b87c743405987b81e793140d223c5935ac45e8ec","22","6","0","2534","301","56","3114","33","4479","760","316","4","12","3639","0","15","32","186","apache-carbondata","b87c743405987b81e793140d223c5935ac45e8ec","383","20.7","14","53308","27083","5574","5","1060","57","1367","15.5","2094","28","2.5","5","108","1415","11461","10","477","1328","34","280","91","50","10835","1.3","187","360","1"
"apache-carbondata","070fb409e780cae70de4beeb60e2ab95de24485b","2016-09-17 00:03:31","Problem:Column heading was missing in driver statistics table and scan block time was always zero in query statistics table.

Analysis:While creating driver statistics table header was not created and the scan block time was not initialized before recording in statistics recorder.

Fix:One more line is added to print the column header in driver statistics table and the scan block time is initialized before recording the statistics.

Impact:Logs of all query
","refs/heads/master","akash.r.nilugal@huawei.com","apache-carbondata","070fb409e780cae70de4beeb60e2ab95de24485b","22","6","0","2532","294","56","3110","33","4472","759","316","4","12","3623","0","15","33","186","apache-carbondata","070fb409e780cae70de4beeb60e2ab95de24485b","382","20.7","14","53193","27029","5545","5","1059","57","1366","15.4","2090","28","2.5","5","107","1412","11425","9","465","1328","32","280","91","50","10810","1.3","187","359","1"
"apache-carbondata","9702f7a89179a610bd4c8c87e52994d94a946257","2016-09-17 02:48:22","disabling the system compaction lock feature. and making the load ddl to wait for compaction to finish in the auto compaction case.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","9702f7a89179a610bd4c8c87e52994d94a946257","22","6","0","2532","294","56","3110","33","4472","759","316","4","12","3622","0","15","33","186","apache-carbondata","9702f7a89179a610bd4c8c87e52994d94a946257","382","20.7","14","53190","27026","5545","5","1058","57","1365","15.4","2090","28","2.5","5","107","1411","11424","9","465","1328","32","280","91","50","10809","1.3","187","359","1"
"apache-carbondata","ebe987b22a92090a91471534711a63187081f907","2016-09-16 11:34:38","if for any reason data load is failed during the dictionary generation then in the finally block trying to write the meta file but as the stream is null, it will throw null pointer.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","ebe987b22a92090a91471534711a63187081f907","22","6","0","2532","294","56","3110","33","4472","759","316","4","12","3622","0","15","33","186","apache-carbondata","ebe987b22a92090a91471534711a63187081f907","382","20.7","14","53189","27026","5545","5","1058","57","1365","15.4","2090","28","2.5","5","107","1411","11424","9","465","1328","32","280","91","50","10811","1.3","187","359","1"
"apache-carbondata","286904eaf2454441d200dcb8bba1d0c9d537a1e2","2016-09-15 01:41:00","Fixed out of memory issue during query execution, as invalid segments are not getting deleted from Btree
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","286904eaf2454441d200dcb8bba1d0c9d537a1e2","22","6","0","2532","294","56","3110","33","4472","758","316","4","12","3622","0","15","33","186","apache-carbondata","286904eaf2454441d200dcb8bba1d0c9d537a1e2","382","20.7","14","53177","27020","5539","5","1058","57","1365","15.4","2089","28","2.5","5","107","1411","11421","9","465","1328","32","280","91","50","10811","1.3","187","359","1"
"apache-carbondata","34e36dde75e4d964c06f067586ed4121464f0ea3","2016-09-15 02:23:04","[Issue Number] CARBONDATA-242
[Description] When user provides Null member inside NOT IN filter condition the resultset is not compatible with hive result
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","34e36dde75e4d964c06f067586ed4121464f0ea3","22","6","0","2530","293","55","3094","33","4459","757","316","4","12","3619","0","15","33","186","apache-carbondata","34e36dde75e4d964c06f067586ed4121464f0ea3","382","20.7","14","53091","26964","5524","5","1056","57","1363","15.4","2087","28","2.5","5","107","1409","11383","9","465","1328","32","280","91","50","10798","1.3","187","359","1"
"apache-carbondata","528c2bef86bda2bb62dd29c53a229ebb515fe8a9","2016-09-14 09:23:12","[CARBONDATA-212] Use SQLContext to read CarbonData files
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","528c2bef86bda2bb62dd29c53a229ebb515fe8a9","22","6","0","2526","293","55","3094","33","4457","758","316","4","12","3619","0","15","33","186","apache-carbondata","528c2bef86bda2bb62dd29c53a229ebb515fe8a9","381","20.7","14","53034","26932","5516","5","1056","57","1362","15.4","2083","28","2.5","5","107","1408","11377","9","465","1328","32","280","91","50","10789","1.3","186","358","1"
"apache-carbondata","9030923e377d4b2a919799ce689aebfff1adbb76","2016-09-08 00:38:56","Problem: Array Index of bound exception thrown from dictionary look up while writing sort index file

Analysis: Whenever we load dictionary data into memory, then in case of populating reverse dictionary object sometimes a chunk which has no value is also getting added to the dictionary chunk list. This is happening because the logic for dictionary chunk distribution in case of forward dictionary is not implemented for reverse dictionary and 0 size dictionary chunks are not getting removed while adding to the list of dictionary chunks.

Solution: Add the same distribution logic we have in forward dictionary for populating reverse dictionary object

Impact area: Sort index generation
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","9030923e377d4b2a919799ce689aebfff1adbb76","22","6","0","2525","293","55","3094","33","4450","758","316","4","12","3618","0","15","33","186","apache-carbondata","9030923e377d4b2a919799ce689aebfff1adbb76","381","20.7","14","53011","26917","5512","5","1056","57","1362","15.4","2081","28","2.5","5","107","1408","11368","9","465","1328","32","280","91","50","10789","1.3","186","358","1"
"apache-carbondata","c5b45f444344ad121dfd9704f519af9054474d0e","2016-09-07 07:46:28","fixed query issue, use different actualoffset
","refs/heads/master","foryou2030@126.com","apache-carbondata","c5b45f444344ad121dfd9704f519af9054474d0e","22","6","0","2525","293","55","3094","33","4450","758","316","4","12","3618","0","15","33","186","apache-carbondata","c5b45f444344ad121dfd9704f519af9054474d0e","381","20.7","14","53009","26915","5511","5","1056","57","1362","15.4","2081","28","2.5","5","107","1408","11367","9","465","1328","32","280","91","50","10789","1.3","186","358","1"
"apache-carbondata","95457612a1205da017989a0c9d1b85be3d73e853","2016-09-07 06:58:18","show cost as mills instead of seconds
","refs/heads/master","foryou2030@126.com","apache-carbondata","95457612a1205da017989a0c9d1b85be3d73e853","22","6","0","2525","293","55","3094","33","4450","758","316","4","12","3616","0","15","33","186","apache-carbondata","95457612a1205da017989a0c9d1b85be3d73e853","381","20.7","14","53004","26910","5511","5","1055","57","1361","15.4","2081","28","2.5","5","107","1407","11364","9","465","1328","32","280","91","50","10774","1.3","186","358","1"
"apache-carbondata","952ba38699367c7f336f4ed07ed606ad38d14e2c","2016-09-06 07:37:23","compress CSV file using GZIP while loading
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","952ba38699367c7f336f4ed07ed606ad38d14e2c","22","6","0","2525","293","55","3102","33","4454","758","316","4","12","3617","0","15","33","186","apache-carbondata","952ba38699367c7f336f4ed07ed606ad38d14e2c","381","20.7","14","53018","26918","5512","5","1055","57","1361","15.4","2082","28","2.5","5","107","1407","11367","9","465","1328","32","280","91","50","10774","1.3","186","358","1"
"apache-carbondata","dc5dfebd04834496e43ed25e6245db23aae66ada","2016-09-02 03:22:03","clear query statistics map
","refs/heads/master","foryou2030@126.com","apache-carbondata","dc5dfebd04834496e43ed25e6245db23aae66ada","22","6","0","2525","293","55","3106","33","4455","759","316","4","12","3616","0","15","33","186","apache-carbondata","dc5dfebd04834496e43ed25e6245db23aae66ada","381","20.7","14","53011","26911","5517","5","1054","57","1360","15.4","2082","28","2.5","5","107","1406","11363","9","465","1328","32","280","91","50","10769","1.3","186","358","1"
"apache-carbondata","5aedf54437757e645bb360a913c424418c433b45","2016-09-02 03:36:05","Problem: Code contains currentRestructureNumber variable which is not used in the code now

Impact area: Data load flow

Fix: Remove the usage of currentRestructureNumber variable everywhere in the code
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","5aedf54437757e645bb360a913c424418c433b45","22","6","0","2524","290","56","3092","33","4448","758","316","4","12","3575","0","15","33","186","apache-carbondata","5aedf54437757e645bb360a913c424418c433b45","381","20.7","14","52946","26864","5506","5","1048","57","1351","15.4","2081","28","2.5","5","107","1397","11342","9","465","1328","32","280","91","51","10729","1.3","182","358","1"
"apache-carbondata","40595a90f2ebd1dfca001dd31f450c31ff096065","2016-09-02 02:18:37","handled all dictionary exception

add testcase

remove rdd.count

use better sentence
","refs/heads/master","foryou2030@126.com","apache-carbondata","40595a90f2ebd1dfca001dd31f450c31ff096065","22","6","0","2527","291","57","3092","33","4458","760","316","4","12","3580","0","15","31","186","apache-carbondata","40595a90f2ebd1dfca001dd31f450c31ff096065","381","20.7","14","53022","26912","5524","5","1051","57","1355","15.4","2084","28","2.5","5","107","1401","11368","9","465","1328","32","280","91","51","10760","1.3","183","358","1"
"apache-carbondata","12be50bc631be05be18bbe0d4b3b54f7c6540cb8","2016-08-24 04:20:07","add more query statistics

example recovery

show statistics as table

add query id for decoder

add common constants file

print driver log and executor log seperately

add single recorder

and lock for log

fixed example
","refs/heads/master","foryou2030@126.com","apache-carbondata","12be50bc631be05be18bbe0d4b3b54f7c6540cb8","22","6","0","2527","291","57","3094","33","4458","760","316","4","12","3580","0","15","31","186","apache-carbondata","12be50bc631be05be18bbe0d4b3b54f7c6540cb8","381","20.7","14","53026","26913","5524","5","1051","57","1355","15.4","2084","28","2.5","5","107","1401","11368","9","465","1328","32","280","91","51","10760","1.3","183","358","1"
"apache-carbondata","ffbb35964dd5246c59ffc5b26d5239d9791448cf","2016-08-31 09:40:44","1. implemented system level compaction lock feature.
2. made the DDL call to compaction as blocking call.
3. handled the reqests which are received during one compaction and taking those requests later.
4. Supported property ""carbon.concurrent.compaction"" default to false
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","ffbb35964dd5246c59ffc5b26d5239d9791448cf","22","6","0","2503","287","17","3036","31","4413","754","316","4","12","3548","0","15","31","186","apache-carbondata","ffbb35964dd5246c59ffc5b26d5239d9791448cf","379","20.8","14","52614","26644","5483","5","1030","57","1316","15.4","2072","28","2.5","5","105","1362","11227","9","465","1328","32","280","91","50","10644","1.3","168","356","1"
"apache-carbondata","fc57aa6f50dd201e95a059b969df1a362f938bcd","2016-08-31 07:48:11","[CARBONDATA-195] Select query with AND filter failing for empty '' operand value of numeric column
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","fc57aa6f50dd201e95a059b969df1a362f938bcd","22","6","0","2501","287","17","3008","31","4413","754","316","4","12","3548","0","15","31","186","apache-carbondata","fc57aa6f50dd201e95a059b969df1a362f938bcd","379","20.8","9","52587","26638","5483","5","1025","57","1308","15.4","2072","28","2.5","5","100","1349","11227","9","465","1328","32","180","91","50","10586","1.3","165","356","1"
"apache-carbondata","5fa76712ac6ee13d3944b8b9bbb68c2a8a67de50","2016-07-19 11:48:50","Fixed issues after merge to apache/master
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","5fa76712ac6ee13d3944b8b9bbb68c2a8a67de50","23","8","0","2488","291","17","2922","30","4321","754","311","4","11","3525","0","15","31","190","apache-carbondata","5fa76712ac6ee13d3944b8b9bbb68c2a8a67de50","383","20.6","7","51862","26366","5410","5","1019","59","1295","15","2051","30","2.6","5","96","1332","11081","7","445","1374","30","140","93","53","10505","1.3","157","360","1"
"apache-carbondata","3b1c8345ef2fd5d2ae3bcabcca64b3dbfacb1ccc","2016-08-30 18:34:12","Fix the bug that negtive data compress is not properly when datatype is Double
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","3b1c8345ef2fd5d2ae3bcabcca64b3dbfacb1ccc","22","6","0","2501","287","17","3008","31","4413","753","316","4","12","3548","0","15","31","186","apache-carbondata","3b1c8345ef2fd5d2ae3bcabcca64b3dbfacb1ccc","379","20.8","9","52589","26640","5484","5","1024","57","1307","15.4","2072","28","2.5","5","100","1348","11228","9","465","1328","32","180","91","50","10577","1.3","165","356","1"
"apache-carbondata","7a8ca5393bf636b2f1b7841f935de6ce9ede4a65","2016-08-24 13:02:02","[CARBONDATA-177] Greater than and Less than filter returning wrong result
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","7a8ca5393bf636b2f1b7841f935de6ce9ede4a65","22","6","0","2500","287","17","3008","31","4412","753","316","4","12","3548","0","15","31","186","apache-carbondata","7a8ca5393bf636b2f1b7841f935de6ce9ede4a65","379","20.8","9","52585","26638","5477","5","1023","57","1306","15.4","2072","28","2.5","5","100","1347","11227","9","465","1328","32","180","91","50","10560","1.3","165","356","1"
"apache-carbondata","fe56ad0dd1c30008b032af7796b23ebb0628d1aa","2016-08-29 05:55:46","Fiex Data Mismatch issue in filter query
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","fe56ad0dd1c30008b032af7796b23ebb0628d1aa","22","6","0","2500","287","17","3008","31","4412","753","316","4","12","3548","0","15","31","186","apache-carbondata","fe56ad0dd1c30008b032af7796b23ebb0628d1aa","379","20.8","9","52579","26633","5475","5","1023","57","1306","15.4","2072","28","2.5","5","100","1347","11225","9","465","1328","32","180","91","50","10559","1.3","165","356","1"
"apache-carbondata","d0c0f647a92ff3b4ccb4cd44eebf1316513ba88d","2016-08-29 08:10:00","Fixed Data mismatch issue when inverted index is disabled
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d0c0f647a92ff3b4ccb4cd44eebf1316513ba88d","22","6","0","2500","287","17","3006","31","4410","753","316","4","12","3545","0","15","31","186","apache-carbondata","d0c0f647a92ff3b4ccb4cd44eebf1316513ba88d","379","20.8","9","52567","26629","5474","5","1022","57","1305","15.4","2072","28","2.5","5","100","1346","11221","9","465","1328","32","180","91","50","10549","1.3","165","356","1"
"apache-carbondata","276a3ff2706b6d00a25d5bee2390d1ba3c6ea475","2016-08-25 03:40:29","Double min max difference compression issue.
1.While compressing maxdifference typecast with proper DataType
2.While writting we follow like
a. diff with max value , say d = max - x
b. multiply with 10^decimal i.e w = d*10^decimal
3.Similarly while reading we should follow like
a. divide written value 10^decimal i.e d = w/10^decimal
b. diff with max i.e x = max -d
4. There is problem in java with double subtraction
i.e double value = 3.141818 - 0.000610
java will result 3.1412080000000002
To avoid this we are converting to BigDecimal and then doing subtraction
5.Changed logic to calculate no of integer after decimal.
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","276a3ff2706b6d00a25d5bee2390d1ba3c6ea475","22","6","0","2500","287","17","3006","31","4410","753","316","4","12","3545","0","15","31","186","apache-carbondata","276a3ff2706b6d00a25d5bee2390d1ba3c6ea475","379","20.8","9","52567","26629","5474","5","1022","57","1305","15.4","2072","28","2.5","5","100","1346","11221","9","465","1328","32","180","91","50","10549","1.3","165","356","1"
"apache-carbondata","ceda339833ee76616ed7183fe822798a1f3f7b9c","2016-08-22 03:00:00","adapt data with header for all dictionary

use DEFAULT_CHARSET

remove listFiles
","refs/heads/master","foryou2030@126.com","apache-carbondata","ceda339833ee76616ed7183fe822798a1f3f7b9c","22","6","0","2500","287","17","3006","31","4385","753","316","4","12","3515","0","15","31","184","apache-carbondata","ceda339833ee76616ed7183fe822798a1f3f7b9c","379","20.8","9","52534","26597","5474","5","1021","57","1303","15.4","2072","28","2.5","5","100","1344","11196","9","465","1328","32","180","91","50","10543","1.3","164","356","1"
"apache-carbondata","6187b13fd6cb304a5900c2c6f21c26d07c59b9fa","2016-08-26 23:42:16","Handle all dictionary exception more properly

modifed by suggestions
","refs/heads/master","foryou2030@126.com","apache-carbondata","6187b13fd6cb304a5900c2c6f21c26d07c59b9fa","22","6","0","2500","287","17","3006","31","4384","753","316","4","12","3512","0","15","31","184","apache-carbondata","6187b13fd6cb304a5900c2c6f21c26d07c59b9fa","379","20.8","9","52504","26575","5471","5","1020","57","1302","15.4","2071","28","2.5","5","100","1343","11185","9","465","1328","32","180","91","50","10528","1.3","164","356","1"
"apache-carbondata","cb8abfef529f2ed594f36493fe745f3a763e3847","2016-08-26 02:10:27","Fixed special char delimiter for complex data.
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","cb8abfef529f2ed594f36493fe745f3a763e3847","22","6","0","2500","287","17","3004","31","4384","753","316","4","12","3512","0","15","31","184","apache-carbondata","cb8abfef529f2ed594f36493fe745f3a763e3847","379","20.8","9","52501","26572","5469","5","1020","57","1302","15.4","2071","28","2.5","5","100","1343","11183","9","465","1328","32","180","91","50","10528","1.3","164","356","1"
"apache-carbondata","8e75531a447e92ef145b75b7acc86732a0228706","2016-08-23 23:30:50","fix the problem of hdfs lock and move the lock file inside the table folder

fix the problem of hdfs lock and move the lock file inside the table folder
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","8e75531a447e92ef145b75b7acc86732a0228706","22","6","0","2501","287","17","3004","31","4384","753","316","4","12","3512","0","15","31","184","apache-carbondata","8e75531a447e92ef145b75b7acc86732a0228706","379","20.8","9","52483","26560","5457","5","1019","57","1301","15.3","2071","28","2.5","5","100","1342","11184","9","465","1328","32","180","91","50","10510","1.3","164","356","1"
"apache-carbondata","fe1b0f07deda03fe21b98191be7750bf61d8520c","2016-07-20 03:32:18","CARBONDATA-117 BlockLet distribution for optimum resource usage
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","fe1b0f07deda03fe21b98191be7750bf61d8520c","22","6","0","2501","287","17","3004","31","4384","753","316","4","12","3512","0","15","31","184","apache-carbondata","fe1b0f07deda03fe21b98191be7750bf61d8520c","379","20.8","9","52475","26558","5457","5","1019","57","1301","15.3","2071","28","2.5","5","100","1342","11184","9","465","1328","32","180","91","50","10510","1.3","164","356","1"
"apache-carbondata","7e0584e7a1d90724e88fffd6fcea15e5ba640da8","2016-07-19 02:25:52","Perform equal distribution of dictionary values among the sublists of a list whenever a dictionary file is loaded into memory
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","7e0584e7a1d90724e88fffd6fcea15e5ba640da8","22","6","0","2499","283","17","2970","31","4361","752","315","4","12","3473","0","15","31","184","apache-carbondata","7e0584e7a1d90724e88fffd6fcea15e5ba640da8","378","20.7","9","52218","26455","5446","5","1018","57","1299","15.3","2067","28","2.5","5","100","1340","11141","9","465","1328","32","180","91","50","10499","1.3","163","355","1"
"apache-carbondata","cd6a4ff33a0a7ab97e820d82d2aa3044351d0cae","2016-08-14 09:40:43","Renamed packages to org.apache.carbondata and fixed errors
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","cd6a4ff33a0a7ab97e820d82d2aa3044351d0cae","23","6","0","2491","283","17","2924","31","4337","749","315","4","12","3464","0","15","31","182","apache-carbondata","cd6a4ff33a0a7ab97e820d82d2aa3044351d0cae","377","20.7","9","51988","26344","5426","5","1018","57","1296","15.3","2058","28","2.6","5","100","1337","11086","9","465","1328","32","180","91","50","10512","1.3","160","354","1"
"apache-carbondata","d03af4a5523ee7fc2ac27271ed1787a88861707c","2016-08-09 20:09:20","fix the bug og block prune

fix review comments

fix review comments

fix review comments
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","d03af4a5523ee7fc2ac27271ed1787a88861707c","23","6","0","2493","283","17","2924","31","4337","749","315","4","12","3464","0","15","31","182","apache-carbondata","d03af4a5523ee7fc2ac27271ed1787a88861707c","377","20.7","9","51980","26330","5426","5","1018","57","1296","15.3","2058","28","2.6","5","100","1337","11086","9","465","1328","32","180","91","50","10512","1.3","160","354","1"
"apache-carbondata","f8efc66d93bcb9945329c4f22c2cce82970357af","2016-08-11 06:14:55","Fixed query fails on bigdata issue

Fixed query fails on bigdata issue2

Fixed query fails on bigdata issue3

Fixed join with carbon and other table
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","f8efc66d93bcb9945329c4f22c2cce82970357af","23","6","0","2490","283","17","2920","31","4326","750","315","4","12","3461","0","15","32","182","apache-carbondata","f8efc66d93bcb9945329c4f22c2cce82970357af","377","20.7","9","51934","26294","5423","5","1018","57","1295","15.3","2058","28","2.6","5","99","1336","11069","9","465","1328","32","180","91","50","10516","1.3","160","354","1"
"apache-carbondata","fd5493b9dd4ebbba2a7cbec33dd8fc301b1e8316","2016-08-06 01:39:51","Merge remote-tracking branch 'apache-master/master' into merge7
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","fd5493b9dd4ebbba2a7cbec33dd8fc301b1e8316","23","6","0","2487","283","17","2920","31","4327","749","315","4","12","3464","0","15","32","182","apache-carbondata","fd5493b9dd4ebbba2a7cbec33dd8fc301b1e8316","377","20.7","9","51912","26275","5414","5","1016","57","1293","15.3","2056","28","2.6","5","99","1334","11061","9","465","1328","32","180","91","50","10499","1.3","160","354","1"
"apache-carbondata","b38468aa5cc2bcd80e44fc7cdb6ab0ceaacf3b12","2016-08-05 02:16:32","[CARBONDATA-140] Fix all legal headers, add the legal files (NOTICE, DISCLAIMER) and fix LICENSE file
","refs/heads/master","jbonofre@apache.org","apache-carbondata","b38468aa5cc2bcd80e44fc7cdb6ab0ceaacf3b12","23","6","0","2486","283","17","2916","31","4326","749","315","4","12","3463","0","15","32","182","apache-carbondata","b38468aa5cc2bcd80e44fc7cdb6ab0ceaacf3b12","377","20.7","9","51877","26257","5411","5","1016","57","1293","15.3","2054","28","2.6","5","99","1334","11056","9","465","1328","32","180","91","50","10499","1.3","160","354","1"
"apache-carbondata","975983816666c07b401fdc75b9729c3fabe61e88","2016-08-04 06:58:37","Merge remote-tracking branch 'HuaweiBigData/master' into apache/master

Conflicts:
	core/src/main/java/org/carbondata/query/aggregator/impl/AvgBigDecimalAggregator.java
	core/src/main/java/org/carbondata/query/carbon/executor/internal/impl/InternalDetailQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/AbstractDetailQueryResultIterator.java
	integration/spark/src/main/scala/org/apache/spark/sql/execution/command/carbonTableSchema.scala
	integration/spark/src/main/scala/org/carbondata/spark/agg/CarbonAggregates.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDataRDDFactory.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonScanRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/util/CarbonScalaUtil.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/joinquery/EquiJoinTestCase.scala
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","975983816666c07b401fdc75b9729c3fabe61e88","23","6","0","2479","283","17","2920","31","4327","749","315","4","12","3464","0","15","32","182","apache-carbondata","975983816666c07b401fdc75b9729c3fabe61e88","377","20.7","9","51768","26275","5414","5","1016","57","1293","15.3","2056","28","2.6","5","99","1334","11061","9","465","1328","32","180","91","50","10499","1.3","160","354","1"
"apache-carbondata","89847ea20308d6685c0d28dbbadd620bffb971b5","2016-08-04 04:47:16","[CARBONDATA-128] Modification done to read thrift files using Tcompact protocol (#907)

replace Tbinary protocol with TCompact for performance ","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","89847ea20308d6685c0d28dbbadd620bffb971b5","27","6","0","3296","323","22","3522","48","5450","976","362","4","16","4487","0","13","37","230","apache-carbondata","89847ea20308d6685c0d28dbbadd620bffb971b5","513","20.1","14","66668","33736","6883","5","1265","77","1614","14.3","2726","44","2.5","5","145","1681","14119","11","860","1691","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","1721d40d3d44d91c8f1115febc8a449071129f22","2016-08-04 04:24:07","[CARBONDATA-139] Sortindex read by by appending offset from metadata (#905)

During sort index reading phase, read offset from dictionary chunk meta and then get respective file.
Corrected testcase","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","1721d40d3d44d91c8f1115febc8a449071129f22","27","6","0","3296","323","22","3522","48","5450","976","362","4","16","4487","0","13","37","230","apache-carbondata","1721d40d3d44d91c8f1115febc8a449071129f22","513","20.2","14","66666","33734","6883","5","1265","77","1614","14.3","2726","44","2.5","5","145","1681","14119","11","860","1691","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","07fe4d2132f62ffaa3eac5a67315ffb6183ee45a","2016-08-04 03:40:43","[CARBONDATA-138] Avg aggregation for decimal type keeping sync with hive (#900)

scale up the decimal value during average aggregation","refs/heads/master","zhujin2@huawei.com","apache-carbondata","07fe4d2132f62ffaa3eac5a67315ffb6183ee45a","27","6","0","3295","323","22","3518","48","5449","976","362","4","16","4485","0","13","37","230","apache-carbondata","07fe4d2132f62ffaa3eac5a67315ffb6183ee45a","513","20.1","14","66637","33718","6880","5","1265","77","1614","14.3","2724","44","2.5","5","145","1681","14114","11","860","1691","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","75ddcceb7bf6e681dd63c0bd082aeaeb6dd7388a","2016-08-04 00:33:38","[CARBONDATA-135] Fixed multiple hdfs client creation issue-Query scan flow (#902)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","75ddcceb7bf6e681dd63c0bd082aeaeb6dd7388a","27","6","0","3295","323","22","3518","48","5447","976","362","4","16","4485","0","13","37","230","apache-carbondata","75ddcceb7bf6e681dd63c0bd082aeaeb6dd7388a","513","20.1","14","66629","33714","6880","5","1265","77","1614","14.3","2724","44","2.5","5","145","1681","14112","11","860","1691","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","b327375a39f485574782441b425754aa64904d0d","2016-08-04 00:00:50","[CARBONDATA-136] Fixed Query data mismatch issue after compaction (#903)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","b327375a39f485574782441b425754aa64904d0d","27","6","0","3295","323","22","3518","48","5447","976","362","4","16","4486","0","13","37","230","apache-carbondata","b327375a39f485574782441b425754aa64904d0d","513","20.1","14","66629","33715","6880","5","1265","77","1614","14.3","2724","44","2.5","5","145","1681","14112","11","860","1691","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","9be7451ec7bb5561b1f142ebdd40d6048713760e","2016-07-21 08:20:33","Refactored code to improve performance by using removing unnecessary conversion.

Refactored code

Fixed review comments

support create using select as for other formats

Fixed issues after merge
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9be7451ec7bb5561b1f142ebdd40d6048713760e","23","6","0","2478","283","17","2916","31","4326","749","315","4","12","3463","0","15","32","182","apache-carbondata","9be7451ec7bb5561b1f142ebdd40d6048713760e","377","20.7","9","51733","26257","5411","5","1016","57","1293","15.3","2054","28","2.6","5","99","1334","11056","9","465","1328","32","180","91","50","10499","1.3","160","354","1"
"apache-carbondata","f9c2e57d670a51d5d8379f8b9b89a37b6909ce10","2016-08-01 07:20:26","[CARBONDATA-130]Adapt kettle home when  ""carbon.kettle.home"" configuration is wrong (#889)

Generally kettle home is inside carbon lib so same can be looked in default","refs/heads/master","zhujin2@huawei.com","apache-carbondata","f9c2e57d670a51d5d8379f8b9b89a37b6909ce10","27","6","0","3295","323","22","3516","48","5446","976","362","4","16","4486","0","13","38","230","apache-carbondata","f9c2e57d670a51d5d8379f8b9b89a37b6909ce10","513","20.1","14","66625","33716","6881","5","1265","77","1614","14.3","2724","44","2.5","5","145","1681","14111","11","860","1693","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","21d8c7ea6884d820605a187dcf2bcb6787aa09a6","2016-08-01 02:42:44","Fixed issues after merge
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","21d8c7ea6884d820605a187dcf2bcb6787aa09a6","23","6","0","2492","291","17","2926","31","4335","753","313","4","11","3551","0","15","32","190","apache-carbondata","21d8c7ea6884d820605a187dcf2bcb6787aa09a6","383","20.6","9","52072","26477","5444","5","1020","57","1297","15.1","2054","28","2.6","5","99","1338","11138","9","465","1328","32","180","93","52","10512","1.3","158","360","1"
"apache-carbondata","50dfdf6c8eea672665fe99c5ac4603107a435209","2016-08-01 00:28:17","Merge remote-tracking branch 'carbon_master/master' into apache/master

Conflicts:
	core/src/main/java/org/carbondata/core/util/DataTypeUtil.java
	core/src/main/java/org/carbondata/query/aggregator/impl/CountAggregator.java
	core/src/main/java/org/carbondata/query/aggregator/util/MeasureAggregatorFactory.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/AbstractDetailQueryResultIterator.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/DetailQueryResultIterator.java
	core/src/main/java/org/carbondata/scan/executor/util/QueryUtil.java
	core/src/main/java/org/carbondata/scan/filter/FilterExpressionProcessor.java
	core/src/main/java/org/carbondata/scan/filter/FilterUtil.java
	core/src/main/java/org/carbondata/scan/filter/resolver/AndFilterResolverImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/LogicalFilterResolverImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/visitor/DictionaryColumnVisitor.java
	integration/spark/src/main/java/org/carbondata/integration/spark/merger/CompactionCallable.java
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonOperators.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonSqlParser.scala
	integration/spark/src/main/scala/org/apache/spark/sql/execution/command/carbonTableSchema.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonMetastoreCatalog.scala
	integration/spark/src/main/scala/org/carbondata/spark/agg/CarbonAggregates.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDataRDDFactory.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonGlobalDictionaryRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonMergerRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonScanRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/Compactor.scala
	integration/spark/src/main/scala/org/carbondata/spark/util/CarbonScalaUtil.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/directdictionary/TimestampDataTypeDirectDictionaryTestCase.scala
	processing/src/main/java/org/carbondata/processing/mdkeygen/MDKeyGenStep.java
	processing/src/main/java/org/carbondata/processing/sortandgroupby/sortdata/SortDataRows.java
	processing/src/main/java/org/carbondata/processing/surrogatekeysgenerator/csvbased/CarbonCSVBasedSeqGenStep.java
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","50dfdf6c8eea672665fe99c5ac4603107a435209","23","6","0","2498","291","17","2926","32","4340","754","313","4","13","3551","0","17","32","192","apache-carbondata","50dfdf6c8eea672665fe99c5ac4603107a435209","384","20.6","9","52126","26501","5449","5","1020","57","1301","15.1","2059","28","2.5","5","100","1342","11147","9","465","1328","32","180","94","52","10531","1.3","161","361","1"
"apache-carbondata","f495b6bd4653b7bb3139377cd93b4d16425553a7","2016-07-28 20:49:03","[Bug]Changed locking so that zookeeper lock or hdfs lock will be available at executer. (#885)

[Bug]Changed locking so that zookeeper lock or hdfs lock will be available at executer. (#885)","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","f495b6bd4653b7bb3139377cd93b4d16425553a7","27","6","0","3295","323","22","3516","48","5446","976","362","4","16","4486","0","13","38","230","apache-carbondata","f495b6bd4653b7bb3139377cd93b4d16425553a7","513","20.1","14","66621","33715","6881","5","1265","77","1614","14.3","2724","44","2.5","5","145","1681","14111","11","860","1693","53","280","123","64","12878","1.3","196","481","1"
"apache-carbondata","066f74b649257b02e0e0b07c34ddc61661f267b4","2016-07-28 19:27:02","[CARBONDATA-122] Block distribution give second and third preferred locaiton (#887)

  Give second and third option for node distribution
 Support second and third locations option for dataload
","refs/heads/master","g.ramana.v1@gmail.com","apache-carbondata","066f74b649257b02e0e0b07c34ddc61661f267b4","27","6","0","3294","323","22","3514","46","5443","976","362","4","16","4486","0","13","38","230","apache-carbondata","066f74b649257b02e0e0b07c34ddc61661f267b4","513","20.1","14","66577","33686","6873","5","1264","77","1613","14.3","2723","44","2.5","5","145","1680","14101","11","860","1693","53","280","123","64","12873","1.3","196","481","1"
"apache-carbondata","5341c7dce8ce1a260d1ac48af67d58cd12331ba6","2016-07-28 17:35:39","[CARBONDATA-118][Bug] Temp location clean up in compaction (#883)

Passed compaction temporary location to compaction and data load merge flow. Handled clean up of that temp folder.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","5341c7dce8ce1a260d1ac48af67d58cd12331ba6","27","6","0","3292","323","22","3514","46","5442","974","360","4","16","4486","0","13","38","230","apache-carbondata","5341c7dce8ce1a260d1ac48af67d58cd12331ba6","513","20.1","14","66571","33681","6873","5","1264","77","1613","14.3","2723","44","2.5","5","145","1680","14099","11","860","1693","53","280","123","64","12873","1.3","196","481","1"
"apache-carbondata","935e0d3a6dad7300adc980df6bfacc1272dff904","2016-07-28 11:51:39","[CARBONDATA-112] Regexp_replace function is throwing NullPointerException (#867)

as the expression is evaluated on executor side in carbon, transient variable was not initialized.","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","935e0d3a6dad7300adc980df6bfacc1272dff904","27","6","0","3292","323","22","3506","46","5442","974","360","4","16","4486","0","13","38","230","apache-carbondata","935e0d3a6dad7300adc980df6bfacc1272dff904","513","20.1","13","66566","33680","6873","5","1263","77","1611","14.3","2723","44","2.5","5","144","1677","14099","11","860","1693","53","260","123","64","12861","1.3","195","481","1"
"apache-carbondata","bdc1321d9c3f42c6bd56f6bf787cfba5bf3fb6b9","2016-07-28 07:09:01","[CARBONDATA-116]ignore the major compacted segment for minor compaction (#880)

Once a segment is formed using major compaction the same segment can not be considered for minor compaction. this PR will skip the same for an effective compaction.

* for correcting test case.

* for test case  correction.

* correcting test cases.

* correcting test cases.

* correcting test cases.

* fixing review comments.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","bdc1321d9c3f42c6bd56f6bf787cfba5bf3fb6b9","27","6","0","3292","323","22","3506","46","5436","974","360","4","16","4486","0","13","38","230","apache-carbondata","bdc1321d9c3f42c6bd56f6bf787cfba5bf3fb6b9","513","20.1","13","66534","33662","6868","5","1262","77","1610","14.3","2721","44","2.5","5","144","1676","14089","11","860","1693","53","260","123","64","12860","1.3","195","481","1"
"apache-carbondata","6dfaefed8d0de5245d7fef72573a555134ae4d00","2016-07-28 03:17:53","[CARBONDATA-115] The log level has been changed to debug since its been repeatedly getting logged for each block, so if any detail level analysis is required (#863)

the developer can verify the debug level log to know how much time is taken to generate start and end key.
Also as part of log start and end key for the block will be logged.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","6dfaefed8d0de5245d7fef72573a555134ae4d00","27","6","0","3291","323","22","3498","46","5435","974","360","4","16","4486","0","13","38","230","apache-carbondata","6dfaefed8d0de5245d7fef72573a555134ae4d00","513","20.1","12","66509","33654","6867","5","1261","77","1608","14.3","2720","44","2.5","5","143","1673","14087","11","860","1693","53","240","123","64","12848","1.3","194","481","1"
"apache-carbondata","e367e12b1c2523f12887af03d2a87547d4e897ae","2016-07-27 08:00:49","Problem: Null values getting display in not equals filter for timestamp datatype column (#878)

Analysis: While setting surrogates for exclude filter in custom dictionary visitor, surrogate for null value is not getting added to surrogate list due to which the query displays null value in case of dictionary column filters.

Impact: Not equals, equals, not null and is null query on timestamp datatype column

Fix: Add surrogate value for null member in exclude filter list","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","e367e12b1c2523f12887af03d2a87547d4e897ae","27","6","0","3291","323","22","3498","46","5435","974","360","4","16","4482","0","13","38","230","apache-carbondata","e367e12b1c2523f12887af03d2a87547d4e897ae","513","20.1","12","66505","33650","6867","5","1261","77","1608","14.3","2720","44","2.5","5","143","1672","14087","10","850","1693","52","240","123","64","12848","1.3","194","481","1"
"apache-carbondata","82b74070b090e627c333f1a574111c33e281725e","2016-07-25 10:54:00","[CARBONDATA-99][Bug] For complex type filter queries issue, like and not like are failing (#870)

For complex type filter queries if query contains filter expression rather than BinaryExpression the system was not able to get the dimensions which are involved","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","82b74070b090e627c333f1a574111c33e281725e","27","6","0","3290","323","22","3498","46","5435","974","360","4","16","4477","0","13","38","230","apache-carbondata","82b74070b090e627c333f1a574111c33e281725e","513","20.1","12","66495","33642","6864","5","1261","77","1608","14.3","2720","44","2.5","5","143","1672","14084","10","850","1693","52","240","123","64","12848","1.3","194","481","1"
"apache-carbondata","4b6314cc337e5af8ecffc68ee1ffd3c32f9b754e","2016-07-25 03:15:57","[CARBONDATA-95] Columns values with numeric data types are not getting parsed when included in dictionary_include (#853)

Problem: Columns values with numeric data types are not getting parsed when included in dictionary_include

Analysis: When a numeric datatype lets say Decimal is defined for a column and the column is included as dictionary_include, then the whatever precision and scale is defined by the user is not taken into consideration and each value is accepted and dictionary is generated for that value.

Solution: Parse big decimal while generating global dictionary and dictionary look up and set the precision and scale specified by the user","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","4b6314cc337e5af8ecffc68ee1ffd3c32f9b754e","27","6","0","3290","323","22","3498","46","5436","975","360","4","16","4477","0","13","38","230","apache-carbondata","4b6314cc337e5af8ecffc68ee1ffd3c32f9b754e","513","20.1","12","66500","33647","6864","5","1261","77","1608","14.3","2720","44","2.5","5","143","1672","14087","10","850","1693","52","240","123","64","12848","1.3","194","481","1"
"apache-carbondata","f57a95c65ddf70e2e5ccda45c16f5aab300facf0","2016-07-25 01:13:56","no key columns (#856)

when create table without key columns, it should  throw exception","refs/heads/master","liujunjie9@huawei.com","apache-carbondata","f57a95c65ddf70e2e5ccda45c16f5aab300facf0","27","6","0","3288","323","22","3498","45","5431","976","360","4","16","4476","0","13","38","230","apache-carbondata","f57a95c65ddf70e2e5ccda45c16f5aab300facf0","513","20.1","12","66485","33642","6862","5","1262","77","1607","14.3","2718","44","2.5","5","142","1671","14083","10","850","1693","52","240","123","64","12850","1.3","193","481","1"
"apache-carbondata","1b16f765c37202284e2b404c5bc45a06c15c23a7","2016-07-24 20:21:15","[Bug] reset statistics information after dataloading #842

[Bug] reset statistics information after dataloading #842","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","1b16f765c37202284e2b404c5bc45a06c15c23a7","27","6","0","3288","323","22","3496","45","5431","976","360","4","16","4476","0","13","38","230","apache-carbondata","1b16f765c37202284e2b404c5bc45a06c15c23a7","513","20.1","12","66480","33641","6862","5","1262","77","1607","14.3","2718","44","2.5","5","142","1671","14083","10","850","1693","52","240","123","64","12850","1.3","193","481","1"
"apache-carbondata","7159dce7b17646c67c9eed36f4d22d2577940055","2016-07-24 09:14:46","[CARBONDATA-99] For complex type filter queries if query contains filter expression rather than BinaryExpression the system was not able to get the dimensions which are involved (#854)

in the particular filter expression for executing complex type filter column expressions.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","7159dce7b17646c67c9eed36f4d22d2577940055","27","6","0","3296","323","22","3512","45","5440","980","360","4","16","4476","0","13","38","230","apache-carbondata","7159dce7b17646c67c9eed36f4d22d2577940055","513","20.1","12","66507","33654","6869","5","1264","77","1611","14.3","2725","44","2.5","5","142","1675","14078","10","850","1693","52","240","123","64","12870","1.3","195","481","1"
"apache-carbondata","c3197a8645b5b2d06b298b07888693cfa1c2e793","2016-07-23 00:25:12","[CARBONDATA-96] Make zookeeper lock as default if zookeeper url is configured. make zookeeper as default if zookeeper url is configured. (#712)

Make the lock type as zookeeper if zookeeper URL is present in the spark conf.
if spark.deploy.zookeeper.url property is set in spark-default.conf then need to take the zookeeper locking.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","c3197a8645b5b2d06b298b07888693cfa1c2e793","27","6","0","3295","323","22","3514","45","5436","978","360","4","16","4475","0","13","37","230","apache-carbondata","c3197a8645b5b2d06b298b07888693cfa1c2e793","513","20.1","12","66485","33640","6865","5","1264","77","1612","14.3","2725","44","2.5","5","142","1675","14071","9","840","1693","51","240","123","65","12870","1.3","195","481","1"
"apache-carbondata","a81ed981230e3fddd8e1c29d774266c171a54643","2016-07-22 23:51:02","[CARBONDATA-68] Added query statistic for detail query case measuring carbon executor time (#852)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","a81ed981230e3fddd8e1c29d774266c171a54643","27","6","0","3295","323","22","3514","45","5436","978","360","4","16","4475","0","13","37","230","apache-carbondata","a81ed981230e3fddd8e1c29d774266c171a54643","513","20.1","12","66486","33640","6865","5","1264","77","1612","14.3","2725","44","2.5","5","142","1675","14071","9","840","1693","51","240","123","65","12870","1.3","195","481","1"
"apache-carbondata","584402e8008d64b57233dc5be2a13a2739e32c61","2016-07-22 22:36:21","[CARBONDATA-84] Change lock framework to accept locklocation (#844)

1.get dictionary lock location from CarbonTablePath
2.Change lock framework to accept lock location","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","584402e8008d64b57233dc5be2a13a2739e32c61","27","6","0","3295","323","22","3512","45","5433","978","360","4","16","4473","0","13","37","230","apache-carbondata","584402e8008d64b57233dc5be2a13a2739e32c61","513","20.1","12","66459","33624","6864","5","1263","77","1611","14.3","2724","44","2.5","5","142","1674","14060","9","840","1693","51","240","123","65","12855","1.3","195","481","1"
"apache-carbondata","07116d242db652ad8edf6e80526f6a377295343d","2016-07-22 08:43:31","Struct of array is failing because of complex dimension ordinal (#848)

Problem:
Assignment of complex dimension ordinal was not correct as it was not increment and two children was getting same complex dimension ordinal
Second issue was selecting all the block indexes of complex dimension children.","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","07116d242db652ad8edf6e80526f6a377295343d","27","6","0","3294","323","22","3508","45","5424","981","360","4","16","4473","0","13","37","230","apache-carbondata","07116d242db652ad8edf6e80526f6a377295343d","513","20.1","12","66405","33600","6852","5","1263","77","1611","14.2","2719","44","2.5","5","142","1674","14048","9","840","1693","51","240","123","65","12855","1.3","195","481","1"
"apache-carbondata","154a4d388b96f5a338d17290f67a09345aebbc7a","2016-07-22 05:09:10","[Bug] Fix ColumnIdentifier toString to let log information understandable. (#847)

[Bug] Fix ColumnIdentifier toString to let log information understandable. (#847)
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","154a4d388b96f5a338d17290f67a09345aebbc7a","27","8","0","3291","323","22","3510","45","5423","982","360","4","16","4464","0","13","37","230","apache-carbondata","154a4d388b96f5a338d17290f67a09345aebbc7a","513","20.1","12","66383","33592","6848","5","1265","79","1613","14.2","2718","46","2.6","5","142","1676","14044","9","840","1739","51","240","123","65","12895","1.3","195","481","1"
"apache-carbondata","34741b48681b1a50bb46d84615dd77c17a6c44f7","2016-07-22 02:42:17","[CARBONDATA-17] - select count(*) from table where column_x = 'value' is not returning the correct count (#771)

if the first measure is having all values null.","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","34741b48681b1a50bb46d84615dd77c17a6c44f7","27","8","0","3290","323","22","3510","45","5423","982","360","4","16","4464","0","13","37","230","apache-carbondata","34741b48681b1a50bb46d84615dd77c17a6c44f7","513","20.1","12","66379","33589","6847","5","1265","79","1613","14.2","2717","46","2.6","5","142","1676","14043","9","840","1739","51","240","123","65","12895","1.3","195","481","1"
"apache-carbondata","a5714acedb453fcf148222854177f383aa88eaab","2016-07-21 07:30:46","[CARBONDATA-91] Concurrent query returning empty result (#849)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","a5714acedb453fcf148222854177f383aa88eaab","27","8","0","3284","323","22","3510","45","5418","982","360","4","15","4464","0","13","37","228","apache-carbondata","a5714acedb453fcf148222854177f383aa88eaab","512","20.1","12","66343","33586","6838","5","1265","79","1612","14.2","2710","46","2.6","5","142","1675","14034","9","840","1739","51","240","123","65","12888","1.3","194","480","1"
"apache-carbondata","54fb3d287c90d8f4369e5ff7eae557e30c49b676","2016-07-19 23:31:31","Moved complex types from query to scan package
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","54fb3d287c90d8f4369e5ff7eae557e30c49b676","23","8","0","2488","291","17","2922","30","4321","754","311","4","11","3525","0","15","31","190","apache-carbondata","54fb3d287c90d8f4369e5ff7eae557e30c49b676","383","20.6","7","51862","26366","5410","5","1019","59","1295","15","2051","30","2.6","5","96","1332","11081","7","445","1374","30","140","93","53","10505","1.3","157","360","1"
"apache-carbondata","eaecb65129fc50c821f8b3cc43a1cab2046c8e3a","2016-07-19 08:59:08","Merge remote-tracking branch 'carbon_master/master' into apache/master

Conflicts:
	README.md
	core/src/main/java/org/carbondata/core/carbon/path/CarbonTablePath.java
	core/src/main/java/org/carbondata/core/constants/CarbonCommonConstants.java
	core/src/main/java/org/carbondata/core/datastorage/store/columnar/BlockIndexerStorageForNoInvertedIndex.java
	core/src/main/java/org/carbondata/core/util/DataTypeUtil.java
	core/src/main/java/org/carbondata/query/aggregator/impl/AvgLongAggregator.java
	core/src/main/java/org/carbondata/query/aggregator/util/MeasureAggregatorFactory.java
	core/src/main/java/org/carbondata/query/carbon/aggregator/dimension/impl/ColumnGroupDimensionsAggregator.java
	core/src/main/java/org/carbondata/query/carbon/aggregator/dimension/impl/FixedLengthDimensionAggregator.java
	core/src/main/java/org/carbondata/query/carbon/aggregator/dimension/impl/VariableLengthDimensionAggregator.java
	core/src/main/java/org/carbondata/query/carbon/aggregator/expression/ExpressionAggregator.java
	core/src/main/java/org/carbondata/query/carbon/aggregator/impl/ListBasedResultAggregator.java
	core/src/main/java/org/carbondata/query/carbon/aggregator/impl/MapBasedResultAggregator.java
	core/src/main/java/org/carbondata/query/carbon/executor/QueryExecutorFactory.java
	core/src/main/java/org/carbondata/query/carbon/executor/impl/AggregationQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/impl/CountStarQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/impl/DetailRawRecordQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/impl/DetailWithOrderByQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/impl/FunctionQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/internal/impl/InternalAbstractQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/internal/impl/InternalCountStartQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/executor/internal/impl/InternalDetailQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/merger/impl/SortedScannedResultMerger.java
	core/src/main/java/org/carbondata/query/carbon/result/BatchRawResult.java
	core/src/main/java/org/carbondata/query/carbon/result/ListBasedResultWrapper.java
	core/src/main/java/org/carbondata/query/carbon/result/impl/MapBasedResult.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/AbstractDetailQueryResultIterator.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/ChunkBasedResultIterator.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/DetailQueryResultIterator.java
	core/src/main/java/org/carbondata/query/carbon/result/iterator/DetailRawQueryResultIterator.java
	core/src/main/java/org/carbondata/query/carbon/result/preparator/QueryResultPreparator.java
	core/src/main/java/org/carbondata/query/carbon/result/preparator/impl/AbstractQueryResultPreparator.java
	core/src/main/java/org/carbondata/query/carbon/result/preparator/impl/QueryResultPreparatorImpl.java
	core/src/main/java/org/carbondata/query/carbon/result/preparator/impl/RawQueryResultPreparatorImpl.java
	core/src/main/java/org/carbondata/query/expression/DataType.java
	core/src/main/java/org/carbondata/scan/executor/impl/AbstractQueryExecutor.java
	core/src/main/java/org/carbondata/scan/executor/impl/DetailQueryExecutor.java
	core/src/main/java/org/carbondata/scan/executor/impl/QueryExecutorProperties.java
	core/src/main/java/org/carbondata/scan/executor/infos/AggregatorInfo.java
	core/src/main/java/org/carbondata/scan/executor/infos/BlockExecutionInfo.java
	core/src/main/java/org/carbondata/scan/executor/util/QueryUtil.java
	core/src/main/java/org/carbondata/scan/expression/ExpressionResult.java
	core/src/main/java/org/carbondata/scan/expression/conditional/EqualToExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/InExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/NotEqualsExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/NotInExpression.java
	core/src/main/java/org/carbondata/scan/filter/FilterUtil.java
	core/src/main/java/org/carbondata/scan/filter/GenericQueryType.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelFilterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/DimColumnResolvedFilterInfo.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/visitor/CustomTypeDictionaryVisitor.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/visitor/NoDictionaryTypeVisitor.java
	core/src/main/java/org/carbondata/scan/model/QueryModel.java
	core/src/main/java/org/carbondata/scan/result/AbstractScannedResult.java
	core/src/main/java/org/carbondata/scan/result/BatchResult.java
	core/src/main/java/org/carbondata/scan/result/Result.java
	core/src/main/java/org/carbondata/scan/result/impl/ListBasedResult.java
	core/src/main/java/org/carbondata/scan/result/iterator/ChunkRowIterator.java
	hadoop/src/main/java/org/carbondata/hadoop/CarbonRecordReader.java
	integration/spark/src/main/java/org/carbondata/spark/load/CarbonLoaderUtil.java
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonContext.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonDatasourceRelation.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonDictionaryDecoder.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonOperators.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonRawAggregate.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonRawOperators.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonSQLConf.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonSqlParser.scala
	integration/spark/src/main/scala/org/apache/spark/sql/execution/command/carbonTableSchema.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonMetastoreCatalog.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonRawStrategies.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonStrategies.scala
	integration/spark/src/main/scala/org/apache/spark/sql/optimizer/CarbonOptimizer.scala
	integration/spark/src/main/scala/org/carbondata/spark/KeyVal.scala
	integration/spark/src/main/scala/org/carbondata/spark/agg/CarbonAggregates.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonCleanFilesRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDataRDDFactory.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDeleteLoadRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDropAggregateTableRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDropTableRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonGlobalDictionaryRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonRawQueryRDD.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonScanRDD.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/dataload/TestLoadDataWithHiveSyntax.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/dataload/TestNoInvertedIndexLoadAndQuery.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/detailquery/AllDataTypesTestCase.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/detailquery/HighCardinalityDataTypesTestCase.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/filterexpr/AllDataTypesTestCaseFilter.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/joinquery/AllDataTypesTestCaseJoin.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/sortexpr/AllDataTypesTestCaseSort.scala
	integration/spark/src/test/scala/org/carbondata/spark/util/AutoHighCardinalityIdentifyTestCase.scala
	integration/spark/src/test/scala/org/carbondata/spark/util/GlobalDictionaryUtilTestCase.scala
	processing/src/main/java/org/carbondata/lcm/locks/LocalFileLock.java
	processing/src/main/java/org/carbondata/lcm/locks/ZooKeeperLocking.java
	processing/src/main/java/org/carbondata/lcm/status/SegmentStatusManager.java
	processing/src/main/java/org/carbondata/processing/csvreaderstep/CsvInput.java
	processing/src/main/java/org/carbondata/processing/store/CarbonFactDataHandlerColumnar.java
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","eaecb65129fc50c821f8b3cc43a1cab2046c8e3a","23","8","0","2488","285","17","2918","30","4320","755","311","4","11","3502","0","18","31","190","apache-carbondata","eaecb65129fc50c821f8b3cc43a1cab2046c8e3a","383","20.6","7","51823","26333","5390","5","1018","59","1298","15","2050","30","2.7","5","97","1335","11060","7","445","1374","30","140","93","53","10486","1.3","160","360","1"
"apache-carbondata","84b476bc41b77d9736da916949e105dda28df31c","2016-07-17 07:57:58","change cube to table

change Cube to Table

fix style

change schemaName to databaseName

change SchemaName to DatabaseName
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","84b476bc41b77d9736da916949e105dda28df31c","22","2","0","2273","271","14","2674","26","4007","663","308","4","8","3220","0","15","31","188","apache-carbondata","84b476bc41b77d9736da916949e105dda28df31c","371","21.2","7","49464","24757","5047","5","943","52","1186","14.5","1889","25","2.5","5","94","1224","10449","7","450","1236","31","140","91","52","9790","1.3","128","348","1"
"apache-carbondata","b81235d76ccda373f9b957f31340f77c9bc7a6ef","2016-07-18 12:55:56","[CARBONDATA-76][Bug] Null members should not display in NotEquals and other logical Filters

","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","b81235d76ccda373f9b957f31340f77c9bc7a6ef","27","8","0","3284","323","22","3510","45","5418","982","360","4","15","4464","0","13","37","228","apache-carbondata","b81235d76ccda373f9b957f31340f77c9bc7a6ef","512","20.1","12","66343","33586","6838","5","1265","79","1612","14.2","2710","46","2.6","5","142","1675","14034","9","840","1739","51","240","123","65","12888","1.3","194","480","1"
"apache-carbondata","5d8f9d097edfab36e41508501f4a3ddbafebd1d7","2016-07-18 12:43:51","[CARBONDATA-75] Dictionary file not getting cleanup on global dictionary generation failure

1.Corrected sorted index cleanup. (#838)
2.dictionary clean up on failure.","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","5d8f9d097edfab36e41508501f4a3ddbafebd1d7","27","8","0","3279","323","22","3510","45","5407","982","360","4","15","4456","0","13","37","228","apache-carbondata","5d8f9d097edfab36e41508501f4a3ddbafebd1d7","512","20.1","12","66309","33555","6830","5","1265","79","1612","14.2","2708","46","2.6","5","142","1675","14020","9","840","1739","51","240","123","65","12887","1.3","194","480","1"
"apache-carbondata","31d824ddbd6146a06e7095766bcb315cb803be99","2016-07-18 05:48:19","[CARBONDATA-62] Invalid type for column values to be discarded while generating global dictionary (#830)

If value read from raw data is not valid for its datatype then discard that value at the time of data loading and insert null at its place while storing data in carbon format","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","31d824ddbd6146a06e7095766bcb315cb803be99","27","8","0","3279","323","22","3510","45","5405","982","360","4","15","4454","0","13","37","228","apache-carbondata","31d824ddbd6146a06e7095766bcb315cb803be99","512","20.1","12","66305","33551","6828","5","1265","79","1612","14.2","2708","46","2.6","5","142","1675","14017","9","840","1739","51","240","123","65","12887","1.3","194","480","1"
"apache-carbondata","13a0df349f862bcb5b418576bb33d002e8a39d67","2016-07-18 05:02:46","[CARBONDATA-68] Log Executor Query statistics (#825)

Logs are added under ""statistic"" category to track the time taken and Performance logs for Query.
How ever detailed statistics module has to be added as per #356 , for complete solution.","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","13a0df349f862bcb5b418576bb33d002e8a39d67","27","8","0","3278","323","22","3508","44","5403","981","360","4","15","4454","0","13","37","228","apache-carbondata","13a0df349f862bcb5b418576bb33d002e8a39d67","512","20.1","12","66263","33523","6817","5","1263","79","1609","14.2","2707","46","2.6","5","141","1672","14001","9","840","1739","51","240","123","65","12851","1.3","194","480","1"
"apache-carbondata","91aa35430deb2af51da801e868b5842af093b9ce","2016-07-18 04:47:08","[CARBONDATA-66][Bug] Filter was failing when join condition on timestamp, bigint, bigdecimal columns(#824)

1) Timestamp type InExpression type mismatch for Timestamp type column filters,
2) For other filter like BigInt and Decimal, expression result was not handling such data type while comparing the expression results.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","91aa35430deb2af51da801e868b5842af093b9ce","27","8","0","3268","323","22","3494","44","5389","977","360","4","15","4441","0","13","37","228","apache-carbondata","91aa35430deb2af51da801e868b5842af093b9ce","510","20.1","12","66078","33435","6808","5","1260","79","1606","14.2","2701","46","2.6","5","141","1669","13965","9","840","1745","51","240","122","65","12825","1.3","194","478","1"
"apache-carbondata","8034da1898eea811a1c25cdcab42ff63b8747273","2016-07-18 04:25:11","[Bug] During array of array complex column query execution, fixed complex query execution . (#832)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","8034da1898eea811a1c25cdcab42ff63b8747273","26","8","0","3267","323","22","3484","44","5377","976","360","4","15","4449","0","13","37","228","apache-carbondata","8034da1898eea811a1c25cdcab42ff63b8747273","510","20.1","12","66007","33372","6781","5","1261","79","1607","14.2","2696","46","2.6","5","141","1670","13935","9","840","1745","51","240","122","65","12832","1.3","194","478","1"
"apache-carbondata","8b3c13506e3344f01b2893704baf411ec76501f9","2016-07-18 04:21:30","[Bug] While defining Column groups, if group is not defined in schema order than data loading is failing (#829)

This fix is to arrange the group in schema order","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","8b3c13506e3344f01b2893704baf411ec76501f9","26","8","0","3267","323","22","3480","44","5375","976","360","4","15","4454","0","13","37","228","apache-carbondata","8b3c13506e3344f01b2893704baf411ec76501f9","510","20.1","12","66007","33372","6780","5","1261","79","1607","14.2","2696","46","2.6","5","141","1670","13933","9","840","1745","51","240","122","65","12832","1.3","194","478","1"
"apache-carbondata","efc395165b0ab33bdd96eac0d62e60e19e8f4c53","2016-07-14 23:43:14","handle decimal query (#789)

LGTM","refs/heads/master","liujunjie9@huawei.com","apache-carbondata","efc395165b0ab33bdd96eac0d62e60e19e8f4c53","26","8","0","3162","317","19","3336","41","5250","930","355","5","15","4349","0","13","37","230","apache-carbondata","efc395165b0ab33bdd96eac0d62e60e19e8f4c53","505","20.3","7","65006","32712","6623","5","1228","77","1541","14","2603","45","2.7","5","134","1599","13728","9","840","1728","51","140","122","65","12498","1.3","163","473","1"
"apache-carbondata","b466c10f31876ac4160904a6d1078709dd2a2611","2016-07-17 21:13:10","[Bug] Concurrency for dictionary generation (#806)

Supported single commit point for dictionary, sort index and dictionary metadata files.
New sort index file is created every time and cleared on query max time, to allow parallel read and write.","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","b466c10f31876ac4160904a6d1078709dd2a2611","26","8","0","3267","323","22","3480","44","5371","976","360","4","15","4451","0","13","37","228","apache-carbondata","b466c10f31876ac4160904a6d1078709dd2a2611","510","20.1","12","65999","33364","6780","5","1261","79","1607","14.2","2696","46","2.6","5","141","1670","13929","9","840","1745","51","240","122","65","12832","1.3","194","478","1"
"apache-carbondata","9821beeabe0aa52d31d6fc693f3c1a972be69253","2016-07-17 08:42:20","Handling for percentile aggregate function (#822)

While data loading changed the data type to Long instead of Double","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","9821beeabe0aa52d31d6fc693f3c1a972be69253","26","8","0","3260","323","22","3456","42","5354","981","360","4","15","4423","0","13","37","226","apache-carbondata","9821beeabe0aa52d31d6fc693f3c1a972be69253","510","20.1","7","65876","33270","6759","5","1254","79","1594","14.1","2690","46","2.6","5","135","1652","13901","9","840","1745","51","140","122","65","12732","1.3","189","478","1"
"apache-carbondata","f4c3d10e6be703ffd5fea9d77b376c18aaaceabe","2016-07-16 21:56:05","[Bug] Direct Dictionary Complex primitive timestamp type support in data loading and query (#823)

* Complex type support for timestamp primitives in data loading

* Query Flow Updated to support complex primitive timestamp types

* Fixed Style Issues and added testcode
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","f4c3d10e6be703ffd5fea9d77b376c18aaaceabe","26","8","0","3260","322","22","3456","42","5353","981","360","4","15","4422","0","13","37","226","apache-carbondata","f4c3d10e6be703ffd5fea9d77b376c18aaaceabe","510","20.1","7","65860","33254","6743","5","1253","79","1593","14.1","2690","46","2.6","5","135","1651","13900","9","840","1745","51","140","122","65","12710","1.3","189","478","1"
"apache-carbondata","6d2456f14479a324f9d5124acd20b739f1f0bb23","2016-07-15 10:37:20","fix query avg of bigint field (#807)

","refs/heads/master","zhujin2@huawei.com","apache-carbondata","6d2456f14479a324f9d5124acd20b739f1f0bb23","26","8","0","3259","322","22","3448","42","5349","980","360","5","15","4413","0","13","37","230","apache-carbondata","6d2456f14479a324f9d5124acd20b739f1f0bb23","510","20.1","7","65851","33244","6745","5","1253","79","1594","14.1","2691","46","2.6","5","135","1652","13896","9","840","1745","51","140","122","65","12697","1.3","190","478","1"
"apache-carbondata","eecbdfde7734421c461a2d1f1780fc879e23f13e","2016-07-15 10:01:16","Drop Table dbname.tablename is not working, carbondata file path if '-' exist, gives wrong value. (#797)

","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","eecbdfde7734421c461a2d1f1780fc879e23f13e","26","8","0","3260","322","22","3448","42","5349","980","360","5","15","4413","0","13","37","230","apache-carbondata","eecbdfde7734421c461a2d1f1780fc879e23f13e","510","20.1","7","65845","33244","6745","5","1252","77","1593","14.1","2691","45","2.6","5","135","1651","13896","9","840","1728","51","140","122","65","12667","1.3","190","478","1"
"apache-carbondata","6a092bbea5550665050e70c97b9790c5de48664d","2016-07-15 09:58:59","fix comments and rebase 716 (#798)

","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","6a092bbea5550665050e70c97b9790c5de48664d","26","8","0","3260","322","22","3446","42","5344","980","360","5","15","4401","0","13","37","230","apache-carbondata","6a092bbea5550665050e70c97b9790c5de48664d","510","20.1","7","65827","33233","6741","5","1251","77","1592","14.1","2690","45","2.6","5","135","1650","13889","9","840","1728","51","140","122","65","12662","1.3","190","478","1"
"apache-carbondata","9ddd56692eefacc000d789df3b4ad39cb53525fa","2016-07-15 04:59:12","Problem: when a column with datatype other than string is added to dictionary include property, then filters queries on that column cannot get the correct result (#819)

Analysis: In Sort index file always the numeric values comes first and then the string values. When we perform binary search then when a string value is encountered then parsing operation to correspond datatype throws an exception and -1 value is returned because of which we move further towards last index but actually we should move towards lower index as all numeric values are above the string values.

Fix: return 1 in case of parsing operation failure because of which we will move towards lower index in binary search operation.","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","9ddd56692eefacc000d789df3b4ad39cb53525fa","26","8","0","3176","318","19","3336","41","5263","931","360","5","15","4345","0","13","37","230","apache-carbondata","9ddd56692eefacc000d789df3b4ad39cb53525fa","506","20.3","7","65156","32797","6639","5","1226","77","1539","14","2612","45","2.7","5","134","1597","13755","9","840","1728","51","140","122","65","12410","1.3","163","474","1"
"apache-carbondata","f3589b4ed2d469dca8dcd3213c4f63def784c6a0","2016-07-15 02:16:15","fix for count on column group (#815)

","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","f3589b4ed2d469dca8dcd3213c4f63def784c6a0","26","8","0","3176","318","19","3336","41","5263","931","360","5","15","4345","0","13","37","230","apache-carbondata","f3589b4ed2d469dca8dcd3213c4f63def784c6a0","506","20.3","7","65156","32797","6639","5","1226","77","1539","14","2612","45","2.7","5","134","1597","13755","9","840","1728","51","140","122","65","12410","1.3","163","474","1"
"apache-carbondata","e18c3058ccf3db21f37b521c30df1f1fe823c0c0","2016-07-14 23:58:38","[Bug] For fixing arithmetic expression filter issues in Filters. (#817)

","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","e18c3058ccf3db21f37b521c30df1f1fe823c0c0","26","8","0","3176","318","19","3336","41","5263","931","360","5","15","4344","0","13","37","230","apache-carbondata","e18c3058ccf3db21f37b521c30df1f1fe823c0c0","506","20.3","7","65156","32797","6638","5","1226","77","1539","14","2612","45","2.7","5","134","1597","13755","9","840","1728","51","140","122","65","12410","1.3","163","474","1"
"apache-carbondata","f6488caa094f01c60ec4767851123ba41ce6220e","2016-07-14 23:53:12","inverted index configuration on column level (#800)

inverted index configuration on column level (#800)","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","f6488caa094f01c60ec4767851123ba41ce6220e","26","8","0","3176","318","19","3336","41","5263","931","360","5","15","4344","0","13","37","230","apache-carbondata","f6488caa094f01c60ec4767851123ba41ce6220e","506","20.3","7","65155","32796","6637","5","1226","77","1539","14","2612","45","2.7","5","134","1597","13755","9","840","1728","51","140","122","65","12410","1.3","163","474","1"
"apache-carbondata","8aaa5d1735a1d98f4f51fccd117ea7d8278df0cd","2016-07-14 11:29:40","[Issue-95] Added code to support complex type Query (#492)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","8aaa5d1735a1d98f4f51fccd117ea7d8278df0cd","26","8","0","3162","317","19","3336","41","5250","930","355","5","15","4349","0","13","37","230","apache-carbondata","8aaa5d1735a1d98f4f51fccd117ea7d8278df0cd","505","20.3","7","65006","32712","6623","5","1228","77","1541","14","2603","45","2.7","5","135","1600","13728","9","845","1728","52","140","122","65","12498","1.3","163","473","1"
"apache-carbondata","343e48684f6d605f9c7a607e92f41a72e1789c8c","2016-07-14 03:33:41","Problem: In case of aggregation on dimension which has decimal datatype, the data from utility class is returned as spark sql decimal type. Because of this while aggregating this data data with java decimal type class cast exception is thrown. (#809)

Fix: Type cast to java decimal type while aggregating dimension data for decimal type","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","343e48684f6d605f9c7a607e92f41a72e1789c8c","26","2","0","3065","301","19","3252","41","5092","897","352","4","15","4157","0","13","37","226","apache-carbondata","343e48684f6d605f9c7a607e92f41a72e1789c8c","501","20.6","7","63933","31948","6475","5","1188","70","1498","13.8","2546","40","2.5","5","134","1557","13423","9","845","1588","52","140","122","64","12158","1.3","162","469","1"
"apache-carbondata","2fe46e576089a1b8b12c5cd4ad90ad1c07702c72","2016-07-14 00:02:53","[BUG]handle for No_dict (#803)

","refs/heads/master","liujunjie9@huawei.com","apache-carbondata","2fe46e576089a1b8b12c5cd4ad90ad1c07702c72","26","2","0","3065","293","19","3252","41","5092","897","352","4","15","4150","0","13","37","226","apache-carbondata","2fe46e576089a1b8b12c5cd4ad90ad1c07702c72","501","20.6","7","63917","31935","6472","5","1188","70","1498","13.8","2546","40","2.5","5","134","1557","13417","9","845","1588","52","140","122","64","12156","1.3","162","469","1"
"apache-carbondata","27e879a0fa4630ab7371653ace626a63ca77cc4f","2016-07-11 01:14:49","index file closing issue (#795)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","27e879a0fa4630ab7371653ace626a63ca77cc4f","26","2","0","3065","293","19","3252","41","5092","897","352","4","15","4150","0","13","37","226","apache-carbondata","27e879a0fa4630ab7371653ace626a63ca77cc4f","501","20.6","7","63917","31935","6472","5","1188","70","1498","13.8","2546","40","2.5","5","134","1557","13417","9","845","1588","52","140","122","64","12156","1.3","162","469","1"
"apache-carbondata","742c5a4a3a6214be74599ded7bdc1f0ad2d9fd62","2016-07-08 20:34:36","[Bug] fixed length key updation issue when there is no change in the key size in case of multiple and single load (#794)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","742c5a4a3a6214be74599ded7bdc1f0ad2d9fd62","26","2","0","3065","293","19","3252","41","5092","897","352","4","15","4150","0","13","37","226","apache-carbondata","742c5a4a3a6214be74599ded7bdc1f0ad2d9fd62","501","20.6","7","63913","31931","6472","5","1190","70","1500","13.8","2546","40","2.5","5","134","1559","13415","9","845","1588","52","140","122","64","12186","1.3","162","469","1"
"apache-carbondata","16d51f5147586a5777f66f98e8f47f6f3daaf10f","2016-07-05 02:33:32","Moved unnecessary metastore db to target folder

Make the derby db metastore configurable.

Fixed review comments

Fixed test case compile error

Fixed test cases

Fixed integration test case

Fixed style
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","16d51f5147586a5777f66f98e8f47f6f3daaf10f","22","2","0","2273","271","14","2674","26","4007","663","308","4","8","3220","0","15","31","188","apache-carbondata","16d51f5147586a5777f66f98e8f47f6f3daaf10f","371","21.2","7","49468","24757","5047","5","943","52","1186","14.5","1889","25","2.5","5","94","1224","10449","7","450","1236","31","140","91","52","9790","1.3","128","348","1"
"apache-carbondata","0d81b168e7189a8c142590332cadc9a668f4a14e","2016-07-06 06:28:52","Main process is not exiting even after program completes
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","0d81b168e7189a8c142590332cadc9a668f4a14e","22","2","0","2273","271","14","2670","26","4007","663","308","4","8","3220","0","15","31","188","apache-carbondata","0d81b168e7189a8c142590332cadc9a668f4a14e","371","21.2","7","49458","24755","5047","5","943","52","1186","14.5","1889","25","2.5","5","94","1224","10449","7","450","1236","31","140","91","52","9790","1.3","128","348","1"
"apache-carbondata","74fa84e093730b47cfd7b1aac26dba5a1c9fe0c5","2016-07-07 07:29:37","Optimized detail query flow and push up computation flow. (#573)

* Optimizing detail query (taking out unnessary aggreator object creation)
* Optimized raw detail query to improve push up performance.
* Clean up to remove (K,V) where ever not required, as only (V) is required.","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","74fa84e093730b47cfd7b1aac26dba5a1c9fe0c5","26","2","0","3066","293","19","3252","41","5092","898","352","4","15","4150","0","13","37","226","apache-carbondata","74fa84e093730b47cfd7b1aac26dba5a1c9fe0c5","501","20.6","7","63908","31929","6470","5","1190","70","1500","13.8","2546","40","2.5","5","134","1559","13415","9","845","1588","52","140","122","64","12186","1.3","162","469","1"
"apache-carbondata","ad4622eac886693a318b09fc0ebf30d77a46061e","2016-07-07 03:40:33","[Issue-578] Improving the compaction performance. (#780)

","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","ad4622eac886693a318b09fc0ebf30d77a46061e","26","2","0","3048","291","19","3230","40","5070","893","352","4","15","4141","0","13","37","226","apache-carbondata","ad4622eac886693a318b09fc0ebf30d77a46061e","499","20.7","7","63739","31802","6453","5","1202","70","1513","13.8","2539","40","2.6","5","134","1572","13374","9","845","1628","52","140","122","65","12245","1.3","162","468","1"
"apache-carbondata","b77695f136a98bc00ee15ea9138199fa01fca5e0","2016-07-03 10:45:52","Fixed drop table with dbname

Fixed hdfs folder path issue which contains '-'

Reverted commented testcase code
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b77695f136a98bc00ee15ea9138199fa01fca5e0","22","2","0","2273","271","14","2670","26","4007","663","308","4","8","3220","0","15","31","188","apache-carbondata","b77695f136a98bc00ee15ea9138199fa01fca5e0","371","21.2","7","49454","24751","5047","5","943","52","1186","14.5","1889","25","2.5","5","94","1224","10446","7","450","1236","31","140","91","52","9790","1.3","128","348","1"
"apache-carbondata","4c67a7f402a6cf18283a7503833d12b8a115a2b2","2016-07-05 04:58:05","[CARBONDATA-29] Make inverted index can be configurable
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","4c67a7f402a6cf18283a7503833d12b8a115a2b2","22","2","0","2273","271","14","2668","26","4005","663","308","4","8","3208","0","15","31","188","apache-carbondata","4c67a7f402a6cf18283a7503833d12b8a115a2b2","371","21.3","7","49442","24743","5043","5","943","52","1186","14.5","1888","25","2.5","5","94","1224","10442","7","450","1236","31","140","91","52","9790","1.3","128","348","1"
"apache-carbondata","b7c285b7267a32d3e32c9a3218ae4ab72dda1f0c","2016-07-04 10:47:57","[CARBONDATA-32] Refactor DataType related code
","refs/heads/master","chenliang613@apache.org","apache-carbondata","b7c285b7267a32d3e32c9a3218ae4ab72dda1f0c","22","2","0","2259","270","14","2668","26","3992","662","303","4","8","3213","0","15","31","188","apache-carbondata","b7c285b7267a32d3e32c9a3218ae4ab72dda1f0c","370","21.3","7","49293","24659","5029","5","945","52","1188","14.5","1879","25","2.5","5","94","1226","10415","7","450","1236","31","140","91","52","9878","1.3","128","347","1"
"apache-carbondata","440c9da97767fcc39c9bc9a78da36d12f8b48cdf","2016-07-01 22:33:40","Fixed folder path issue which contains '-'
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","440c9da97767fcc39c9bc9a78da36d12f8b48cdf","22","2","0","2265","272","14","2670","26","3992","661","303","4","8","3216","0","9","31","188","apache-carbondata","440c9da97767fcc39c9bc9a78da36d12f8b48cdf","373","21.3","7","49379","24693","5035","5","950","52","1208","14.4","1881","25","2.5","5","94","1246","10420","7","450","1236","31","140","92","52","9958","1.3","143","350","1"
"apache-carbondata","7f72218602926ca5f6629825df7b8f70ab1c6aa6","2016-06-30 05:11:47","Merge remote-tracking branch 'carbon_master/master' into apache/master

Conflicts:
	README.md
	core/src/main/java/org/carbondata/core/datastorage/util/StoreFactory.java
	core/src/main/java/org/carbondata/core/keygenerator/directdictionary/timestamp/TimeStampDirectDictionaryGenerator.java
	core/src/main/java/org/carbondata/core/util/CarbonUtil.java
	core/src/main/java/org/carbondata/core/util/DataFileFooterConverter.java
	core/src/main/java/org/carbondata/query/aggregator/impl/CustomAggregatorHelper.java
	core/src/main/java/org/carbondata/query/carbon/executor/internal/impl/InternalDetailQueryExecutor.java
	core/src/main/java/org/carbondata/query/carbon/processor/impl/AggregateQueryBlockProcessor.java
	core/src/main/java/org/carbondata/query/filter/executer/ColGroupFilterExecuterImpl.java
	core/src/main/java/org/carbondata/query/filter/executer/IncludeColGroupFilterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/executor/util/QueryUtil.java
	core/src/main/java/org/carbondata/scan/expression/Expression.java
	core/src/main/java/org/carbondata/scan/expression/ExpressionResult.java
	core/src/main/java/org/carbondata/scan/expression/arithmetic/AddExpression.java
	core/src/main/java/org/carbondata/scan/expression/arithmetic/DivideExpression.java
	core/src/main/java/org/carbondata/scan/expression/arithmetic/MultiplyExpression.java
	core/src/main/java/org/carbondata/scan/expression/arithmetic/SubstractExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/EqualToExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/GreaterThanEqualToExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/GreaterThanExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/InExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/LessThanEqualToExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/LessThanExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/ListExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/NotEqualsExpression.java
	core/src/main/java/org/carbondata/scan/expression/conditional/NotInExpression.java
	core/src/main/java/org/carbondata/scan/expression/exception/FilterUnsupportedException.java
	core/src/main/java/org/carbondata/scan/expression/logical/AndExpression.java
	core/src/main/java/org/carbondata/scan/expression/logical/NotExpression.java
	core/src/main/java/org/carbondata/scan/expression/logical/OrExpression.java
	core/src/main/java/org/carbondata/scan/filter/FilterUtil.java
	core/src/main/java/org/carbondata/scan/filter/executer/ColGroupFilterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelFilterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelRangeGrtThanFiterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelRangeGrtrThanEquaToFilterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelRangeLessThanEqualFilterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelRangeLessThanFiterExecuterImpl.java
	core/src/main/java/org/carbondata/scan/filter/executer/RowLevelRangeTypeExecuterFacory.java
	core/src/main/java/org/carbondata/scan/filter/resolver/AndFilterResolverImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/FilterResolverIntf.java
	core/src/main/java/org/carbondata/scan/filter/resolver/LogicalFilterResolverImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/RestructureFilterResolverImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/RowLevelRangeFilterResolverImpl.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/visitor/CustomTypeDictionaryVisitor.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/visitor/DictionaryColumnVisitor.java
	core/src/main/java/org/carbondata/scan/filter/resolver/resolverinfo/visitor/NoDictionaryTypeVisitor.java
	core/src/main/java/org/carbondata/scan/util/DataTypeUtil.java
	integration-testcases/src/test/scala/org/carbondata/spark/testsuite/allqueries/AllDataTypesTestCase1.scala
	integration-testcases/src/test/scala/org/carbondata/spark/testsuite/allqueries/AllDataTypesTestCase2.scala
	integration/spark/src/main/java/org/carbondata/spark/load/CarbonLoaderUtil.java
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonDatasourceRelation.scala
	integration/spark/src/main/scala/org/apache/spark/sql/CarbonSqlParser.scala
	integration/spark/src/main/scala/org/apache/spark/sql/execution/command/carbonTableSchema.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonMetastoreCatalog.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonSQLDialect.scala
	integration/spark/src/main/scala/org/apache/spark/sql/hive/CarbonStrategies.scala
	integration/spark/src/main/scala/org/carbondata/spark/agg/CarbonAggregates.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonScanRDD.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/allqueries/AllDataTypesTestCaseAggregate.scala
	processing/src/main/java/org/carbondata/processing/store/CarbonFactDataHandlerModel.java
	processing/src/main/java/org/carbondata/processing/store/colgroup/ColGroupDataHolder.java
	processing/src/main/java/org/carbondata/processing/store/colgroup/ColGroupMinMax.java
	processing/src/main/java/org/carbondata/processing/store/writer/AbstractFactDataWriter.java
	processing/src/test/java/org/carbondata/processing/store/colgroup/ColGroupMinMaxTest.java
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7f72218602926ca5f6629825df7b8f70ab1c6aa6","22","2","0","2265","272","14","2670","26","3989","661","303","4","8","3216","0","9","31","188","apache-carbondata","7f72218602926ca5f6629825df7b8f70ab1c6aa6","373","21.3","7","49373","24690","5035","5","950","52","1208","14.4","1881","25","2.5","5","94","1246","10417","7","450","1236","31","140","92","52","9958","1.3","143","350","1"
"apache-carbondata","167d52799a87b2d17cd3aa2fb846cfa0a8337e63","2016-06-29 16:27:03","[issue-777] Filter query issue for >, <, <= than filter for timestamp(#778)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","167d52799a87b2d17cd3aa2fb846cfa0a8337e63","26","2","0","3034","290","19","3210","40","5055","893","352","4","15","4121","0","13","37","226","apache-carbondata","167d52799a87b2d17cd3aa2fb846cfa0a8337e63","497","20.7","7","63571","31708","6436","5","1199","73","1509","13.8","2532","41","2.6","5","134","1568","13329","9","845","1645","52","140","122","65","12244","1.3","161","466","1"
"apache-carbondata","49bd621e2a92e3dea7e98ddf5edd0262169fb4b1","2016-05-18 04:21:16","Fixed non number data type dimension column aggregation issue (#436)","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","49bd621e2a92e3dea7e98ddf5edd0262169fb4b1","50","6","0","5246","519","271","6312","68","8465","1806","727","12","56","6015","0","4","91","354","apache-carbondata","49bd621e2a92e3dea7e98ddf5edd0262169fb4b1","735","18.6","48","100048","52420","10465","4","2481","127","3991","17","3989","68","3","5","304","4143","22720","27","1659","2996","104","785","166","105","28708","1.8","1226","616","1"
"apache-carbondata","697ba7b7e38ff0aa8966ef2bfbac15b5435e9835","2016-06-29 11:40:19","[BUG] Timestamp column filter is not working for unknown filter (#779)

","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","697ba7b7e38ff0aa8966ef2bfbac15b5435e9835","26","2","0","3030","272","19","3202","40","5032","896","352","4","15","4096","0","13","37","224","apache-carbondata","697ba7b7e38ff0aa8966ef2bfbac15b5435e9835","497","20.7","7","63453","31613","6412","5","1190","77","1499","13.8","2531","41","2.7","5","133","1558","13270","9","845","1719","52","140","122","65","12187","1.3","161","466","1"
"apache-carbondata","b5fc5188ef198402fd302b5f0a2e96c7cf077097","2016-06-29 11:10:45","[Bug] Column Group filter row level filter and Exclude filter not working(#775)

","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","b5fc5188ef198402fd302b5f0a2e96c7cf077097","27","2","0","3030","272","19","3202","40","5032","897","352","4","15","4089","0","13","37","224","apache-carbondata","b5fc5188ef198402fd302b5f0a2e96c7cf077097","497","20.7","7","63458","31617","6414","5","1192","77","1501","13.8","2531","41","2.7","5","133","1560","13274","9","845","1719","52","140","122","65","12204","1.3","161","466","1"
"apache-carbondata","a74375719a5c09249bb742bf7faef33b02bcf252","2016-06-28 09:23:58","Supported tinyint datatype in carbondata
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","a74375719a5c09249bb742bf7faef33b02bcf252","23","2","0","2161","250","19","2652","25","3724","653","306","4","7","2971","0","8","24","186","apache-carbondata","a74375719a5c09249bb742bf7faef33b02bcf252","359","21.2","7","47230","23456","4731","5","885","38","1133","14","1783","23","1.8","5","91","1170","9836","9","435","854","30","140","88","58","9105","1.3","127","337","1"
"apache-carbondata","3718dc2fda6b45cf46e50944d23a13aa5d945f89","2016-06-27 14:46:41","[BUG] Fixed Carbon Table Path while registering as External Table to Hive (#768)

","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","3718dc2fda6b45cf46e50944d23a13aa5d945f89","27","2","0","3029","272","19","3194","39","4982","900","352","4","15","4070","0","13","38","224","apache-carbondata","3718dc2fda6b45cf46e50944d23a13aa5d945f89","496","20.7","7","63226","31466","6385","5","1188","77","1496","13.7","2521","39","2.6","5","133","1555","13197","9","845","1651","52","140","122","65","12175","1.3","160","465","1"
"apache-carbondata","5e1a67b9b5f2a24a8cded7e7c299ae3b9d06dea8","2016-06-27 10:46:42","[Bug] ColumnProperty: Change visibility of variable (#764)

","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","5e1a67b9b5f2a24a8cded7e7c299ae3b9d06dea8","27","2","0","3029","272","19","3194","39","4982","900","352","4","15","4070","0","13","38","224","apache-carbondata","5e1a67b9b5f2a24a8cded7e7c299ae3b9d06dea8","496","20.7","7","63226","31466","6385","5","1188","77","1496","13.7","2521","39","2.6","5","133","1555","13197","9","845","1651","52","140","122","65","12175","1.3","160","465","1"
"apache-carbondata","462eb393baf99d3b0a7f49869f5a3d95f0e2fd9e","2016-06-27 10:04:51","[CARBONDATA-13] Direct surrogate key range filters not able to prune blocks (#721)

* When Range filters(>,<,>=,<=) is applied Direct Surrogate Column block and blocklet pruning is supported
* Binary search inside block let for range filters.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","462eb393baf99d3b0a7f49869f5a3d95f0e2fd9e","27","2","0","3027","272","19","3194","39","4982","904","352","4","15","4070","0","13","38","224","apache-carbondata","462eb393baf99d3b0a7f49869f5a3d95f0e2fd9e","496","20.7","7","63204","31463","6384","5","1188","77","1496","13.7","2520","39","2.6","5","133","1555","13196","9","845","1651","52","140","122","65","12175","1.3","160","465","1"
"apache-carbondata","e689092960045634ca3531918022d5030274eb1c","2016-06-27 09:09:23","[Bug] Executor Btree loading performance improvement (#763)

Make block level btree loading in executor multi threaded.","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","e689092960045634ca3531918022d5030274eb1c","27","2","0","2985","273","19","3160","39","4914","887","352","4","15","3963","0","13","38","226","apache-carbondata","e689092960045634ca3531918022d5030274eb1c","496","20.8","7","62573","30995","6281","5","1158","59","1468","13.5","2501","39","2","5","133","1526","12959","9","840","1264","51","140","122","66","11628","1.3","160","465","1"
"apache-carbondata","c6cafaa817ddcc848de9421efcb63d9a912b963b","2016-06-27 07:15:49","Fixed count star with filter issue (#762)

","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","c6cafaa817ddcc848de9421efcb63d9a912b963b","27","2","0","2983","273","19","3160","38","4908","886","352","4","14","3956","0","13","37","226","apache-carbondata","c6cafaa817ddcc848de9421efcb63d9a912b963b","495","20.8","7","62495","30944","6272","5","1156","59","1466","13.5","2497","39","2","5","132","1523","12937","9","825","1264","50","140","122","66","11613","1.3","160","465","1"
"apache-carbondata","38d84e0e2d89744290d50d46750bbadf5ba9c693","2016-06-27 04:11:52","[Issue-643] Column Property addition, extract interface for dictionary (#641)

1.Added interface to get dictionary service
2.Modified schema.thrift to add column properties
3. Describe formatted shows column properties","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","38d84e0e2d89744290d50d46750bbadf5ba9c693","27","2","0","2984","273","19","3160","38","4908","886","352","4","14","3952","0","13","37","226","apache-carbondata","38d84e0e2d89744290d50d46750bbadf5ba9c693","495","20.8","7","62493","30946","6271","5","1156","59","1467","13.5","2497","39","2","5","132","1524","12937","9","825","1264","50","140","122","67","11613","1.3","160","465","1"
"apache-carbondata","5b6081d7b203411fcc2e4b941c6f67f62d8c2878","2016-06-26 07:09:17","[Bug] Timestamp with different format compare to spark date format will fail to provide filter result. this is because while (#754)

querying the engine is trying to get the direct surrogate based in user defined time format in properties file.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","5b6081d7b203411fcc2e4b941c6f67f62d8c2878","27","2","0","2958","268","19","3134","38","4873","889","352","4","14","3922","0","13","31","226","apache-carbondata","5b6081d7b203411fcc2e4b941c6f67f62d8c2878","487","20.7","7","61773","30635","6192","5","1150","55","1463","13.5","2465","38","1.9","5","132","1520","12853","9","825","1176","50","140","119","67","11493","1.3","162","457","1"
"apache-carbondata","73975b02ce8a8e62ad052c08ed712a32f1e02f37","2016-06-25 22:00:53","Added Validation for delete segments query, load start time parameter (#752)

* Added Validation for delete segments, load start time parameter

* fixed review comment
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","73975b02ce8a8e62ad052c08ed712a32f1e02f37","27","2","0","2950","269","19","3134","38","4868","888","352","4","14","3924","0","13","31","226","apache-carbondata","73975b02ce8a8e62ad052c08ed712a32f1e02f37","487","20.7","7","61735","30621","6186","5","1151","55","1464","13.5","2462","38","1.9","5","132","1521","12847","9","825","1176","50","140","119","67","11506","1.3","162","457","1"
"apache-carbondata","720e8d6152e91be7276be5a7c1317d17caf5b30b","2016-06-25 07:23:02","[Bug] Added comments for carbon.properties.template and Carbonindex file cleanup fix (#749)

* Added comments for carbon.properties.template
* clean files not cleaning .carbonindex files","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","720e8d6152e91be7276be5a7c1317d17caf5b30b","27","2","0","2949","269","19","3132","38","4867","886","352","4","14","3922","0","13","31","226","apache-carbondata","720e8d6152e91be7276be5a7c1317d17caf5b30b","487","20.7","7","61692","30595","6179","5","1150","55","1463","13.5","2460","38","1.9","5","131","1519","12838","9","810","1176","49","140","119","67","11496","1.3","162","457","1"
"apache-carbondata","24c47c204426cdc51d6d3d13a47f4d351b687484","2016-06-25 06:26:14","[BUG] Memory leak issue ,Clean Up handling,Preserve handling during compaction (#748)

* handling the cleanup of stale compacted segments in the compaction also.
* Fix problem in preserving segments during compaction
* Memory leak problem in query flow.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","24c47c204426cdc51d6d3d13a47f4d351b687484","27","2","0","2949","269","20","3132","38","4865","886","352","4","14","3921","0","13","31","226","apache-carbondata","24c47c204426cdc51d6d3d13a47f4d351b687484","487","20.7","7","61678","30588","6176","5","1150","55","1463","13.5","2459","38","1.9","5","131","1519","12834","9","810","1176","49","140","119","67","11498","1.3","162","457","1"
"apache-carbondata","322a77bf41823d4696c4525dc94f068e23efecd0","2016-06-25 03:35:15","[Bug] fix bug when high.cardinality.threshold == HIGH_CARDINALITY_THRESHOLD_MIN (#750)

[Bug] fix bug when high.cardinality.threshold == HIGH_CARDINALITY_THRESHOLD_MIN (#750)","refs/heads/master","zhujin2@huawei.com","apache-carbondata","322a77bf41823d4696c4525dc94f068e23efecd0","27","2","0","2949","269","20","3132","38","4864","886","352","4","14","3920","0","13","31","226","apache-carbondata","322a77bf41823d4696c4525dc94f068e23efecd0","487","20.7","7","61670","30580","6174","5","1151","55","1464","13.5","2459","38","1.9","5","131","1519","12827","8","780","1176","48","140","119","67","11511","1.3","162","457","1"
"apache-carbondata","60490179674681985aad2465afd8c0f5b025e185","2016-06-25 01:58:35","Removed unused properties from carbon (#739)

* Removed unused properties from carbon

* Removed unused carbon properties

* Fixed review comments
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","60490179674681985aad2465afd8c0f5b025e185","27","2","0","2949","269","20","3132","38","4863","886","352","4","14","3920","0","13","31","226","apache-carbondata","60490179674681985aad2465afd8c0f5b025e185","487","20.7","7","61670","30580","6174","5","1151","55","1464","13.5","2459","38","1.9","5","131","1519","12827","8","780","1176","48","140","119","67","11513","1.3","162","457","1"
"apache-carbondata","e96de9f5b9e0560a5e59cc5f941e450d4a7e00f8","2016-06-25 01:35:56","[BUG]Column group with no dictionary and timestamp (#713)

While data loading, encoding is not proper for all dimension

Fixed query execution for no dictionary and column groups
Fixed test cases and added more test case for column group and dictionary exclude
Fixed review comment","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","e96de9f5b9e0560a5e59cc5f941e450d4a7e00f8","27","2","0","2951","270","24","3246","38","4888","886","352","4","14","3930","0","13","31","226","apache-carbondata","e96de9f5b9e0560a5e59cc5f941e450d4a7e00f8","487","20.6","7","62267","30942","6230","5","1151","55","1467","13.6","2472","38","1.9","5","131","1522","12950","8","780","1176","48","140","119","67","11600","1.2","165","457","1"
"apache-carbondata","82332b0e4381ede8a39789ccf1d917af0c89ab39","2016-06-25 01:05:07","Fixed driver btree performance issue (#729)

LGTM","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","82332b0e4381ede8a39789ccf1d917af0c89ab39","27","2","0","2947","269","24","3236","38","4854","884","355","4","14","3919","0","12","31","226","apache-carbondata","82332b0e4381ede8a39789ccf1d917af0c89ab39","487","20.7","7","62163","30857","6203","5","1146","55","1462","13.6","2462","38","1.9","5","131","1517","12898","8","780","1176","48","140","119","67","11594","1.3","165","457","1"
"apache-carbondata","be46423a08effd5fb784ed7d1ff1736adf44b670","2016-06-25 00:42:30","[Issue-578] Changing the minor compaction behavior to work on segment numbers. (#737)

* Minor compaction need to be done based on the number of segments.
User will give the number of segments to be merged in levels.
* Add property carbon.compaction.level.threshold, removing carbon.compaction.minor.size","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","be46423a08effd5fb784ed7d1ff1736adf44b670","27","2","0","2937","269","24","3210","38","4807","885","355","4","14","3889","0","12","31","226","apache-carbondata","be46423a08effd5fb784ed7d1ff1736adf44b670","484","20.6","7","61724","30663","6173","5","1144","55","1456","13.6","2444","38","1.9","5","131","1511","12809","8","780","1176","48","140","118","66","11566","1.3","162","454","1"
"apache-carbondata","d5636db0de30d6461381b58d0c2e594470d9e938","2016-06-25 00:29:38","[Issue - CARBONDATA-10] Avoid to much logging of timestamp parsing exception in TimeStampDirectDictionaryGenerator (#745)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","d5636db0de30d6461381b58d0c2e594470d9e938","27","2","0","2938","269","24","3208","38","4799","885","355","4","14","3888","0","12","31","226","apache-carbondata","d5636db0de30d6461381b58d0c2e594470d9e938","484","20.6","7","61688","30638","6163","5","1142","55","1454","13.6","2442","38","1.9","5","131","1509","12792","8","780","1176","48","140","118","66","11508","1.3","162","454","1"
"apache-carbondata","a174f69e711f531e33d5979aa8845b1aee9de902","2016-06-25 00:22:50","[Issue- CARBONDATA-7] fortify issue fixes, Fixed Explicit null dereferenced ,Dereference null return value (#738)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","a174f69e711f531e33d5979aa8845b1aee9de902","27","2","0","2938","269","24","3208","38","4799","885","355","4","14","3888","0","12","31","226","apache-carbondata","a174f69e711f531e33d5979aa8845b1aee9de902","484","20.6","7","61687","30636","6163","5","1142","55","1454","13.6","2442","38","1.9","5","131","1509","12791","8","780","1176","48","140","118","66","11508","1.3","162","454","1"
"apache-carbondata","b0f2f060f82669a4c62b2b7d6d649e49243846ba","2016-06-24 12:19:58","[BUG] Failed to update table status on concurrent compaction and data load. (#741)

* If table status lock is failed, retry to acquire, then complete data load or the compaction should fail.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","b0f2f060f82669a4c62b2b7d6d649e49243846ba","27","2","0","2938","269","24","3208","38","4797","886","355","4","14","3883","0","12","31","226","apache-carbondata","b0f2f060f82669a4c62b2b7d6d649e49243846ba","484","20.6","7","61658","30608","6148","5","1139","55","1451","13.5","2442","38","1.9","5","131","1508","12779","10","800","1175","50","140","118","66","11483","1.3","162","454","1"
"apache-carbondata","c65f9729c76ce4b9e199334d958df8299e4b00d9","2016-06-24 06:07:20","[issue-705]Fix  data cleanup before data load and data load failure (#706)

[issue-705]Fix  data cleanup before data load and data load failure (#706)
* fix cleanup while data load failure or useless files exist
* use segmentstatusmanage to read tablestatus file","refs/heads/master","linyixin@huawei.com","apache-carbondata","c65f9729c76ce4b9e199334d958df8299e4b00d9","27","2","0","2938","269","24","3208","38","4798","886","355","4","14","3883","0","12","31","226","apache-carbondata","c65f9729c76ce4b9e199334d958df8299e4b00d9","484","20.6","7","61657","30606","6148","5","1139","55","1451","13.5","2442","38","1.9","5","131","1508","12778","10","800","1175","50","140","118","66","11483","1.3","162","454","1"
"apache-carbondata","aafd1a470b21dc9a19072605fec296d3c2b59c65","2016-06-24 03:16:47","[Bug] throw exception while comparing invalid type members in filter evaluation (#683)

","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","aafd1a470b21dc9a19072605fec296d3c2b59c65","27","2","0","2936","269","24","3208","38","4798","886","355","4","14","3883","0","12","31","226","apache-carbondata","aafd1a470b21dc9a19072605fec296d3c2b59c65","484","20.6","7","61657","30606","6148","5","1139","55","1451","13.5","2442","38","1.9","5","131","1508","12778","10","800","1175","50","140","118","66","11483","1.3","162","454","1"
"apache-carbondata","123fe1f86b668f00c0ab51d78d075cb9897afe62","2016-06-24 02:21:56","sorting logic of the table blocks was considering task no as string. which is wrong. Need to convert it to int. (#736)

","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","123fe1f86b668f00c0ab51d78d075cb9897afe62","27","2","0","2928","269","24","3194","39","4791","886","355","4","14","3884","0","12","30","224","apache-carbondata","123fe1f86b668f00c0ab51d78d075cb9897afe62","483","20.6","7","61469","30498","6132","5","1133","55","1433","13.5","2435","38","1.9","5","131","1490","12750","10","800","1175","50","140","118","71","11343","1.2","145","453","1"
"apache-carbondata","aa0ac0b3ea57f02d497470906b78d086ca2f490c","2016-06-24 02:14:50","[issue-725] data mismatch between the carbon Table and Hive Table (#726)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","aa0ac0b3ea57f02d497470906b78d086ca2f490c","27","2","0","2928","269","24","3194","39","4791","886","355","4","14","3886","0","12","30","224","apache-carbondata","aa0ac0b3ea57f02d497470906b78d086ca2f490c","483","20.6","7","61471","30500","6134","5","1133","55","1433","13.5","2435","38","1.9","5","131","1490","12752","10","800","1175","50","140","118","71","11345","1.2","145","453","1"
"apache-carbondata","63d3284e4f0a09ef5248065da19c2bd3db371e08","2016-06-22 23:19:58","Refactor carbon-core module for code clean up (#720)

* refactor core module

* fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","63d3284e4f0a09ef5248065da19c2bd3db371e08","23","2","0","2160","226","19","2652","25","3726","651","306","4","7","2937","0","12","24","178","apache-carbondata","63d3284e4f0a09ef5248065da19c2bd3db371e08","359","21.3","7","47171","23391","4696","5","880","38","1126","13.9","1784","23","1.8","5","90","1163","9799","9","435","851","30","140","88","58","8994","1.3","126","337","1"
"apache-carbondata","899551509610d43976c18853e8d1f6ea0e7fcc62","2016-06-22 01:45:19","[issue-717] select id from table_x where salary is not null; returning the empty result even though null data is available (#718)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","899551509610d43976c18853e8d1f6ea0e7fcc62","27","2","0","2928","269","24","3194","39","4791","886","355","4","14","3885","0","12","30","224","apache-carbondata","899551509610d43976c18853e8d1f6ea0e7fcc62","483","20.6","7","61470","30499","6133","5","1133","55","1433","13.5","2435","38","1.9","5","131","1490","12751","10","800","1175","50","140","118","71","11344","1.2","145","453","1"
"apache-carbondata","9d89d69e77bb63bef017b29f599282bd2ad9d2fd","2016-06-20 09:16:47","Deleting unnecessary code added after merge from master
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9d89d69e77bb63bef017b29f599282bd2ad9d2fd","23","2","0","2338","229","21","2780","28","3965","715","340","4","12","3068","0","12","24","198","apache-carbondata","9d89d69e77bb63bef017b29f599282bd2ad9d2fd","380","21.1","7","50025","24884","4977","5","941","38","1216","14","1874","23","1.7","5","110","1256","10433","10","475","851","33","140","93","58","9627","1.3","137","356","1"
"apache-carbondata","7972709bcf70a4278535b5195d7c2c3ae934ddc5","2016-06-20 09:13:22","Merge remote-tracking branch 'carbon_master/master' into merge3

Conflicts:
	core/src/main/java/org/carbondata/core/keygenerator/directdictionary/timestamp/TimeStampDirectDictionaryGenerator.java
	core/src/main/java/org/carbondata/query/aggregator/util/MeasureAggregatorFactory.java
	core/src/main/java/org/carbondata/scan/executor/util/QueryUtil.java
	core/src/main/java/org/carbondata/scan/filter/resolver/ConditionalFilterResolverImpl.java
	integration/spark/src/main/scala/org/apache/spark/sql/execution/command/carbonTableSchema.scala
	integration/spark/src/main/scala/org/carbondata/spark/agg/CarbonAggregates.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonDataRDDFactory.scala
	integration/spark/src/main/scala/org/carbondata/spark/rdd/CarbonMergerRDD.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/allqueries/AllDataTypesTestCaseAggregate.scala
	integration/spark/src/test/scala/org/carbondata/spark/testsuite/datacompaction/DataCompactionNoDictionaryTest.scala
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7972709bcf70a4278535b5195d7c2c3ae934ddc5","23","2","0","2354","229","21","2802","28","3986","724","340","4","12","3088","0","12","24","198","apache-carbondata","7972709bcf70a4278535b5195d7c2c3ae934ddc5","383","21.1","7","50347","25037","5010","5","942","38","1217","14","1892","23","1.7","5","110","1257","10500","10","475","851","33","140","95","58","9632","1.3","137","359","1"
"apache-carbondata","1c725f5ba2e95e82e4922e7a8e0aa81cdc671a80","2016-06-18 11:30:21","Refactor org.carbondata.query package (#692)

* fix style

* move query.carbon package one level up

* rename org.carbondata.query to org.carbondata.scan

* refactory
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","1c725f5ba2e95e82e4922e7a8e0aa81cdc671a80","25","2","0","2319","227","21","2766","28","3946","709","340","4","12","3052","0","12","24","194","apache-carbondata","1c725f5ba2e95e82e4922e7a8e0aa81cdc671a80","377","21.2","7","49709","24681","4905","5","936","34","1211","13.9","1859","21","1.6","5","108","1251","10361","10","475","775","33","140","93","58","9553","1.3","139","353","1"
"apache-carbondata","29360501336ddc54a349257512fffb5bd8d87126","2016-06-18 09:09:54","Optimized detail query flow and cleanup (#691)

* Optimizing detail query

* Optimizing detail query flow

* Optimizing detail query flow

* Optimized raw detail query to improve push up performance.

* Fixed bugs

* reverted wrong check in

* Rebased the code

* Removed aggregation from core

* Refactored core package and fixed test cases

* Fixed bugs

* Fixed review comments and deleted aggregate classes after merge from master

* Removed unused code

* Optimized scanner flow

* Optimized scanner flow

* Optimized scanning flow

* Optimized scanner flow

* Refactored code

* Refactored code

* Removed unused code

* Reverted unnecessary comment

* Reverted queryinterface package from core

* Removed queryinterface package from core

* Handled review comments

* Handled review comments

* Added assert
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","29360501336ddc54a349257512fffb5bd8d87126","25","2","0","2329","227","21","2810","28","3972","718","342","4","12","3058","0","12","24","194","apache-carbondata","29360501336ddc54a349257512fffb5bd8d87126","384","21.2","7","50174","24856","4924","5","939","34","1214","13.7","1870","21","1.5","5","108","1254","10406","10","475","775","33","140","100","58","9585","1.3","139","360","1"
"apache-carbondata","656577d5c05d57291de77084d8993553a49cdfdc","2016-06-17 23:41:02","remove AbastructQueryExecutor (#690)

","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","656577d5c05d57291de77084d8993553a49cdfdc","26","2","0","2422","228","24","2874","35","4102","758","348","4","14","3125","0","12","27","196","apache-carbondata","656577d5c05d57291de77084d8993553a49cdfdc","417","21.5","8","53044","25926","5076","5","972","34","1252","13.2","1966","21","1.5","5","121","1302","10770","10","715","775","42","150","109","59","9774","1.3","140","386","1"
"apache-carbondata","6288ec7152bbb832884de24e2e5912a0feecc0af","2016-06-17 18:17:19","Refactored core package and fixed all testcases (#684)

* Optimizing detail query

* Optimizing detail query flow

* Optimizing detail query flow

* Optimized raw detail query to improve push up performance.

* Fixed bugs

* reverted wrong check in

* Rebased the code

* Removed aggregation from core

* Refactored core package and fixed test cases

* Fixed bugs

* Fixed review comments and deleted aggregate classes after merge from master

* Removed unused code
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","6288ec7152bbb832884de24e2e5912a0feecc0af","26","2","0","2425","228","24","2882","36","4114","761","348","4","14","3146","0","12","27","196","apache-carbondata","6288ec7152bbb832884de24e2e5912a0feecc0af","418","21.5","8","53167","25999","5086","5","977","34","1258","13.1","1967","21","1.5","5","123","1309","10803","10","730","775","43","150","109","59","9840","1.3","140","387","1"
"apache-carbondata","91951acf2f89a0f5d0cf340a273f5ede8a08afb2","2016-06-17 11:13:25","[Issue - 685] Support null or empty value for timestamp column (#686)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","91951acf2f89a0f5d0cf340a273f5ede8a08afb2","27","2","0","2928","269","24","3194","39","4791","886","355","4","14","3880","0","12","30","224","apache-carbondata","91951acf2f89a0f5d0cf340a273f5ede8a08afb2","483","20.6","7","61468","30497","6132","5","1133","55","1433","13.5","2435","38","1.9","5","131","1490","12751","10","800","1175","50","140","118","71","11343","1.2","145","453","1"
"apache-carbondata","f479e7efecfb10c16ac994a4c933d59efa6bb685","2016-06-17 10:42:33","[BUG] Zookeeper lock changes to allow exclusive locks for different tables (#688)

added schema name and table name to Zookeeper lock location","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","f479e7efecfb10c16ac994a4c933d59efa6bb685","27","2","0","2928","268","24","3192","39","4789","886","355","4","14","3878","0","12","30","224","apache-carbondata","f479e7efecfb10c16ac994a4c933d59efa6bb685","483","20.6","7","61455","30484","6124","5","1132","55","1432","13.5","2435","38","1.9","5","131","1489","12744","10","800","1175","50","140","118","71","11329","1.2","145","453","1"
"apache-carbondata","25cd9e5de13e2b9c561308be2a376ec458be5168","2016-06-16 20:39:13","[issue-644]Update CarbonFile to support Federation (#661)

* Update CarbonFile to support Federation

* Set DefaultFileType to VIEWFS when store-path schema is viewfs://

* fix checkstyle error

* fix instance error of CarbonFile#getParentFile return

* update #ViewFSCarbonFile follow of optimizing nn rpc request
","refs/heads/master","xq.he2009@gmail.com","apache-carbondata","25cd9e5de13e2b9c561308be2a376ec458be5168","27","2","0","2928","268","24","3192","39","4786","884","355","4","14","3878","0","12","30","224","apache-carbondata","25cd9e5de13e2b9c561308be2a376ec458be5168","483","20.6","7","61432","30472","6123","5","1131","55","1431","13.5","2435","38","1.9","5","131","1488","12737","10","800","1175","50","140","118","71","11324","1.2","145","453","1"
"apache-carbondata","ead0076b077873a776e0e02273f587500ee713e7","2016-06-16 17:22:03","[Issue 618]Supported Spark 1.6 in Carbondata (#670)

* [Issue-660] Show segments query should not fail, if table name is case insensitive (#662)

* Show segments should not fail, if table name is case insensitive

* Corrected test case

* [issue-656] fix load data when int column contains integer.min_value (#657)

* load data when int column contains min Integer

* fixed test case

*  fix test bigint

*  fix test bigint

* removed no used DATA_BIGINT case

* removed no used condition for unCompressMaxMin

* [issue- 664] select count(joinDate) from table_x is failing for direct dictionary column (#665)

* Supported Spark 1.6 by changing aggregation interfaces

* Fixed compile issue after rebase

* optmizing the flow with unsafe row

* Fixed bugs in push up

* Fixed compiler issues after rebasing

* Fixed merging issue after rebase

* Fixed scan query pushdown
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","ead0076b077873a776e0e02273f587500ee713e7","29","2","0","2901","266","24","3174","39","4759","880","355","4","14","3849","0","12","30","220","apache-carbondata","ead0076b077873a776e0e02273f587500ee713e7","479","20.7","7","60985","30208","6032","5","1129","51","1429","13.4","2408","36","1.8","5","129","1486","12629","10","800","1099","50","140","125","71","11280","1.2","147","449","1"
"apache-carbondata","512436dc520fb4b69024b77453e8f9da836cf6ab","2016-06-16 12:14:16","[Bug] Bug fix in the minor compaction segment size identification, other compaction fixes. (#663)

1. Bug fix in the minor compaction segment size identification.
2. Handling of the locking mechanism for compaction using wrapper thread.
3. loadmetadata details was updated wrongly when two compactions triggered.
4. compaction status should get updated correctly after all the rdd success.
5. Fixes for exclusive tmp store locations across tasks and dataloads by taking the temp store location from the spark temp file, for better utilization of local disks.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","512436dc520fb4b69024b77453e8f9da836cf6ab","29","2","0","2913","267","24","3190","39","4774","883","355","4","14","3868","0","12","30","224","apache-carbondata","512436dc520fb4b69024b77453e8f9da836cf6ab","481","20.7","7","61234","30329","6067","5","1129","51","1429","13.5","2424","36","1.8","5","129","1486","12688","10","800","1099","50","140","118","71","11240","1.2","147","451","1"
"apache-carbondata","a090125ee7b99ad81adb310e9cc4c39d0939c548","2016-06-16 11:41:35","[Issue - 612] Direct dictionary improvement 1. Remove property ""carbon.direct.dictionary"" to enable/disable the direct dictionary feature. (#615)

even though user configures timestamp type column to be NO_DICTIONARY col, treat that column as Direct dictionary column
+ handled the direct dictionary support for the dataframe
+Fixed the NullMeasureValueTestCaseAggregate.scala test cases
+Fixed integration-testcases and removed some of duplicate test cases.
+Fixed the select avg(Timestamp_Type) from table_x; was not returning the the same value as hive
+Fixed the select sum(Timestamp_Type) from carbonTable_x; was not returning the the same value as hiveTable
+Change the avgTest.csv timestampt to make it parseable for both carbon and hive table","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","a090125ee7b99ad81adb310e9cc4c39d0939c548","29","2","0","2913","267","24","3188","39","4774","883","355","4","14","3868","0","12","30","224","apache-carbondata","a090125ee7b99ad81adb310e9cc4c39d0939c548","481","20.7","7","61230","30328","6067","5","1129","51","1429","13.5","2424","36","1.8","5","129","1486","12688","10","800","1099","50","140","118","71","11240","1.2","147","451","1"
"apache-carbondata","d3b7e8fa4957cfa960a611f2ea85d384b935000d","2016-06-16 06:56:55","[Bug] Optimize HDFSCarbonFile.listFiles(CarbonFileFilter) and reduce the number of namenode rpc (#669)

* optimize listFiles","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","d3b7e8fa4957cfa960a611f2ea85d384b935000d","29","2","0","2899","267","24","3184","39","4762","883","355","4","14","3853","0","12","30","224","apache-carbondata","d3b7e8fa4957cfa960a611f2ea85d384b935000d","479","20.7","7","61017","30222","6037","5","1128","51","1428","13.4","2408","36","1.8","5","129","1485","12637","10","800","1099","50","140","118","71","11231","1.2","147","449","1"
"apache-carbondata","afabe63c456fa8d92941c3eba50cf074867db3d5","2016-06-16 04:06:17","Zookeeper Instance need to be created in the carbon env. (#642)

* Zookeeper Instance need to be created in the carbon env.
Creating the zookeeper client on the start up.
creating the singleton instance of zookeeperInit.

* correcting zookeeper Testcase.

* carbon context changes.

* changing the init to the carbon metastore catalog.

* correcting the checkstyles.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","afabe63c456fa8d92941c3eba50cf074867db3d5","29","2","0","2900","267","24","3184","39","4760","882","355","4","14","3849","0","12","30","220","apache-carbondata","afabe63c456fa8d92941c3eba50cf074867db3d5","479","20.7","7","61000","30217","6033","5","1127","51","1428","13.4","2406","36","1.8","5","130","1485","12635","10","800","1099","50","140","118","71","11270","1.2","147","449","1"
"apache-carbondata","ab137077139185e26300c730c8b032f765e0349c","2016-06-16 02:13:33","[issue- 664] select count(joinDate) from table_x is failing for direct dictionary column (#665)

","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","ab137077139185e26300c730c8b032f765e0349c","29","2","0","2895","266","24","3174","39","4759","880","355","4","14","3849","0","12","30","220","apache-carbondata","ab137077139185e26300c730c8b032f765e0349c","478","20.7","7","60936","30185","6029","5","1127","51","1427","13.5","2404","36","1.8","5","129","1484","12626","10","800","1099","50","140","118","71","11260","1.2","147","448","1"
"apache-carbondata","0eb3c6ed8efe46dae765fd26d2ad659d43967116","2016-06-16 00:17:44","[issue-656] fix load data when int column contains integer.min_value (#657)

* load data when int column contains min Integer

* fixed test case

*  fix test bigint

*  fix test bigint

* removed no used DATA_BIGINT case

* removed no used condition for unCompressMaxMin
","refs/heads/master","zhujin2@huawei.com","apache-carbondata","0eb3c6ed8efe46dae765fd26d2ad659d43967116","29","2","0","2893","266","24","3158","39","4750","871","355","4","14","3840","0","12","30","220","apache-carbondata","0eb3c6ed8efe46dae765fd26d2ad659d43967116","477","20.7","7","60814","30128","6022","5","1127","51","1427","13.5","2402","36","1.8","5","129","1484","12608","10","800","1099","50","140","118","71","11260","1.2","147","447","1"
"apache-carbondata","da85fd63e508f30ad8a3404921452e6e6e02841a","2016-06-16 00:06:14","[Issue-660] Show segments query should not fail, if table name is case insensitive (#662)

* Show segments should not fail, if table name is case insensitive

* Corrected test case
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","da85fd63e508f30ad8a3404921452e6e6e02841a","29","2","0","2893","266","24","3158","39","4750","871","355","4","14","3840","0","12","30","220","apache-carbondata","da85fd63e508f30ad8a3404921452e6e6e02841a","477","20.7","7","60818","30133","6024","5","1126","51","1426","13.5","2402","36","1.8","5","129","1483","12611","10","800","1099","50","140","118","71","11258","1.2","147","447","1"
"apache-carbondata","4dde51cd6f1a591c0feae76b35bc22cfc0961b85","2016-06-15 21:32:54","[Bug] Sort index not created properly for null members in case of data types rather than String type. (#667)

","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","4dde51cd6f1a591c0feae76b35bc22cfc0961b85","29","2","0","2893","266","24","3158","39","4749","870","355","4","14","3840","0","12","30","220","apache-carbondata","4dde51cd6f1a591c0feae76b35bc22cfc0961b85","477","20.7","7","60809","30130","6023","5","1126","51","1426","13.5","2401","36","1.8","5","129","1483","12610","10","800","1099","50","140","118","71","11258","1.2","147","447","1"
"apache-carbondata","9c9f58b6f9634cfa91b81d494b703e344017a253","2016-06-15 21:26:10","Added Code To Improve Btree Loading Performance And block pruning (#666)

LGTM","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","9c9f58b6f9634cfa91b81d494b703e344017a253","29","2","0","2889","264","24","3158","39","4746","870","355","4","14","3832","0","12","30","218","apache-carbondata","9c9f58b6f9634cfa91b81d494b703e344017a253","477","20.7","7","60762","30099","6005","5","1126","51","1426","13.4","2400","36","1.8","5","129","1483","12594","10","800","1103","50","140","118","71","11248","1.2","147","447","1"
"apache-carbondata","412beabf45947ba94808f8e64d076893b79ab274","2016-06-15 15:10:53","[Bug] For non string data type no dictionary column if any string type(unparseable) data is present then the data has to be converted to defaullt nulll (#653)

member values.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","412beabf45947ba94808f8e64d076893b79ab274","29","2","0","2884","264","24","3136","39","4742","864","355","4","14","3841","0","12","30","218","apache-carbondata","412beabf45947ba94808f8e64d076893b79ab274","477","20.6","7","60618","30044","5994","5","1119","51","1419","13.4","2395","36","1.8","5","129","1476","12564","10","800","1103","50","140","118","71","11186","1.2","147","447","1"
"apache-carbondata","cbd2c29d5df04c3def84b14172c7a9ca92d82a64","2016-06-15 08:30:41","[issue-650]handle not exists input file path and stop data loading flow (#651)

[issue-650]handle not exists input file path and stop data loading flow (#651)","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","cbd2c29d5df04c3def84b14172c7a9ca92d82a64","29","2","0","2883","264","24","3136","39","4739","863","355","4","14","3838","0","12","30","218","apache-carbondata","cbd2c29d5df04c3def84b14172c7a9ca92d82a64","477","20.6","7","60564","30004","5975","5","1116","51","1416","13.4","2394","36","1.8","5","129","1473","12547","10","800","1103","50","140","118","71","11142","1.2","147","447","1"
"apache-carbondata","67a6c3b0f0995f6ff357da3dd284de400937ea94","2016-06-12 21:57:14","[Bug] fix bug for appending hdfs url (#637)

","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","67a6c3b0f0995f6ff357da3dd284de400937ea94","29","2","0","2883","264","24","3136","39","4739","863","355","4","14","3838","0","12","30","218","apache-carbondata","67a6c3b0f0995f6ff357da3dd284de400937ea94","477","20.6","7","60564","30004","5975","5","1116","51","1416","13.4","2394","36","1.8","5","129","1473","12547","10","800","1103","50","140","118","71","11144","1.2","147","447","1"
"apache-carbondata","787380319330127ab06bb60efe2ce8524c080b59","2016-06-12 15:16:15","[Issue 548] Fixed all find bugs in all modules (#574)

* Fixed find bugs

* FIxed find bugs in processing module and cleaned code.

* Fixed final find bug

* Fixed check style

* Fixed more find bugs after rebase
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","787380319330127ab06bb60efe2ce8524c080b59","29","2","0","2883","264","24","3136","39","4739","863","355","4","14","3838","0","12","30","218","apache-carbondata","787380319330127ab06bb60efe2ce8524c080b59","477","20.6","7","60564","30004","5975","5","1116","51","1416","13.4","2394","36","1.8","5","129","1473","12547","10","800","1103","50","140","118","71","11144","1.2","147","447","1"
"apache-carbondata","2e6ad6a1a3702b1d6a157224a30199815f93fcaf","2016-06-12 07:48:59","[Bug] cardinality normalization during compaction, include/exclude the compacted segment in compaction (#634)

!changes to include/exclude the compacted segment to be part of minor compaction again or not.
using configuration ""carbon.include.compacted.segments"", default to ""false""
* Handling of the Column cardinality in case of compacting 2 segments with different cardinality.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","2e6ad6a1a3702b1d6a157224a30199815f93fcaf","29","2","0","2886","265","24","3200","39","4739","863","355","4","14","3838","0","12","30","218","apache-carbondata","2e6ad6a1a3702b1d6a157224a30199815f93fcaf","477","20.7","7","60735","30050","5975","5","1116","51","1416","13.4","2394","36","1.8","5","130","1474","12547","10","830","1103","51","140","118","71","11154","1.2","147","447","1"
"apache-carbondata","f6bc60bc2f624ef4fc17f2c6a8d3dcb85a810c05","2016-06-11 16:11:55","[BUG]Fixed Aggregate Function No Dictionary Column Issue (#622)

* Fixed Aggregate Function NoDictionary Column Issue

* fixed code review comments and added test case

* fixed test case
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","f6bc60bc2f624ef4fc17f2c6a8d3dcb85a810c05","29","0","0","2883","265","24","3182","39","4729","862","353","4","14","3834","0","12","30","218","apache-carbondata","f6bc60bc2f624ef4fc17f2c6a8d3dcb85a810c05","477","20.7","7","60664","29998","5963","5","1112","49","1410","13.3","2393","35","1.8","5","128","1468","12519","10","830","1080","51","140","118","71","11029","1.2","147","447","1"
"apache-carbondata","eea895a06d34041dd1b21ff1774d06eb7c343958","2016-06-11 16:02:43","[BUG]Fixed Issues regarding Filter, There were issues in dictionary search for range filters if filter members contains Null. (#623)

Also handled the scenario where unsupported data type is been returned by Spark,In this case system has to throw exception to the user interface.
Also there is an issue in hashcode implementation of Expression result because of which the reference check itself getting failed in case of same
filter member comparison present in 'IN' filter.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","eea895a06d34041dd1b21ff1774d06eb7c343958","29","0","0","2881","259","24","3178","39","4730","860","353","4","14","3830","0","12","30","218","apache-carbondata","eea895a06d34041dd1b21ff1774d06eb7c343958","477","20.7","7","60631","29979","5957","5","1111","49","1409","13.3","2393","35","1.8","5","128","1467","12509","10","830","1080","51","140","118","71","11016","1.2","147","447","1"
"apache-carbondata","d11c6efa0f1d183a5d4f80579fa40b9a45497dcb","2016-06-11 14:29:43","[Bug]Fixed Null Measure Value issue , it was showing unique value need to show null in case of detail query (#628)

in case of aggregate query need to show based on aggregator","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d11c6efa0f1d183a5d4f80579fa40b9a45497dcb","29","0","0","2878","258","24","3178","30","4725","852","353","4","14","3812","0","12","24","214","apache-carbondata","d11c6efa0f1d183a5d4f80579fa40b9a45497dcb","477","20.7","5","60543","29901","5919","5","1089","51","1383","13.2","2392","37","1.8","5","123","1439","12483","10","830","1112","51","90","118","71","10746","1.2","146","447","1"
"apache-carbondata","b8a1d270b42c0faaaf96488096e81d3f4911c227","2016-06-11 01:16:21","[Issue-578] Threaded compaction (#619)

* compaction is done thread based.
* minor compaction will trigger only when the size limit is reached.
* Added Alter table DDL support for triggering compaction. both minor , major.
* Added the property of auto compaction. enabling/disabling.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","b8a1d270b42c0faaaf96488096e81d3f4911c227","29","0","0","2879","261","24","3174","30","4725","851","351","4","15","3828","0","12","24","214","apache-carbondata","b8a1d270b42c0faaaf96488096e81d3f4911c227","477","20.7","5","60486","29857","5919","5","1089","51","1383","13.2","2393","37","1.8","5","123","1439","12456","10","830","1093","51","90","118","71","10750","1.2","146","447","1"
"apache-carbondata","9dd899fd0486137f1d1015805c36675dd82d801a","2016-06-10 02:10:49","[issue-602] fix equals bug of tableinfo & tableschema (#604)

fix equals bug of tableinfo & tableschema
fix type changed of tableid
","refs/heads/master","xq.he2009@gmail.com","apache-carbondata","9dd899fd0486137f1d1015805c36675dd82d801a","29","0","0","2879","261","24","3180","30","4725","848","351","4","15","3828","0","12","24","214","apache-carbondata","9dd899fd0486137f1d1015805c36675dd82d801a","477","20.7","5","60504","29862","5920","5","1089","51","1383","13.2","2393","37","1.8","5","123","1439","12456","10","830","1093","51","90","118","71","10752","1.2","146","447","1"
"apache-carbondata","cfb6e87e9ea17901498d76c730cf5cd2b6e4b576","2016-06-10 00:10:31","delete bad log after drop table (#565)

","refs/heads/master","zhujin2@huawei.com","apache-carbondata","cfb6e87e9ea17901498d76c730cf5cd2b6e4b576","29","0","0","2879","261","24","3180","30","4725","848","351","4","15","3828","0","12","24","214","apache-carbondata","cfb6e87e9ea17901498d76c730cf5cd2b6e4b576","477","20.7","5","60504","29862","5920","5","1089","51","1383","13.2","2393","37","1.8","5","123","1439","12456","10","830","1093","51","90","118","71","10752","1.2","146","447","1"
"apache-carbondata","f893e0d84f53367b0226f0ccff0d3eda8f70160e","2016-06-09 23:02:57","[Issue 513] Add tableId as part of CarbonTableIdentifier (#614)

1.Changed tableId to string from int in schema.thrift
2.Added tableId in CarbonTableIdentifier
3.Made CarbonTable as hub to get carbonTableIdentifier or absoluteTableIdentifier","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","f893e0d84f53367b0226f0ccff0d3eda8f70160e","29","0","0","2878","261","24","3178","30","4723","848","351","4","15","3827","0","12","24","214","apache-carbondata","f893e0d84f53367b0226f0ccff0d3eda8f70160e","477","20.7","5","60496","29856","5919","5","1089","51","1383","13.2","2392","37","1.8","5","123","1439","12453","10","830","1093","51","90","118","71","10752","1.2","146","447","1"
"apache-carbondata","9b2da0708a17ad06a7dc6bbe59aebcea1b3663be","2016-06-09 22:55:05","tableblockinfo sorting was wrong. (#611)

// segment id is changed from int to string.
// changed != to equalignorecase.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","9b2da0708a17ad06a7dc6bbe59aebcea1b3663be","29","0","0","2875","248","24","3174","30","4724","847","351","7","15","3823","0","12","24","216","apache-carbondata","9b2da0708a17ad06a7dc6bbe59aebcea1b3663be","477","20.8","5","60471","29818","5894","5","1088","47","1385","13.2","2388","35","1.7","5","123","1441","12432","10","830","1035","51","90","118","71","10696","1.2","149","447","1"
"apache-carbondata","19bbdbcf97491d44b6e02f4ad804336e860451a7","2016-06-09 02:29:05","[Bug] Handled Clearing access count for a dictionary column in compaction and limit case (#613)

* Modified code to handle clearing of access counts from lru cache for a column after its usage is completed

* Code Modified to handle changes by calling clear at all places wherever dictionary is getting used

* Handled clearing of access count for dictionary in case of failure while loading the dictionary in forward and reverse dictionary cache
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","19bbdbcf97491d44b6e02f4ad804336e860451a7","29","0","0","2875","248","24","3174","30","4724","847","351","7","15","3823","0","12","24","216","apache-carbondata","19bbdbcf97491d44b6e02f4ad804336e860451a7","477","20.8","5","60471","29818","5894","5","1088","47","1385","13.2","2388","35","1.7","5","123","1441","12432","10","830","1035","51","90","118","71","10696","1.2","149","447","1"
"apache-carbondata","29a281522ce719cd5a99508c1cf0bff3ca5a95a0","2016-06-08 05:46:38","[Bug] sorting will be wrong for table blocks. (#605)","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","29a281522ce719cd5a99508c1cf0bff3ca5a95a0","29","0","0","2874","248","24","3170","28","4720","851","351","7","15","3815","0","12","25","216","apache-carbondata","29a281522ce719cd5a99508c1cf0bff3ca5a95a0","477","20.8","3","60457","29808","5894","4","1091","47","1388","13.2","2387","35","1.7","5","125","1444","12419","8","860","1033","53","50","118","71","10711","1.2","149","447","1"
"apache-carbondata","f8e61ab4c651aa4552328998a0f9fa1f0ae9b63d","2016-06-08 02:14:16","Store location changes (#598)

Handled Store location as argument in code","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","f8e61ab4c651aa4552328998a0f9fa1f0ae9b63d","29","0","0","2874","248","24","3170","28","4720","851","351","7","15","3815","0","12","25","216","apache-carbondata","f8e61ab4c651aa4552328998a0f9fa1f0ae9b63d","477","20.8","3","60457","29808","5894","4","1091","47","1388","13.2","2387","35","1.7","5","125","1444","12419","8","860","1033","53","50","118","71","10711","1.2","149","447","1"
"apache-carbondata","ea3c95837c54a2b4b5c3805fe792ca3e773abed3","2016-06-07 21:43:10","[Bug] Handle clearing of access count logic for dictionary column eviction policy (#580)

Code Modified to handle changes by calling clear at all places wherever dictionary is getting used
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","ea3c95837c54a2b4b5c3805fe792ca3e773abed3","29","0","0","2871","248","24","3170","28","4718","851","351","7","15","3815","0","12","25","216","apache-carbondata","ea3c95837c54a2b4b5c3805fe792ca3e773abed3","477","20.8","3","60432","29794","5894","4","1091","47","1388","13.2","2387","35","1.7","5","125","1444","12414","8","860","1033","53","50","118","71","10711","1.2","149","447","1"
"apache-carbondata","f052859defecc50b95a7fc2c53d9d9678ffbb947","2016-06-07 20:04:05","Fixed multiple aggregation on same column issue (#601)

LGTM","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","f052859defecc50b95a7fc2c53d9d9678ffbb947","29","0","0","2883","248","24","3168","28","4720","860","351","7","15","3815","0","12","26","216","apache-carbondata","f052859defecc50b95a7fc2c53d9d9678ffbb947","478","20.7","3","60469","29805","5888","4","1090","47","1387","13.1","2385","35","1.7","5","124","1442","12413","8","830","1033","52","50","119","71","10696","1.2","149","448","1"
"apache-carbondata","1517448cf3e79caf69ee8ca1753497d59bb35bd1","2016-06-07 08:52:09","[Issue-595] Pushdown Equijoin to carbon (#596)

* Pushdown Equijoin to carbon
1. Modified CarbonDataSourceRelation to get relation size(table size)
3. Modified CarbonStrategies@canpushdown to allow pushdown in case of both table are carbontable
3. Renamed FilterPushJoin to BroadcastFilterPushJoin
4. Modified BroadcastFilterPushJoin to broadcast small table data to executors","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","1517448cf3e79caf69ee8ca1753497d59bb35bd1","29","0","0","2883","248","24","3168","28","4718","860","351","7","15","3813","0","12","26","216","apache-carbondata","1517448cf3e79caf69ee8ca1753497d59bb35bd1","478","20.7","3","60466","29802","5888","4","1088","47","1385","13.1","2385","35","1.7","5","124","1440","12409","8","830","1033","52","50","119","71","10694","1.2","149","448","1"
"apache-carbondata","404ee1d6bdf04e06c11a4b5ac6d91b9cbde004a6","2016-06-07 08:05:38","[issue-599] changes for the merge clean up. (#600)

* changes for the merge clean up.
* Added the compacted segment info in to the status file","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","404ee1d6bdf04e06c11a4b5ac6d91b9cbde004a6","29","0","0","2883","248","24","3166","28","4713","860","351","7","15","3811","0","12","26","216","apache-carbondata","404ee1d6bdf04e06c11a4b5ac6d91b9cbde004a6","478","20.7","3","60444","29788","5883","4","1088","47","1385","13.1","2384","35","1.7","5","124","1440","12402","8","830","1033","52","50","119","71","10694","1.2","149","448","1"
"apache-carbondata","fb0018f9be06210407070212840bb7bbdf4ce1e5","2016-06-06 23:26:37","[Issue-576]fix path error for windows system and optimize getPath method (#577)

* fix path error for windows system and optimize getPath method

* add test case for loading multi file

* fixed review comments
","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","fb0018f9be06210407070212840bb7bbdf4ce1e5","29","0","0","2882","248","24","3166","28","4713","860","351","7","15","3811","0","12","26","216","apache-carbondata","fb0018f9be06210407070212840bb7bbdf4ce1e5","478","20.7","3","60442","29787","5883","4","1088","47","1385","13.1","2384","35","1.7","5","124","1440","12402","8","830","1033","52","50","119","71","10694","1.2","149","448","1"
"apache-carbondata","f4a32dac00d3e384202588ea05bc6bbf98b9fad6","2016-06-06 21:57:36","[issue-543] Dataload failure 1. with single dimension column & 2. with only complex dimension (#559)

Fixed data load failure in below scenario
1. with single dimension column 
2. with only complex dimension
3. with only single no dictionary
and 
ColumnSchema invisible attribute was neither getting saved to schema nor getting read from the schema.","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","f4a32dac00d3e384202588ea05bc6bbf98b9fad6","29","0","0","2882","248","24","3166","28","4713","860","351","7","15","3811","0","12","26","216","apache-carbondata","f4a32dac00d3e384202588ea05bc6bbf98b9fad6","478","20.7","3","60434","29785","5883","4","1088","47","1385","13.1","2384","35","1.7","5","124","1440","12402","8","830","1033","52","50","119","71","10694","1.2","149","448","1"
"apache-carbondata","0072372d6896bf050ec16037328ffa63f642b377","2016-06-06 02:38:54","[ISSUE-578] data compaction new. (#571)

* Data compaction feature

* Fixed Review Comments

* // changed carboninputformat to get valid loads if it is already set otherwise it will search the status and find the valid segments.
// corrected merge problems.

* // fixing after rebase.

* correcting failing test case.

* fixing style issue after rebase .
also fixing the measure data type changes.

* // for test case correction.

* added logs for more info.

* adding logs

* //removing the static instance.

* fixing review comments.

* // fixing review comments.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","0072372d6896bf050ec16037328ffa63f642b377","29","0","0","2882","248","24","3166","28","4711","860","351","7","15","3811","0","12","26","216","apache-carbondata","0072372d6896bf050ec16037328ffa63f642b377","478","20.7","3","60426","29777","5877","4","1088","47","1385","13.1","2384","35","1.7","5","124","1440","12400","8","830","1029","52","50","119","71","10688","1.2","149","448","1"
"apache-carbondata","6c9fcd7f3e37399e72a735e39ad30b230af99534","2016-06-04 00:55:51","[Issue-556] Support for bigInt and decimal data type (#555)

* Code Modifications done:
1. Modified to support decimal datatype in data loading

* For parsing decimal type and writing precision and scale in schema file

Open points
1) Need to correct in describe to show user provided scale and precision instead of default value

* Added import

* Code Modifications done:
1. Modified to support decimal datatype in data loading

* changes done to support big decimal type

* Modified code for supporting big decimal type for measures

* regex parsing is failing if scale is 0 while loading carbontable to DatasourceRelation

* Modified code for supporting big decimal type for measures. Corrected bug for max, min and distinct count aggregators
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","6c9fcd7f3e37399e72a735e39ad30b230af99534","29","0","0","2874","248","24","3132","28","4701","854","351","7","15","3812","0","12","26","216","apache-carbondata","6c9fcd7f3e37399e72a735e39ad30b230af99534","476","20.7","3","60095","29636","5843","4","1087","47","1382","13.1","2371","35","1.7","5","124","1437","12351","8","830","1029","52","50","119","71","10650","1.2","147","446","1"
"apache-carbondata","c1c9873dfe41f123d8460fea3bc695113f882fa5","2016-06-03 23:15:45","add MemoryMappedFileHolderImpl (#457)","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","c1c9873dfe41f123d8460fea3bc695113f882fa5","27","0","0","2833","249","24","3122","31","4655","848","351","7","15","3784","0","12","26","216","apache-carbondata","c1c9873dfe41f123d8460fea3bc695113f882fa5","467","20.7","3","59552","29425","5785","4","1090","43","1386","13.2","2335","31","1.6","5","124","1441","12287","8","830","924","52","50","119","71","10627","1.2","148","437","1"
"apache-carbondata","fef01cc5dbb9ec686288ce5a44ab038754a1c4b4","2016-06-03 08:55:21","[#389] Optimized IN filter lookup while reading the forward dictionary cache. (#570)

Now doing a incremental binary search","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","fef01cc5dbb9ec686288ce5a44ab038754a1c4b4","27","0","0","2819","249","24","3118","31","4633","848","351","7","15","3774","0","12","26","216","apache-carbondata","fef01cc5dbb9ec686288ce5a44ab038754a1c4b4","466","20.8","3","59433","29340","5770","4","1088","43","1384","13.2","2325","31","1.6","5","124","1438","12254","7","825","924","51","50","119","71","10625","1.2","148","436","1"
"apache-carbondata","53aecc393372f57bc7aba880d6dee2613926bbfd","2016-06-03 02:34:42","[Issue-339] Block balance for data load (#569)

* support for uniform block distribution during dataload

* Data load distribution logic for block locality

1) Blocks load distribution based on block locality
2) Blocks size reduction to parallelize block reading by logically
splitting bigger blocks to small blocks. This will be done only, if not
sufficient blocks exists to parallelize.
Merge","refs/heads/master","g.ramana.v@gmail.com","apache-carbondata","53aecc393372f57bc7aba880d6dee2613926bbfd","27","0","0","2818","249","24","3100","30","4610","846","351","7","15","3763","0","6","26","216","apache-carbondata","53aecc393372f57bc7aba880d6dee2613926bbfd","466","20.8","3","59313","29248","5749","4","1080","43","1375","13.2","2321","31","1.6","5","123","1429","12209","7","825","924","51","50","119","71","10531","1.2","148","436","1"
"apache-carbondata","fefd225eea84fd0c3b904c6828eb1852bf4af14b","2016-06-03 00:29:33","[Performance Improvement] Data loading performance optimization (#536)

* Code Modifications done:
1. Modified code to get max cardinality of a column from dictionary cache and not read the dictionary metadata file again.
2. Removed unused code in sort step

* Modified code to move writing sort temp file in a different thread so that only one thread writes to a file and multiple threads sort the data
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","fefd225eea84fd0c3b904c6828eb1852bf4af14b","27","0","0","2817","249","24","3098","30","4605","846","351","7","15","3762","0","6","26","216","apache-carbondata","fefd225eea84fd0c3b904c6828eb1852bf4af14b","466","20.8","3","59276","29228","5744","4","1080","43","1375","13.2","2319","31","1.6","5","121","1427","12200","7","815","924","49","50","119","71","10530","1.2","148","436","1"
"apache-carbondata","9334caa1f9f02f2c83fbd07047785765b1a1f0a5","2016-06-02 22:55:32","[Issue 560] Zookeeper test case fails randomly and generates big log files under core package (#561)

* Moved large generated zookeeper log to target folder. And downgraded zookeeper to 3.4.7

* Fixed random failing bug.
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9334caa1f9f02f2c83fbd07047785765b1a1f0a5","27","0","0","2817","249","24","3098","30","4605","846","351","7","15","3762","0","6","26","216","apache-carbondata","9334caa1f9f02f2c83fbd07047785765b1a1f0a5","466","20.8","3","59276","29228","5744","4","1080","43","1375","13.2","2319","31","1.6","5","121","1427","12200","7","815","924","49","50","119","71","10530","1.2","148","436","1"
"apache-carbondata","70d4f744d9aeee7718a8c3d0ff1c2e8d74c6a997","2016-06-01 10:19:42","Redundant variables and inappropriate error messages (#554)

* modify the not proper error info

* rm not needed var
","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","70d4f744d9aeee7718a8c3d0ff1c2e8d74c6a997","27","0","0","2816","249","24","3098","30","4605","845","351","7","15","3763","0","6","26","216","apache-carbondata","70d4f744d9aeee7718a8c3d0ff1c2e8d74c6a997","465","20.8","3","59281","29233","5745","4","1081","43","1381","13.2","2317","31","1.6","5","126","1433","12203","7","815","924","49","50","119","71","10605","1.2","148","436","1"
"apache-carbondata","b11ab2b62733c004ad79ad07dfcf3fff7c2e5dd3","2016-06-01 09:57:42","[Issue 548]Fixed Carbon Core find bugs and cleaned code (#549)

* Fixed Carbon core find bugs and cleaned code

* Fixed review comments
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b11ab2b62733c004ad79ad07dfcf3fff7c2e5dd3","27","0","0","2816","249","24","3098","30","4605","845","351","7","15","3763","0","6","26","216","apache-carbondata","b11ab2b62733c004ad79ad07dfcf3fff7c2e5dd3","465","20.8","3","59281","29233","5745","4","1081","43","1381","13.2","2317","31","1.6","5","126","1433","12203","7","815","924","49","50","119","71","10605","1.2","148","436","1"
"apache-carbondata","34bd0ce65ed0cac39f393020b7de2f95d2b79e29","2016-06-01 06:01:06","add configure ""carbon.number.of.cores.block.sort"" (#497)

add configure ""carbon.number.of.cores.block.sort""","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","34bd0ce65ed0cac39f393020b7de2f95d2b79e29","28","0","0","2787","247","24","3076","31","4592","862","351","7","15","3750","0","6","34","220","apache-carbondata","34bd0ce65ed0cac39f393020b7de2f95d2b79e29","468","20.9","5","59448","29240","5695","4","1104","43","1407","13","2288","31","1.6","5","135","1468","12208","9","920","930","56","90","119","72","10829","1.2","148","439","1"
"apache-carbondata","1f3a6619bcf5960684cb28e5746c1ff3919828d8","2016-05-30 23:33:05","[Issue- 408] Data Load is failing when no measure is used in create cube command (#466)

Added check to skip the invisible column","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","1f3a6619bcf5960684cb28e5746c1ff3919828d8","28","0","0","2787","247","24","3068","31","4590","862","351","7","15","3750","0","6","34","220","apache-carbondata","1f3a6619bcf5960684cb28e5746c1ff3919828d8","468","20.9","5","59404","29213","5691","4","1104","43","1407","13","2287","31","1.6","5","135","1468","12199","9","920","930","56","90","119","72","10829","1.2","148","439","1"
"apache-carbondata","7bda5578bcbd272007c88fd0ac7b2ee0f9dc3668","2016-05-30 13:45:59","[Issue 323] Column Group Data loading and Query execution (#460)

1.column group data loading
2.Detail query execution
3.Filter query execution
merging on behalf of @Vimal-Das ","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","7bda5578bcbd272007c88fd0ac7b2ee0f9dc3668","28","0","0","2787","247","24","3068","31","4588","862","351","7","15","3750","0","6","34","220","apache-carbondata","7bda5578bcbd272007c88fd0ac7b2ee0f9dc3668","468","20.9","5","59383","29206","5691","4","1104","43","1407","13","2287","31","1.6","5","135","1468","12197","9","920","930","56","90","119","72","10829","1.2","148","439","1"
"apache-carbondata","3e10570d7ec959864d534c55f7a1dad37194767f","2016-05-30 12:30:33","[Issue 85][Issue 262][Issue 418] Pushup aggregation to spark layer and implement Record reader for CarbonInputFormat and support HadoopFSRelation (#524)

* dictionary mr generation
* Added configuration for aggregation push down
* Changes in inputformat
* Added join support
* Added dimension expression support
* Added Hadoop FS relation support
* Fixed bugs and changed design for plan optimization","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","3e10570d7ec959864d534c55f7a1dad37194767f","28","0","0","2785","247","24","3056","30","4531","860","348","7","15","3706","0","6","33","220","apache-carbondata","3e10570d7ec959864d534c55f7a1dad37194767f","467","20.9","5","59026","28998","5649","4","1094","43","1398","12.9","2275","31","1.6","5","135","1459","12085","9","920","945","56","90","119","73","10779","1.2","148","438","1"
"apache-carbondata","4ab05031cc3aa9096fa35568a5a1cb9792a84c0d","2016-05-27 22:17:10","[Issue-507] Support Range based scan for Like Filters for No_Dictionary Cols
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","4ab05031cc3aa9096fa35568a5a1cb9792a84c0d","27","0","0","2696","239","24","2982","30","4390","828","334","7","15","3562","0","6","27","216","apache-carbondata","4ab05031cc3aa9096fa35568a5a1cb9792a84c0d","453","21.1","5","57552","28142","5502","4","1052","39","1354","13","2233","27","1.5","5","135","1415","11725","9","920","843","56","90","117","72","10372","1.2","147","424","1"
"apache-carbondata","be7fe4eeadd232ea8caba90e9f3149d565df634f","2016-05-30 06:39:06","[Issue-488] load data result is not correct when there are blank lines in data (#489)

* load data with blank lines

* load data with blank lines
","refs/heads/master","zhujin2@huawei.com","apache-carbondata","be7fe4eeadd232ea8caba90e9f3149d565df634f","27","0","0","2646","227","24","2894","30","4250","818","330","7","16","3461","0","6","26","212","apache-carbondata","be7fe4eeadd232ea8caba90e9f3149d565df634f","446","21.3","5","56687","27593","5406","4","1015","33","1314","13","2196","23","1.3","5","134","1375","11530","9","920","753","56","90","117","71","10127","1.2","146","417","1"
"apache-carbondata","800f705bbac32e00f753cbc19ac4dabdb3016841","2016-05-30 05:26:56","auto identify high cardinality column in first load (#396)

* When struct data type data has more number of values then desired columns, throws indexOutOfBound (#515)

* Fix bug in UnsafeComparer.INSTANCE.compareTo(PR#523)

Fix bug "" Comparison method violates its general contract""

* auto identify high cardinality column in first load

* add test case and fix review comments

* change to new formula
","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","800f705bbac32e00f753cbc19ac4dabdb3016841","27","0","0","2646","227","24","2894","30","4250","818","330","7","16","3461","0","6","26","212","apache-carbondata","800f705bbac32e00f753cbc19ac4dabdb3016841","446","21.3","5","56683","27592","5406","4","1015","33","1314","13","2196","23","1.3","5","134","1375","11530","9","920","753","56","90","117","71","10127","1.2","146","417","1"
"apache-carbondata","da6acf48eec3862a53b05bc8890a784e824b50d3","2016-05-30 05:11:42","Fixed error "" java.lang.IllegalArgumentException: Comparison method violates its general contract! ""  when nodictionary column is present. (#525)","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","da6acf48eec3862a53b05bc8890a784e824b50d3","27","0","0","2641","227","24","2872","30","4245","818","330","7","16","3461","0","6","26","212","apache-carbondata","da6acf48eec3862a53b05bc8890a784e824b50d3","446","21.4","5","56599","27523","5398","4","1015","33","1314","12.9","2193","23","1.3","5","134","1375","11506","9","920","753","56","90","117","71","10117","1.2","146","417","1"
"apache-carbondata","aa79cb015d4d0592015eb14be09780e6942ddf8f","2016-05-29 11:45:38","[Issue - #516] findbugs fix (#519)","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","aa79cb015d4d0592015eb14be09780e6942ddf8f","27","0","0","2641","231","24","2886","30","4249","819","330","7","16","3461","0","6","26","220","apache-carbondata","aa79cb015d4d0592015eb14be09780e6942ddf8f","446","21.4","5","56648","27559","5412","4","1023","35","1322","13","2193","24","1.4","5","134","1383","11532","9","920","818","56","90","117","71","10206","1.2","146","417","1"
"apache-carbondata","081b69cbd2a12bef3426e9529d8f3ad6bb19420e","2016-05-24 22:05:11","[Issue- 479] Direct dictionary dataload failure when used with No dictionary columns (#480)","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","081b69cbd2a12bef3426e9529d8f3ad6bb19420e","28","0","0","2641","231","24","2884","30","4248","821","330","7","15","3461","0","6","26","220","apache-carbondata","081b69cbd2a12bef3426e9529d8f3ad6bb19420e","446","21.4","6","56638","27555","5411","4","1025","35","1323","13","2192","24","1.4","5","135","1386","11531","10","935","818","57","110","117","71","10219","1.2","145","417","1"
"apache-carbondata","71ec17569b5014d5ed4dea445df24a0c510670e7","2016-05-24 09:59:17","[Issue-366] Added for supporting Data Retention feature (#432)

*Supported retension feature
ex: DELETE SEGMENTS FROM TABLE TABLENAME where STARTTIME before '2016-05-10 00:00:00'
*Moved required code to SegmentStatusManager
*Refactored and removed duplicate code from existing Util class
","refs/heads/master","manohar.crazy09@gmail.com","apache-carbondata","71ec17569b5014d5ed4dea445df24a0c510670e7","28","0","0","2641","231","24","2884","30","4248","821","330","7","14","3461","0","6","26","220","apache-carbondata","71ec17569b5014d5ed4dea445df24a0c510670e7","446","21.4","6","56650","27567","5411","4","1025","35","1323","13","2192","24","1.4","5","135","1386","11531","10","935","818","57","110","117","71","10219","1.2","145","417","1"
"apache-carbondata","3f25be3d7e1d0a59bd924e5b710bceea9c93b0db","2016-05-24 08:19:43","[Bug] Complex data types data loading issue fix (#440)

fix for complex datatypes data load failing, due to data load merge sort optimization impact","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","3f25be3d7e1d0a59bd924e5b710bceea9c93b0db","28","0","0","2641","231","24","2886","30","4252","821","330","7","14","3463","0","6","26","220","apache-carbondata","3f25be3d7e1d0a59bd924e5b710bceea9c93b0db","446","21.3","6","56693","27600","5416","4","1026","35","1325","13","2193","24","1.4","5","136","1388","11548","10","935","818","57","110","117","71","10244","1.2","145","417","1"
"apache-carbondata","65becc57326de59b28fd9b10752e5d74592409f4","2016-05-24 07:30:03","[Issue #359]  Direct Surrogate Support filter handling (#469)

since the
filter value resolving mechanism is increasing the code has been re factored also for accommodating such extensions","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","65becc57326de59b28fd9b10752e5d74592409f4","28","0","0","2641","231","24","2886","30","4251","820","330","7","14","3462","0","6","26","220","apache-carbondata","65becc57326de59b28fd9b10752e5d74592409f4","446","21.3","6","56688","27596","5414","4","1025","35","1324","13","2193","24","1.4","5","136","1387","11545","10","935","818","57","110","117","71","10242","1.2","145","417","1"
"apache-carbondata","07f2b32a988155fea83eb7ce6f7562fad4ff1d8d","2016-05-23 23:58:53","Remove CarbonIterator (#413)

* refactor CarbonIterator

* rename
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","07f2b32a988155fea83eb7ce6f7562fad4ff1d8d","28","2","0","2594","231","24","2848","29","4205","810","330","7","14","3422","0","4","26","220","apache-carbondata","07f2b32a988155fea83eb7ce6f7562fad4ff1d8d","439","21.4","6","56165","27345","5376","4","1014","35","1313","13.1","2180","24","1.5","5","135","1377","11463","10","937","818","58","110","113","74","10141","1.2","144","410","1"
"apache-carbondata","cfed00ccb1da52b620dac8cde8f13e5027ff6e6a","2016-05-23 15:07:16","[Issue-359] Direct Dictionary Query Flow handling as per the latest implementation + FT Test correction (#458)","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","cfed00ccb1da52b620dac8cde8f13e5027ff6e6a","28","2","0","2592","231","24","2846","29","4205","810","330","7","14","3422","0","4","26","220","apache-carbondata","cfed00ccb1da52b620dac8cde8f13e5027ff6e6a","439","21.4","6","56165","27341","5374","4","1012","35","1311","13.1","2179","24","1.5","5","135","1375","11462","10","937","818","58","110","113","74","10137","1.2","144","410","1"
"apache-carbondata","209d94775f733258de7e97256287b4c8ca04ba0a","2016-05-23 04:13:49","[Issue-324] Data loading performance optimization (#444)

1. Enabled prefetch - code modifications done to make prefetch work according to new code
2. Moved mdkey processing code to a different thread
3. Moved copying of file from local to hdfs as soon as file is completed writing","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","209d94775f733258de7e97256287b4c8ca04ba0a","28","2","0","2592","230","24","2844","29","4200","810","330","7","15","3410","0","4","26","220","apache-carbondata","209d94775f733258de7e97256287b4c8ca04ba0a","439","21.4","6","56126","27305","5361","4","1011","35","1310","13.1","2179","24","1.5","5","135","1374","11449","10","937","818","58","110","113","74","10119","1.2","144","410","1"
"apache-carbondata","3894afe8eff176a786d500585b5ecb6913599b2f","2016-05-20 22:39:57","Merge pull request #455 from QiangCai/optimizefileholder

[Issue-324]Data loading performance optimization: optimize FileHolderImpl","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","3894afe8eff176a786d500585b5ecb6913599b2f","28","2","0","2591","230","24","2840","29","4200","810","330","7","15","3408","0","4","26","220","apache-carbondata","3894afe8eff176a786d500585b5ecb6913599b2f","439","21.4","6","56103","27292","5359","4","1011","35","1309","13.1","2178","24","1.5","5","135","1373","11445","10","937","818","58","110","113","74","10117","1.2","143","410","1"
"apache-carbondata","4d9c5c54ecd902da81341bd136600343e563b302","2016-05-20 10:38:18","Removed carbondef dependencies from carbon processing (#464)

* Removed carbondef dependencies from carbon processing
removed unused code

* Removed CarbonDef dependency

* Removed mondrian dependencies from carbon spark

* Fixed compilation issues

* Fixed style
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","4d9c5c54ecd902da81341bd136600343e563b302","28","2","0","2591","230","24","2840","29","4201","810","330","7","15","3411","0","4","26","220","apache-carbondata","4d9c5c54ecd902da81341bd136600343e563b302","439","21.4","6","56105","27294","5359","4","1011","35","1309","13.1","2178","24","1.5","5","135","1373","11446","10","937","818","58","110","113","74","10117","1.2","143","410","1"
"apache-carbondata","bfdbfa856ed0c79d53a16799c1c596f0cb8c83d7","2016-05-19 21:54:48","Cleaned Thrift Files
","refs/heads/master","vimaldas.kammath@gmail.com","apache-carbondata","bfdbfa856ed0c79d53a16799c1c596f0cb8c83d7","48","6","0","5125","476","222","6052","67","8067","1760","703","12","56","5839","0","4","89","338","apache-carbondata","bfdbfa856ed0c79d53a16799c1c596f0cb8c83d7","718","18.7","48","96168","50213","9931","4","2359","123","3854","16.6","3873","64","3","5","297","4000","21578","22","1494","2864","98","785","162","104","27380","1.8","1218","600","1"
"apache-carbondata","02afe2fc999da6b7306230fd970c7604451457f2","2016-05-19 21:18:55","optimize FileHolderImpl
","refs/heads/master","david.caiq@gmail.com","apache-carbondata","02afe2fc999da6b7306230fd970c7604451457f2","49","6","0","5246","519","271","6312","68","8464","1806","727","12","56","6012","0","4","91","354","apache-carbondata","02afe2fc999da6b7306230fd970c7604451457f2","735","18.6","48","100044","52416","10464","4","2478","127","3988","17","3989","68","3","5","304","4140","22718","27","1659","2996","104","785","166","105","28683","1.8","1226","616","1"
"apache-carbondata","bcf760939adc5a983017764f02af06041345cdb1","2016-05-19 20:39:53","[Issue-376] Code Clean Up Task (#378)

* [Issue-376] Code Clean Up Task

* [Issue-376] Code Clean Up Task
handled review comments
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","bcf760939adc5a983017764f02af06041345cdb1","48","6","0","5125","484","222","6052","67","8071","1760","703","12","56","5839","0","4","89","338","apache-carbondata","bcf760939adc5a983017764f02af06041345cdb1","718","18.7","48","96383","50389","10070","4","2362","123","3857","16.8","3877","64","3","5","297","4003","21659","22","1494","2934","98","785","162","104","27518","1.8","1218","600","1"
"apache-carbondata","1fc4c7b71286b26568c1045ac519b682205d8268","2016-05-19 20:36:24","[Issue-376] Code Clean Up Task (#381)

Checkpoint removal","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","1fc4c7b71286b26568c1045ac519b682205d8268","48","6","0","5226","513","271","6300","67","8435","1798","727","12","56","6003","0","4","91","352","apache-carbondata","1fc4c7b71286b26568c1045ac519b682205d8268","729","18.6","48","99524","52199","10417","4","2464","127","3968","17.1","3968","68","3","5","299","4115","22634","22","1509","2996","99","785","164","105","28427","1.8","1225","610","1"
"apache-carbondata","e90a40c2f31ca467e3c4ad657f29dba514ff5d92","2016-05-18 22:29:51","Update IncludeFilterExecuterImpl.java (#439)","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","e90a40c2f31ca467e3c4ad657f29dba514ff5d92","49","6","0","5246","519","271","6312","68","8465","1806","727","12","56","6015","0","4","91","354","apache-carbondata","e90a40c2f31ca467e3c4ad657f29dba514ff5d92","735","18.6","48","100046","52418","10464","4","2478","127","3988","17","3989","68","3","5","304","4140","22719","27","1659","2996","104","785","166","105","28683","1.8","1226","616","1"
"apache-carbondata","2fd9af6897b9847a9c5be5e38914004d8b00b503","2016-05-18 02:07:17","Fixed Testcase failure issue (#434)

fixed Sum(dimension column) was failing for other data type then double","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","2fd9af6897b9847a9c5be5e38914004d8b00b503","50","6","0","5248","519","271","6308","68","8461","1804","727","12","56","6006","0","4","91","354","apache-carbondata","2fd9af6897b9847a9c5be5e38914004d8b00b503","735","18.6","48","99968","52380","10451","4","2477","127","3987","17","3987","68","3","5","304","4139","22698","27","1659","2996","104","785","166","105","28679","1.8","1226","616","1"
"apache-carbondata","3fe8e08a5b3f9201eadf06101c00c9cf3f58308a","2016-05-18 02:07:00","Code Modifications done: (#433)

1. If number of blocks are less than number of nodes, then map of node vs block was empty and exception was thrown
2. Made default size of carbon file size to 1024
3. complex type primitive int columns are not parsed","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","3fe8e08a5b3f9201eadf06101c00c9cf3f58308a","50","6","0","5248","519","271","6308","68","8461","1804","727","12","56","6004","0","4","91","354","apache-carbondata","3fe8e08a5b3f9201eadf06101c00c9cf3f58308a","735","18.6","48","99968","52380","10451","4","2477","127","3987","17","3987","68","3","5","304","4139","22698","27","1659","2996","104","785","166","105","28679","1.8","1226","616","1"
"apache-carbondata","2ef6ec91680f1e57dbcdead52a471f7307eb93f8","2016-05-13 15:33:03","[Bug] force no partitioning during data load (#397)","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","2ef6ec91680f1e57dbcdead52a471f7307eb93f8","50","6","0","5248","519","271","6308","68","8461","1804","727","12","56","6004","0","4","91","354","apache-carbondata","2ef6ec91680f1e57dbcdead52a471f7307eb93f8","735","18.6","48","99968","52380","10451","4","2477","127","3987","17","3987","68","3","5","304","4139","22698","27","1659","2996","104","785","166","105","28679","1.8","1226","616","1"
"apache-carbondata","3b24829edd1b7e6729c64d0f9c2972695cf6c083","2016-05-13 08:34:05","[Bug] Issue while appending data to HDFS file

1. Issue in incremental load: If file already existed then while creating the HDFS stream exception was being thrown as append option was being treated as overwrite option.","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","3b24829edd1b7e6729c64d0f9c2972695cf6c083","50","6","0","5248","519","271","6308","68","8461","1804","727","12","56","6004","0","4","91","354","apache-carbondata","3b24829edd1b7e6729c64d0f9c2972695cf6c083","735","18.6","48","99968","52380","10451","4","2477","127","3987","17","3987","68","3","5","304","4139","22698","27","1659","2996","104","785","166","105","28677","1.8","1226","616","1"
"apache-carbondata","83c372b53556eb36752a10f558ff5a8eb43920a0","2016-05-12 09:24:56","Revert ""Revert ""Remove println in all code""""
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","83c372b53556eb36752a10f558ff5a8eb43920a0","50","6","0","5248","519","271","6308","68","8462","1805","727","12","56","6001","0","4","91","354","apache-carbondata","83c372b53556eb36752a10f558ff5a8eb43920a0","735","18.6","48","99957","52371","10449","4","2475","127","3985","17","3987","68","3","5","304","4137","22693","27","1659","2996","104","785","166","105","28657","1.8","1226","616","1"
"apache-carbondata","57b897e690490e85b0dfb9f09a453ead86c299ac","2016-05-12 09:06:58","Revert ""Remove println in all code""
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","57b897e690490e85b0dfb9f09a453ead86c299ac","50","6","0","5249","519","271","6312","68","8465","1806","727","12","56","6001","0","4","91","354","apache-carbondata","57b897e690490e85b0dfb9f09a453ead86c299ac","735","18.6","48","99965","52377","10450","4","2476","127","3986","17","3988","68","3","5","304","4138","22696","27","1659","2996","104","785","166","105","28667","1.8","1226","616","1"
"apache-carbondata","6e6c4b843bec5aacc5ec7f892599c341c9ab0006","2016-05-12 08:53:27","Merge pull request #348 from jackylk/log3

Remove println in all code","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","6e6c4b843bec5aacc5ec7f892599c341c9ab0006","50","6","0","5248","519","271","6308","68","8462","1805","727","12","56","6001","0","4","91","354","apache-carbondata","6e6c4b843bec5aacc5ec7f892599c341c9ab0006","735","18.6","48","99957","52371","10449","4","2475","127","3985","17","3987","68","3","5","304","4137","22693","27","1659","2996","104","785","166","105","28657","1.8","1226","616","1"
"apache-carbondata","54d503df7f6098c1b667205362515104748072b5","2016-05-12 01:10:52","rebase
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","54d503df7f6098c1b667205362515104748072b5","50","6","0","5248","519","271","6308","68","8462","1805","727","12","56","6001","0","4","91","354","apache-carbondata","54d503df7f6098c1b667205362515104748072b5","735","18.6","48","99957","52371","10449","4","2475","127","3985","17","3987","68","3","5","304","4137","22693","27","1659","2996","104","785","166","105","28657","1.8","1226","616","1"
"apache-carbondata","8870da3fa92e12bd01cde1ae73a597f4b4dfd740","2016-05-12 00:57:07","fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","8870da3fa92e12bd01cde1ae73a597f4b4dfd740","50","6","0","5230","513","271","6268","67","8414","1801","727","12","56","5941","0","4","91","336","apache-carbondata","8870da3fa92e12bd01cde1ae73a597f4b4dfd740","735","18.6","48","99632","52152","10382","4","2450","127","3962","16.9","3977","67","3","5","303","4114","22572","27","1659","2958","104","785","166","108","28447","1.8","1226","616","1"
"apache-carbondata","67f827f8889cbc9d0d8a3faf9c9c5ad305f29eab","2016-05-12 00:33:53","Fixed binary search logic
Fixed Detail query issue
Changed default start key value of the no dictionary column from -128 to 0
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","67f827f8889cbc9d0d8a3faf9c9c5ad305f29eab","50","6","0","5249","519","271","6312","68","8465","1806","727","12","56","6001","0","4","91","354","apache-carbondata","67f827f8889cbc9d0d8a3faf9c9c5ad305f29eab","735","18.6","48","99965","52377","10450","4","2476","127","3986","17","3988","68","3","5","304","4138","22696","27","1659","2996","104","785","166","105","28667","1.8","1226","616","1"
"apache-carbondata","d7789cb9821bc465ec0cf56285dd984a57b84577","2016-05-10 09:31:45","[Bug] Fixed local data loading issue file not found exception was coming (#368)

*Fixed local data loading issue file not found exception was coming because file path was coming with file:/ suffix
*Fixed filter query issue flyweight object (scanned result was not getting reset)
*Added min max execution true by default","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d7789cb9821bc465ec0cf56285dd984a57b84577","50","6","0","5249","519","271","6312","68","8465","1806","727","12","56","6001","0","4","91","354","apache-carbondata","d7789cb9821bc465ec0cf56285dd984a57b84577","735","18.6","48","99965","52377","10450","4","2476","127","3986","17","3988","68","3","5","304","4138","22696","27","1659","2996","104","785","166","105","28667","1.8","1226","616","1"
"apache-carbondata","49373e00bc8f51a29467a33037ac52914f4b071d","2016-05-10 09:08:51","Fixed issue regarding filter block selection in driver side. (#369)","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","49373e00bc8f51a29467a33037ac52914f4b071d","50","6","0","5249","519","271","6308","68","8465","1806","727","12","56","6001","0","4","91","354","apache-carbondata","49373e00bc8f51a29467a33037ac52914f4b071d","735","18.6","48","99946","52369","10449","4","2476","127","3986","17","3987","68","3","5","304","4138","22695","27","1659","2996","104","785","166","105","28667","1.8","1226","616","1"
"apache-carbondata","288ddc23b25b3abc6127f5521d424f83c560df23","2016-05-10 06:38:23","optimize btree lookup at driver side for non filter query (#355)","refs/heads/master","g.ramana.v@gmail.com","apache-carbondata","288ddc23b25b3abc6127f5521d424f83c560df23","50","6","0","5249","519","271","6308","68","8465","1806","727","12","56","6001","0","4","91","354","apache-carbondata","288ddc23b25b3abc6127f5521d424f83c560df23","735","18.6","48","99946","52369","10449","4","2476","127","3986","17","3987","68","3","5","304","4138","22695","27","1659","2996","104","785","166","105","28667","1.8","1226","616","1"
"apache-carbondata","cf70965cb2a2b0817203f66e20b19231a529dac2","2016-05-10 04:41:07","[Bug] consider max of block and file size for data file block size create: (#362)

1. If file size is greater than block size then block size for hdfs file should be equivalent to file size
2. Increased max limit for Block/File size to 2048 from 1000.","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","cf70965cb2a2b0817203f66e20b19231a529dac2","50","6","0","5249","519","271","6308","68","8464","1806","727","12","56","6000","0","4","91","354","apache-carbondata","cf70965cb2a2b0817203f66e20b19231a529dac2","735","18.6","48","99941","52364","10447","4","2477","127","3987","17","3987","68","3","5","304","4139","22692","27","1659","2996","104","785","166","105","28672","1.8","1226","616","1"
"apache-carbondata","fdce29164b205835ac25705552d6a37421d6ef2f","2016-05-09 09:48:34","Code modifications done: (#350)

1. code changes done to specify the block size for a file while copying data from local disk to carbon store path.
2. Modified code to create hdfs file based on file block size and copy data from local file to hdfs file.","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","fdce29164b205835ac25705552d6a37421d6ef2f","50","6","0","5249","519","271","6308","68","8464","1806","727","12","56","6000","0","4","91","354","apache-carbondata","fdce29164b205835ac25705552d6a37421d6ef2f","735","18.6","48","99940","52364","10447","4","2477","127","3988","17","3987","68","3","5","304","4140","22692","27","1659","2996","104","785","166","106","28672","1.8","1226","616","1"
"apache-carbondata","1f0ffb2c088a4691c86c7fa800cf07ec636c4969","2016-05-09 07:03:35"," filter no dictionary query optimization  (#351)

* NO_Dictionary start key and end key support for filter query performance

# Conflicts:
#	core/src/main/java/org/carbondata/core/cache/dictionary/ColumnDictionaryInfo.java
#	core/src/main/java/org/carbondata/query/filters/measurefilter/util/FilterUtil.java

* NO_Dictionary start key and end key support for filter query performance

* NO_Dictionary start key and end key support for filter query performance

* NO_Dictionary start key and end key support for filter query performance
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","1f0ffb2c088a4691c86c7fa800cf07ec636c4969","50","6","0","5248","519","271","6304","68","8458","1805","727","12","56","5998","0","4","91","354","apache-carbondata","1f0ffb2c088a4691c86c7fa800cf07ec636c4969","735","18.6","48","99921","52346","10441","4","2476","127","3987","16.9","3986","68","3","5","304","4139","22684","27","1659","2996","104","785","166","106","28667","1.8","1226","616","1"
"apache-carbondata","2dade6071ea70af4442f643b513705dd214ad0bb","2016-05-09 02:20:55","remove println
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","2dade6071ea70af4442f643b513705dd214ad0bb","50","6","0","5230","513","271","6268","67","8414","1801","727","12","57","5941","0","5","91","336","apache-carbondata","2dade6071ea70af4442f643b513705dd214ad0bb","735","18.6","48","99634","52153","10382","4","2450","127","3963","16.9","3977","67","3","5","303","4115","22572","27","1659","2958","104","785","166","108","28449","1.8","1227","616","1"
"apache-carbondata","32bc25a56f19561d973ce4a25c790134dad71ef5","2016-05-08 08:06:50","[Bug] support no dictionary column based on schema order ,(#344)

Support no dictionary column any where in the schema ,
previously it was supported only at last
1)Supported for data loading
2) supported for query execution","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","32bc25a56f19561d973ce4a25c790134dad71ef5","50","6","0","5231","513","271","6272","67","8417","1802","727","12","56","5941","0","4","91","336","apache-carbondata","32bc25a56f19561d973ce4a25c790134dad71ef5","735","18.6","48","99640","52158","10383","4","2451","127","3963","16.9","3978","67","3","5","303","4115","22575","27","1659","2958","104","785","166","108","28457","1.8","1226","616","1"
"apache-carbondata","d2c3c2887beca62b81a4f3235afe630cbf8f3c5d","2016-05-08 00:21:28","Refactor Log Service (#343)

* refactor log

* move class

* fix style
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","d2c3c2887beca62b81a4f3235afe630cbf8f3c5d","50","6","0","5231","513","271","6272","67","8417","1802","727","12","56","5941","0","4","91","336","apache-carbondata","d2c3c2887beca62b81a4f3235afe630cbf8f3c5d","735","18.6","48","99639","52156","10383","4","2451","127","3963","16.9","3978","67","3","5","303","4115","22573","27","1659","2958","104","785","166","108","28457","1.8","1226","616","1"
"apache-carbondata","2e953b9bd64e65cea35e584054f7ecbab39ab3dd","2016-05-07 09:58:37","[Bug] GC optimization during dictionary generation and dictionary load: (#342)

1. Removed conversion of arraylist to copy on write array list for every dictionary chunk getting added.
2. Removed of Array[Byte] conversion to String in global dictionary generation flow as it was causing lot of GC
3. Added a atomic reference for sort and sort reverse order references","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","2e953b9bd64e65cea35e584054f7ecbab39ab3dd","50","6","0","5238","513","272","6272","67","8416","1802","727","12","56","5948","0","4","91","336","apache-carbondata","2e953b9bd64e65cea35e584054f7ecbab39ab3dd","737","18.5","48","100008","52456","10387","4","2450","125","3955","16.8","3982","65","2.9","5","296","4107","22580","27","1659","2949","104","785","166","108","28354","1.8","1226","618","1"
"apache-carbondata","a0656293301acad271bcce64a61ee3fc45e5a868","2016-05-07 09:28:41","[Bug] Fix No dictionary feature gaps (#338)

* For No Dictionary issue fixes, also added start and end key for no dictionary.
* Added feature gaps dictionary support
* Fixed test case failure issue","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","a0656293301acad271bcce64a61ee3fc45e5a868","50","6","0","5238","513","272","6270","67","8419","1800","727","12","56","5942","0","4","91","336","apache-carbondata","a0656293301acad271bcce64a61ee3fc45e5a868","737","18.5","48","100029","52462","10387","4","2448","125","3953","16.8","3982","65","2.9","5","296","4105","22585","27","1659","2949","104","785","166","108","28352","1.8","1226","618","1"
"apache-carbondata","982e083b998acc0fb58a8d8927ed88ae2af6110d","2016-05-07 02:27:08","Fixed measure aggregation and base issue (#332)

1) Measure aggregation was not working when dimension column aggregation was present result was not coming
2) Blocklet reading from file is was not working in case of hdfs as while reading the blocklet
we need to seek till the offset that code was missing
3) updated compare logic of table block info added part number in comparison","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","982e083b998acc0fb58a8d8927ed88ae2af6110d","50","6","0","5235","513","272","6258","67","8413","1799","727","12","56","5943","0","4","91","328","apache-carbondata","982e083b998acc0fb58a8d8927ed88ae2af6110d","737","18.5","48","99963","52424","10381","4","2443","125","3950","16.8","3981","65","3","5","296","4102","22566","27","1659","2949","104","785","166","110","28348","1.8","1226","618","1"
"apache-carbondata","c9d7a50886bc9c199c8287be26bc6a2542e7280c","2016-05-06 13:53:29","[Issue-179] handling for sorting of the NO-dictionary. (#334)","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","c9d7a50886bc9c199c8287be26bc6a2542e7280c","50","6","0","5235","513","272","6264","67","8413","1799","727","12","56","5942","0","4","91","328","apache-carbondata","c9d7a50886bc9c199c8287be26bc6a2542e7280c","737","18.5","48","99991","52429","10379","4","2443","125","3949","16.8","3981","65","2.9","5","296","4101","22564","27","1659","2949","104","785","166","110","28344","1.8","1225","618","1"
"apache-carbondata","ef3e333f901061a9f64add58bac8fc43dba6905a","2016-05-06 08:59:13","[Bug] use Array[Byte] instead of string for global dictionary generation  (#329)

* use byte array to instead of string
* add write(byte[]) for CarbonDicitionaryWriter","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","ef3e333f901061a9f64add58bac8fc43dba6905a","50","6","0","5235","509","272","6250","67","8403","1797","727","12","56","5942","0","4","91","320","apache-carbondata","ef3e333f901061a9f64add58bac8fc43dba6905a","737","18.5","48","99918","52380","10362","4","2435","123","3941","16.8","3980","64","2.9","5","296","4093","22529","27","1659","2884","104","785","166","110","28255","1.8","1225","618","1"
"apache-carbondata","5f52d75ab39017bb87feb5fdccc3e336df626f93","2016-05-05 12:00:04","1)Fixed Segment level min max calculation
2) Fixed count star with other column issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","5f52d75ab39017bb87feb5fdccc3e336df626f93","50","6","0","5232","509","272","6248","67","8402","1797","727","12","56","5942","0","4","91","320","apache-carbondata","5f52d75ab39017bb87feb5fdccc3e336df626f93","737","18.5","48","99893","52375","10361","4","2435","123","3941","16.8","3978","64","2.9","5","296","4093","22528","27","1659","2884","104","785","166","110","28255","1.8","1225","618","1"
"apache-carbondata","d25c148e593596dcf594053e520cdc2d3871b6cb","2016-05-04 23:56:49","[BuG]Data file metadata converter issue throwing index out of bound issue  (#320)

* Max min creation logic was wrong array index out box bound exception
was coming as outer loop variable was used instead of inner loop
variable to get the blocklet min max
* Added carbon table in metadata","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d25c148e593596dcf594053e520cdc2d3871b6cb","50","6","0","5232","509","272","6248","67","8399","1797","727","12","56","5979","0","4","91","320","apache-carbondata","d25c148e593596dcf594053e520cdc2d3871b6cb","737","18.5","48","99902","52383","10362","4","2434","123","3940","16.8","3978","64","2.9","5","296","4092","22527","27","1659","2884","104","785","166","110","28245","1.8","1225","618","1"
"apache-carbondata","c4a31a6cb933c80abfdaa857cf35f84f649b5f26","2016-05-04 23:31:27","[Issue-308][bug] Greater than filter with non string data type failing (#309)

* Greater than filter with non string data type failing
* When data type is integer the the dictionary cache look up is having issue because of which the filters are failing.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","c4a31a6cb933c80abfdaa857cf35f84f649b5f26","50","6","0","5232","509","272","6248","67","8399","1797","727","12","56","5978","0","4","91","320","apache-carbondata","c4a31a6cb933c80abfdaa857cf35f84f649b5f26","737","18.5","48","99900","52381","10362","4","2434","123","3940","16.8","3978","64","2.9","5","296","4092","22526","27","1659","2884","104","785","166","110","28245","1.8","1225","618","1"
"apache-carbondata","0f477fd3562f999928cef22ff7e8ab196d025a07","2016-05-04 22:04:01","Carbon table was not getting loaded in (#318)

executor side in case of query execution because of this NPE
was coming while resolving the query model. ","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","0f477fd3562f999928cef22ff7e8ab196d025a07","50","6","0","5228","509","272","6242","66","8382","1796","727","12","56","5970","0","4","91","304","apache-carbondata","0f477fd3562f999928cef22ff7e8ab196d025a07","737","18.5","48","99777","52293","10336","4","2423","123","3928","16.7","3974","64","2.9","5","295","4080","22489","27","1659","2884","104","785","166","110","28191","1.8","1225","618","1"
"apache-carbondata","da3ce7784db0fcbcffc9270e30e900bf2ffe1837","2016-05-04 10:04:57","[Bug] Data file footer writing issue for huge data (#313)

* Fixed Test case failure issue and added equals and hash code method is cache type
* Fixed data loading issue 
* Data file footer writing was not proper when loading huge data
this was coming because filepath was getting updated before writing the footer
to file
* Fixed data file size check to handle when first blocklet size is more than block size
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","da3ce7784db0fcbcffc9270e30e900bf2ffe1837","50","6","0","5228","509","272","6242","66","8381","1796","727","12","56","5979","0","4","91","304","apache-carbondata","da3ce7784db0fcbcffc9270e30e900bf2ffe1837","737","18.5","48","99756","52288","10336","4","2423","123","3926","16.7","3974","64","2.9","5","295","4078","22487","27","1659","2884","104","785","166","108","28191","1.8","1225","618","1"
"apache-carbondata","47b6cbce8997cd1d064fc263ebb0beccaa5195fd","2016-05-04 06:53:56","[Issue-311] Issue while calculating carbondata file size (#312)

1. Corrected logic for calculating file size for carbon data file
2. Added configuration for providing blocklet meta reserved space in a file
Configurations:
option: carbon.blocklet.meta.size.reserved.percentage 
default: 10
option: carbon.max.file.size (in MB)
default 100","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","47b6cbce8997cd1d064fc263ebb0beccaa5195fd","50","6","0","5228","509","272","6242","66","8382","1796","727","12","56","5971","0","4","91","304","apache-carbondata","47b6cbce8997cd1d064fc263ebb0beccaa5195fd","737","18.5","48","99749","52281","10335","4","2423","123","3926","16.7","3974","64","2.9","5","295","4078","22483","27","1659","2884","104","785","166","108","28191","1.8","1225","618","1"
"apache-carbondata","9e5adf0110fe79d231b8b6988fe733912cb6434a","2016-05-04 01:57:15","Integrate Spark DataFrame.write for carbon (#75)

* fix comment

* fix comment

* fix

* fix

* fix style

* fix
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","9e5adf0110fe79d231b8b6988fe733912cb6434a","50","6","0","5227","509","272","6238","66","8382","1796","727","12","56","5971","0","4","91","304","apache-carbondata","9e5adf0110fe79d231b8b6988fe733912cb6434a","737","18.5","48","99738","52278","10335","4","2423","123","3926","16.7","3974","64","2.9","5","295","4078","22483","27","1659","2884","104","785","166","108","28191","1.8","1225","618","1"
"apache-carbondata","b77cbdc69ee661f0a8c5bfb45080f90cd69fd8b1","2016-05-03 08:32:30","[BUG]Select * Query fails (#302)

* Fixed Test case failure issue and added equals and hash code method is cache type
* Query output was not proper because of masked byte range was not sorted","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","b77cbdc69ee661f0a8c5bfb45080f90cd69fd8b1","50","6","0","5226","509","272","6238","66","8382","1796","727","12","56","5970","0","4","91","304","apache-carbondata","b77cbdc69ee661f0a8c5bfb45080f90cd69fd8b1","737","18.5","48","99709","52272","10333","4","2423","123","3926","16.7","3973","64","2.9","5","295","4078","22481","27","1659","2884","104","785","166","108","28191","1.8","1225","618","1"
"apache-carbondata","38f2949f03cbe04a3438eb0d21ddf8b864d5de15","2016-05-03 08:28:38","[Issue #288] Greater Than filter was failing,Complex type data struct… (#289)","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","38f2949f03cbe04a3438eb0d21ddf8b864d5de15","50","6","0","5226","509","272","6238","66","8382","1796","727","12","56","5970","0","4","91","304","apache-carbondata","38f2949f03cbe04a3438eb0d21ddf8b864d5de15","737","18.5","48","99708","52271","10333","4","2423","123","3926","16.7","3973","64","2.9","5","295","4078","22481","27","1659","2884","104","785","166","108","28191","1.8","1225","618","1"
"apache-carbondata","1eb9b40e4893d7df1bddbd38ee30a1ff99a65f7d","2016-05-03 03:33:25","[BUG] Concurrent query issue (#293)

* Fixed concurrent query issue.
1) Removed passing heavy objects from driver to executor in query model
2) FT test cases from functional suite will cover this scenarios","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","1eb9b40e4893d7df1bddbd38ee30a1ff99a65f7d","50","6","0","5219","509","272","6234","66","8373","1797","727","12","56","6035","0","4","92","304","apache-carbondata","1eb9b40e4893d7df1bddbd38ee30a1ff99a65f7d","736","18.5","48","99641","52257","10318","4","2426","125","3927","16.7","3961","64","2.9","5","294","4079","22471","27","1659","2916","104","785","166","107","28225","1.8","1225","617","1"
"apache-carbondata","b6ffe4b1bf06cbad8ab9717932c1bec263f23bed","2016-05-02 01:50:15","[Issue-286] Reload dictionary only if its metadata file is modified (#290)","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","b6ffe4b1bf06cbad8ab9717932c1bec263f23bed","50","6","0","5214","509","272","6232","66","8357","1799","727","12","56","5898","0","4","92","304","apache-carbondata","b6ffe4b1bf06cbad8ab9717932c1bec263f23bed","732","18.4","48","99310","52140","10310","4","2426","125","3928","16.8","3958","64","2.9","5","294","4080","22441","27","1659","2916","104","785","166","105","28240","1.8","1228","613","1"
"apache-carbondata","728da5a55b8a06f21eb3771bbc7d7f52b6666842","2016-05-02 00:00:36","[Issue-258] Column group data loading (#259)

Implemented Hybrid store data loading
Added Row block min max
","refs/heads/master","ashok.blend@gmail.com","apache-carbondata","728da5a55b8a06f21eb3771bbc7d7f52b6666842","50","6","0","5210","509","272","6224","66","8348","1796","727","12","56","5897","0","4","92","304","apache-carbondata","728da5a55b8a06f21eb3771bbc7d7f52b6666842","732","18.4","48","99209","52102","10302","4","2426","125","3927","16.8","3952","64","2.9","5","294","4079","22424","27","1659","2916","104","785","166","105","28238","1.8","1227","613","1"
"apache-carbondata","85a54659dedbbf01082b85431d4131c20f967de9","2016-05-01 23:47:21","[Issue- 271] Performance improvement data load (#272)","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","85a54659dedbbf01082b85431d4131c20f967de9","50","6","0","5233","522","272","6258","66","8362","1796","730","12","56","5932","0","4","90","304","apache-carbondata","85a54659dedbbf01082b85431d4131c20f967de9","732","18.4","48","99275","52184","10314","4","2435","121","3934","16.8","3945","62","2.9","5","294","4087","22490","28","1674","2873","105","785","166","105","28300","1.8","1225","613","1"
"apache-carbondata","a1193986259ee753f1c60b69b00f7415464e5242","2016-04-29 11:44:06","[Issue-101] Fixed Filter issue where more than one dimension is present in query and few dimension not part of the filter.
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","a1193986259ee753f1c60b69b00f7415464e5242","50","6","0","5233","522","272","6258","66","8362","1796","730","12","56","5932","0","4","90","304","apache-carbondata","a1193986259ee753f1c60b69b00f7415464e5242","732","18.4","48","99273","52183","10314","4","2435","121","3934","16.8","3945","62","2.9","5","294","4087","22490","28","1674","2873","105","785","166","105","28300","1.8","1225","613","1"
"apache-carbondata","1f6ff0effa96c58ce867524de4d6167a04c3f8de","2016-04-30 04:43:01","[BUG]Order by query fix  (#278)

* Fixed code comments

Fixed order by query issue
problem was in creating a sort info , it was selecting all the dimension when only one dimension was present the order by

* updated test cases for order by
Fixed test case failure issue
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","1f6ff0effa96c58ce867524de4d6167a04c3f8de","50","6","0","5234","522","272","6258","66","8362","1794","730","12","56","5930","0","4","90","304","apache-carbondata","1f6ff0effa96c58ce867524de4d6167a04c3f8de","732","18.4","48","99265","52175","10314","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22487","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","84f237b65b2711f5ab4cc819b11e88a22671ada7","2016-04-30 00:57:49","[Issue - 283] Fix failing dictionary cache test cases // size of LRU cache was not getting set which was causing this issue
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","84f237b65b2711f5ab4cc819b11e88a22671ada7","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","84f237b65b2711f5ab4cc819b11e88a22671ada7","732","18.4","48","99267","52176","10315","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22487","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","2c60315e15f5c6ff60114d21c1a01504de18c7e8","2016-04-29 23:31:56","[issue-267]Correcting zookeeper test (#268)

* // ZooKeeperLockingTest was failing to create 2 level directories.
// so for test case created one directory.

* correcting the zookeeper locking test case.
Multi level folder creation is not happening so the test case is failing.

* // correcting indentation

* // adding the thread sleep so that the zookeeper server will have time to get connected.

* //correcting indentation
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","2c60315e15f5c6ff60114d21c1a01504de18c7e8","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","2c60315e15f5c6ff60114d21c1a01504de18c7e8","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","4f152eec50a2e7ee1b4effa35256e69f5add04a1","2016-04-29 02:07:44","Fixed static check issues
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","4f152eec50a2e7ee1b4effa35256e69f5add04a1","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","4f152eec50a2e7ee1b4effa35256e69f5add04a1","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","2dd6e39f52a0563909498f69c112308609d0ddb0","2016-04-28 09:51:24","Rename HierarchyBtreeStore.java to HierarchyBTreeStore.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","2dd6e39f52a0563909498f69c112308609d0ddb0","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","2dd6e39f52a0563909498f69c112308609d0ddb0","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","714a659def5d13a3fdaf0b81fefbdb3d840d258e","2016-04-28 09:50:37","Rename BtreeLeafNodeIterator.java to BTreeLeafNodeIterator.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","714a659def5d13a3fdaf0b81fefbdb3d840d258e","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","714a659def5d13a3fdaf0b81fefbdb3d840d258e","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","e1cd8c3c28d9d8300a5baa2abeda5b582bafec04","2016-04-28 09:49:43","Rename BtreeDataRefNodeFinder.java to BTreeDataRefNodeFinder.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","e1cd8c3c28d9d8300a5baa2abeda5b582bafec04","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","e1cd8c3c28d9d8300a5baa2abeda5b582bafec04","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","8969c99b1603f4f4b49417e15cb0b1188bed8dc9","2016-04-28 09:48:59","Rename BlockletBtreeBuilder.java to BlockletBTreeBuilder.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","8969c99b1603f4f4b49417e15cb0b1188bed8dc9","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","8969c99b1603f4f4b49417e15cb0b1188bed8dc9","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","6ebdfc965f8e8282036d5d9573a771cddec841bf","2016-04-28 09:48:15","Rename BlockBtreeLeafNode.java to BlockBTreeLeafNode.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","6ebdfc965f8e8282036d5d9573a771cddec841bf","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","6ebdfc965f8e8282036d5d9573a771cddec841bf","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","bf344b9b25ec6697bf22ad0425514d0fa1f4f2b5","2016-04-28 09:47:24","Rename AbstractBtreeLeafNode.java to AbstractBTreeLeafNode.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","bf344b9b25ec6697bf22ad0425514d0fa1f4f2b5","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","bf344b9b25ec6697bf22ad0425514d0fa1f4f2b5","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","3c25997d3369e38a3c26d80db5ba05ea59088f61","2016-04-28 09:46:49","Rename AbstractBtreeBuilder.java to AbstractBTreeBuilder.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","3c25997d3369e38a3c26d80db5ba05ea59088f61","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","3c25997d3369e38a3c26d80db5ba05ea59088f61","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","9717a954216c58fe0e4374f06ebd14b10c8cae91","2016-04-28 09:45:25","Rename BlockBtreeBuilder.java to BlockBTreeBuilder.java","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","9717a954216c58fe0e4374f06ebd14b10c8cae91","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","9717a954216c58fe0e4374f06ebd14b10c8cae91","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","2c1e91826f4008e2ac5994f18a3435f904c64729","2016-04-28 09:43:29","fix
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","2c1e91826f4008e2ac5994f18a3435f904c64729","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","2c1e91826f4008e2ac5994f18a3435f904c64729","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","3d0d093a5cc8514e108e2584db2b4b96214f6fa4","2016-04-28 08:56:38","change LeafNode to Blocklet
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","3d0d093a5cc8514e108e2584db2b4b96214f6fa4","50","6","0","5235","522","272","6258","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","3d0d093a5cc8514e108e2584db2b4b96214f6fa4","732","18.4","48","99271","52179","10317","4","2433","121","3932","16.8","3945","62","2.9","5","294","4085","22490","28","1674","2873","105","785","166","105","28298","1.8","1225","613","1"
"apache-carbondata","d28178cd4f7b8b6fcb37974fdbd3d732d69979d7","2016-04-27 20:42:55","Fixed integration issues related to query
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","d28178cd4f7b8b6fcb37974fdbd3d732d69979d7","50","6","0","5236","522","272","6248","66","8363","1794","730","12","56","5932","0","4","90","304","apache-carbondata","d28178cd4f7b8b6fcb37974fdbd3d732d69979d7","732","18.4","48","99284","52181","10317","4","2433","121","3927","16.8","3945","62","2.9","5","294","4080","22490","28","1674","2873","105","785","166","100","28298","1.8","1225","613","1"
"apache-carbondata","421e3b644b8d89e42baf45fbb7da7fc4b224c0a7","2016-04-27 14:45:09","Fixed driver query flow

* driver query fix
* Corrected Exceptional handling in filter processing","refs/heads/master","g.ramana.v@gmail.com","apache-carbondata","421e3b644b8d89e42baf45fbb7da7fc4b224c0a7","50","6","0","5236","522","272","6242","66","8357","1790","730","12","56","5916","0","4","90","304","apache-carbondata","421e3b644b8d89e42baf45fbb7da7fc4b224c0a7","732","18.4","48","99231","52150","10313","4","2432","121","3925","16.8","3944","62","2.9","5","294","4078","22477","28","1674","2873","105","785","166","99","28288","1.8","1225","613","1"
"apache-carbondata","ca827b74d04b7c24837c8e48bd1711b4c76b85ef","2016-04-27 11:23:41","[Issue 101] FilterExpression review comments fix
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","ca827b74d04b7c24837c8e48bd1711b4c76b85ef","50","6","0","5235","522","272","6238","65","8353","1789","730","12","56","5913","0","4","90","304","apache-carbondata","ca827b74d04b7c24837c8e48bd1711b4c76b85ef","731","18.4","48","99203","52132","10308","4","2431","121","3923","16.8","3943","62","2.9","5","293","4076","22467","28","1674","2873","105","785","166","99","28248","1.8","1225","613","1"
"apache-carbondata","acee9fb71814d12c38ad4d7142f7fa1717f4fb3f","2016-04-27 10:25:42","Fixed Query Integration issue
1) fixed filter query issue as current row was not getting incremented
2) passing the length of the block form rdd to get the file footer
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","acee9fb71814d12c38ad4d7142f7fa1717f4fb3f","50","6","0","5231","522","272","6238","65","8350","1791","730","12","56","5912","0","4","90","304","apache-carbondata","acee9fb71814d12c38ad4d7142f7fa1717f4fb3f","731","18.4","48","99156","52116","10309","4","2434","121","3930","16.8","3943","62","2.9","5","291","4079","22463","28","1554","2873","101","785","166","101","28320","1.8","1225","613","1"
"apache-carbondata","be3367ac20b3fc75ab177aa4a75cb470d40eb538","2016-04-27 06:07:04","Fixed integration issue
1. Table segment index was not loading as mapped of tableblockinfo with task id was not getting created
2. Changed the logic of compare method of table block info as task id will be string previously it was considered as long
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","be3367ac20b3fc75ab177aa4a75cb470d40eb538","50","6","0","5231","515","272","6234","65","8342","1792","730","12","56","5911","0","4","90","304","apache-carbondata","be3367ac20b3fc75ab177aa4a75cb470d40eb538","731","18.4","48","99122","52095","10307","4","2434","121","3930","16.8","3943","62","2.9","5","291","4079","22453","28","1554","2873","101","785","166","101","28320","1.8","1225","613","1"
"apache-carbondata","20b78502f578902ed1f8a2c390c82159c6694a87","2016-04-26 21:25:13","Fixed Integration issue.
Query execution was failing for measure column
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","20b78502f578902ed1f8a2c390c82159c6694a87","50","6","0","5230","515","272","6230","65","8335","1792","730","12","56","5908","0","4","90","304","apache-carbondata","20b78502f578902ed1f8a2c390c82159c6694a87","731","18.4","48","99091","52073","10303","4","2433","121","3929","16.8","3942","62","2.9","5","291","4078","22439","28","1554","2873","101","785","166","101","28319","1.8","1225","613","1"
"apache-carbondata","575c1e1d3a71032b26181569a05353b49a571cf5","2016-04-25 13:01:12","removed querystats, Renamed CarbonDataRDD to CarbonQueryRDD
","refs/heads/master","ramana.gollamudi@huawei.com","apache-carbondata","575c1e1d3a71032b26181569a05353b49a571cf5","50","6","0","5230","515","272","6230","65","8336","1792","730","12","56","5902","0","4","90","304","apache-carbondata","575c1e1d3a71032b26181569a05353b49a571cf5","731","18.4","48","99087","52069","10302","4","2432","121","3928","16.8","3942","62","2.9","5","291","4077","22436","28","1554","2873","101","785","166","101","28304","1.8","1225","613","1"
"apache-carbondata","9f23e37e1839467291ba9683c3c4f3acd12c0e0b","2016-04-24 02:14:26","Supported CarbonInputFormat and Driver Query flow
","refs/heads/master","ramana.gollamudi@huawei.com","apache-carbondata","9f23e37e1839467291ba9683c3c4f3acd12c0e0b","55","8","0","5394","573","286","6396","71","8754","1836","732","12","59","6482","0","6","95","312","apache-carbondata","9f23e37e1839467291ba9683c3c4f3acd12c0e0b","744","18.1","49","102312","54348","10778","4","2573","125","4075","17.2","4036","63","2.9","5","295","4226","23638","28","1559","2931","102","805","167","101","29534","1.8","1229","625","1"
"apache-carbondata","3f8f0c4814f792b66cd1d684c97ae060bcf73374","2016-04-26 01:40:17","Fixed Integration issues
Fixed data loading and query execution issue
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","3f8f0c4814f792b66cd1d684c97ae060bcf73374","55","8","0","5390","574","287","6392","71","8752","1833","732","12","56","6491","0","4","95","312","apache-carbondata","3f8f0c4814f792b66cd1d684c97ae060bcf73374","744","18.1","49","102296","54323","10778","4","2574","125","4071","17.2","4033","63","2.9","5","295","4222","23637","28","1559","2931","102","805","167","100","29527","1.8","1225","625","1"
"apache-carbondata","83083ddac7a6f92422d45e8e713e229e2952554b","2016-04-26 06:57:24","[Issue #101] handled review comments, also added the carbon column interface for filter expression
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","83083ddac7a6f92422d45e8e713e229e2952554b","57","8","0","5388","571","287","6368","69","8743","1827","730","12","56","6530","0","4","96","312","apache-carbondata","83083ddac7a6f92422d45e8e713e229e2952554b","744","18.1","48","102180","54230","10759","4","2565","127","4047","17.2","4029","63","2.9","5","287","4198","23573","29","1574","2997","103","795","167","92","29432","1.8","1225","625","1"
"apache-carbondata","43310412377efee74f28865715677302d67b13df","2016-04-25 12:21:06","[issue 101] updated the interface and refactored the code
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","43310412377efee74f28865715677302d67b13df","57","8","0","5398","568","287","6368","69","8734","1825","730","12","56","6524","0","4","96","312","apache-carbondata","43310412377efee74f28865715677302d67b13df","744","17.9","48","101874","54137","10728","4","2558","124","4040","17.2","4028","63","2.8","5","287","4192","23533","30","1584","2893","104","795","167","93","29308","1.8","1224","625","1"
"apache-carbondata","0fb0d61cf511e2a9715fc562ad263c666693eace","2016-04-25 05:24:13","Deleted unused evaluator classes related to filters
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","0fb0d61cf511e2a9715fc562ad263c666693eace","57","8","0","5401","568","287","6368","69","8734","1824","730","12","56","6518","0","4","96","312","apache-carbondata","0fb0d61cf511e2a9715fc562ad263c666693eace","744","17.9","48","101910","54156","10743","4","2560","124","4045","17.2","4035","63","2.8","5","287","4197","23538","30","1584","2893","104","795","167","96","29317","1.8","1224","625","1"
"apache-carbondata","918e4d2221245d3c9a4f7d6df805da522d38ed86","2016-04-25 03:46:19","[Issue 101] FilterExpression support
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","918e4d2221245d3c9a4f7d6df805da522d38ed86","57","12","0","5504","604","287","6472","69","8988","1864","730","12","56","6969","0","4","115","314","apache-carbondata","918e4d2221245d3c9a4f7d6df805da522d38ed86","758","17.8","48","103508","55225","10952","4","2646","130","4141","17.1","4097","67","2.9","5","287","4293","24004","30","1584","3009","104","795","170","104","30205","1.8","1226","639","1"
"apache-carbondata","b8220e52f0e6dbcc398b7b3f33ec36e0c7180d5e","2016-04-20 10:43:06","[Issue 101] FilterExpression support
","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","b8220e52f0e6dbcc398b7b3f33ec36e0c7180d5e","57","12","0","5523","606","287","6472","69","8988","1865","730","12","65","6969","0","13","115","314","apache-carbondata","b8220e52f0e6dbcc398b7b3f33ec36e0c7180d5e","758","17.9","48","103931","55459","10952","4","2655","130","4157","17.1","4097","67","2.9","5","288","4310","24002","30","1589","3017","105","795","170","106","30272","1.8","1231","639","1"
"apache-carbondata","65d762e1c3b6f1fe9822de843ba7c7fa5e69f76e","2016-04-24 05:49:18","Added method to get complete chunk/DimensionColumnDataChunk.java
This method will be used in case of filter query to get the complete data chunk and apply filter
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","65d762e1c3b6f1fe9822de843ba7c7fa5e69f76e","53","4","0","5319","586","287","6290","69","8726","1824","726","12","56","6848","0","4","95","310","apache-carbondata","65d762e1c3b6f1fe9822de843ba7c7fa5e69f76e","741","17.8","48","101419","54020","10727","4","2536","114","4009","17.2","4003","59","2.7","5","287","4160","23538","30","1582","2721","103","795","168","83","29080","1.8","1224","622","1"
"apache-carbondata","3caea4cc5edc3587aa7adeb2f6fbe1d86e8adf93","2016-04-23 11:59:11","Added to code for query execution
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","3caea4cc5edc3587aa7adeb2f6fbe1d86e8adf93","53","4","0","5319","586","287","6290","69","8726","1824","724","12","56","6848","0","4","95","310","apache-carbondata","3caea4cc5edc3587aa7adeb2f6fbe1d86e8adf93","741","17.8","48","101381","54010","10727","4","2536","114","4009","17.2","4002","59","2.7","5","287","4160","23535","30","1582","2721","103","795","168","83","29080","1.8","1224","622","1"
"apache-carbondata","b5cf108f09833a957f37cf23a15b119e869d0dfe","2016-04-23 11:52:10","Added code for query execution
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","b5cf108f09833a957f37cf23a15b119e869d0dfe","53","4","0","5319","586","287","6292","69","8730","1825","724","12","56","6854","0","4","95","310","apache-carbondata","b5cf108f09833a957f37cf23a15b119e869d0dfe","741","17.8","48","101425","54051","10736","4","2538","119","4011","17.3","4003","60","2.8","5","288","4163","23560","30","1597","2807","104","795","168","83","29155","1.8","1224","622","1"
"apache-carbondata","9696fa6b3dac5820a1629f796e8afb49bb665290","2016-04-23 05:22:37","Fixed formatting issue
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","9696fa6b3dac5820a1629f796e8afb49bb665290","52","4","0","5326","588","287","6288","69","8727","1827","724","12","56","6852","0","4","95","312","apache-carbondata","9696fa6b3dac5820a1629f796e8afb49bb665290","740","17.7","48","101007","54003","10728","4","2541","116","4014","17.3","3999","60","2.7","5","287","4164","23545","29","1567","2771","102","795","164","83","29155","1.8","1224","621","1"
"apache-carbondata","a2f040a0de1e6fac6c4b3d290bba0253bc9b9166","2016-04-23 04:23:31","added query execution code
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","a2f040a0de1e6fac6c4b3d290bba0253bc9b9166","52","6","0","5332","588","287","6288","69","8727","1827","724","12","68","6852","0","16","95","312","apache-carbondata","a2f040a0de1e6fac6c4b3d290bba0253bc9b9166","740","17.8","48","101881","54683","10728","4","2543","116","4028","17.3","3999","60","2.7","5","287","4178","23545","29","1567","2793","102","795","164","83","29189","1.8","1236","621","1"
"apache-carbondata","c70e77594f3304fc5e2b1d07318ca571b09f3c6d","2016-04-25 23:39:51","[Issue-212] [Improvement] Remove the isSharedDictionary flag from the carbon dictionary reader and writer #212 (#216)","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","c70e77594f3304fc5e2b1d07318ca571b09f3c6d","52","4","0","5115","546","286","5788","67","8242","1694","682","12","53","6153","0","0","90","306","apache-carbondata","c70e77594f3304fc5e2b1d07318ca571b09f3c6d","678","17.1","48","93337","50329","10092","4","2387","83","3837","18","3776","37","2.1","5","285","3983","22110","28","1502","1982","98","795","146","64","27408","1.8","1219","560","1"
"apache-carbondata","769f6ec98ef0ddb91f7775cd67026833e85f6469","2016-04-25 23:10:56","[Issue-233] Make carbon file format appendable (#238)

* make carbon appendable in file format
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","769f6ec98ef0ddb91f7775cd67026833e85f6469","52","4","0","5120","546","286","5802","67","8259","1701","682","12","53","6157","0","0","91","306","apache-carbondata","769f6ec98ef0ddb91f7775cd67026833e85f6469","679","17.1","48","93508","50410","10100","4","2389","83","3839","18","3779","37","2.1","5","285","3985","22137","28","1502","1982","98","795","146","64","27443","1.8","1219","561","1"
"apache-carbondata","f2084c2d5890c36d3b0e8f5634f08481d7a019be","2016-04-25 22:13:12","[Issue-254] Cache should throw exception in case data is not loaded to memory (#255)","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","f2084c2d5890c36d3b0e8f5634f08481d7a019be","52","4","0","5110","546","286","5818","67","8265","1698","678","12","53","6145","0","1","91","304","apache-carbondata","f2084c2d5890c36d3b0e8f5634f08481d7a019be","679","17.1","48","93529","50421","10096","4","2394","87","3848","18","3773","41","2.3","5","285","3994","22167","28","1502","2154","98","795","146","65","27580","1.8","1222","561","1"
"apache-carbondata","27eda51c24bedd22601fb2b54270bda2323296bc","2016-04-25 10:26:01","Rename FileMeta to FileFooter (#237)

* Rename FileMeta to FileFooter

* fix

* fix comment
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","27eda51c24bedd22601fb2b54270bda2323296bc","52","4","0","5095","546","286","5822","67","8257","1691","678","12","53","6141","0","1","90","304","apache-carbondata","27eda51c24bedd22601fb2b54270bda2323296bc","679","17.2","48","93484","50380","10084","4","2387","85","3837","18","3773","39","2.3","5","281","3981","22151","28","1472","2114","96","795","146","65","27471","1.8","1220","561","1"
"apache-carbondata","66bbf0a7b403df9731716de9426e9e2a52c93b31","2016-04-23 09:15:55","[Issue-232] Issue in incremental data load (#234)","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","66bbf0a7b403df9731716de9426e9e2a52c93b31","52","4","0","5095","546","286","5834","67","8257","1691","678","12","53","6141","0","1","90","304","apache-carbondata","66bbf0a7b403df9731716de9426e9e2a52c93b31","679","17.2","48","93484","50380","10084","4","2387","85","3837","18","3773","39","2.3","5","281","3981","22151","28","1472","2114","96","795","146","65","27471","1.8","1220","561","1"
"apache-carbondata","3f68ec33e3a34df33e763612c3f39e1b90bc7ff2","2016-04-23 06:54:19"," [Issue-235] Complex dimension data load support (#236)","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","3f68ec33e3a34df33e763612c3f39e1b90bc7ff2","52","4","0","5095","546","286","5834","67","8259","1691","678","12","53","6142","0","1","90","304","apache-carbondata","3f68ec33e3a34df33e763612c3f39e1b90bc7ff2","679","17.2","48","93477","50373","10080","4","2387","85","3837","18","3773","39","2.3","5","281","3981","22147","28","1472","2114","96","795","146","65","27471","1.8","1220","561","1"
"apache-carbondata","787230fadc333de54d02e62b09b96bde50995ca5","2016-04-23 05:55:14","[Issue-96]Query Interface for query execution (#223)

* Query Interface for query execution
* Updated iterator to CarbonIterator as in java 7 If we implement Iterator interface we need to implement remove method and in our this is not required
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","787230fadc333de54d02e62b09b96bde50995ca5","52","4","0","5095","546","286","5834","67","8259","1691","678","12","53","6142","0","1","90","304","apache-carbondata","787230fadc333de54d02e62b09b96bde50995ca5","679","17.2","48","93477","50373","10080","4","2387","85","3837","18","3773","39","2.3","5","281","3981","22147","28","1472","2114","96","795","146","65","27471","1.8","1220","561","1"
"apache-carbondata","b30c164cac0830f6dc0fdd8ccc685c34cfc7f9a4","2016-04-23 05:30:55","[issue-92]support dataload should be configurable to start data loading from Phase1 or 2 (#171)

* support multiple partitions by using table split,and process partition data by blocks

* set the new configuration about is enable table split

* restucture and modify according comments
1.restucture CarbonDataLoadRDD
2.change return empty array instead of null in splitsutil

* format the code style

* support dataload in folder which will skip no csv format file.

* fix checkstyle error

* modify using asScala instead of asInstanceOf

* add partition process

* modify the path to handle different senarios

* remove the replace string and format code

* modify the carbon example

* modify comments,remove blocks id comment
","refs/heads/master","linyixin@huawei.com","apache-carbondata","b30c164cac0830f6dc0fdd8ccc685c34cfc7f9a4","52","4","0","5069","545","286","5812","67","8225","1691","676","12","53","6141","0","1","90","298","apache-carbondata","b30c164cac0830f6dc0fdd8ccc685c34cfc7f9a4","673","17.1","48","92734","50080","10058","4","2372","79","3821","18.1","3762","33","2","5","281","3965","22065","28","1472","1859","96","795","142","65","27314","1.8","1219","555","1"
"apache-carbondata","01ae9567e2731e7dcddb4d910fe31b95912205a9","2016-04-23 01:12:40","[Issue-96] Fixed build failure issue . (#226)

Problem was using putIfAbsent method which is not supported in 1.7","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","01ae9567e2731e7dcddb4d910fe31b95912205a9","52","4","0","5069","545","286","5808","67","8225","1691","676","12","53","6141","0","1","90","298","apache-carbondata","01ae9567e2731e7dcddb4d910fe31b95912205a9","673","17.1","48","92723","50078","10058","4","2372","79","3821","18.1","3762","33","2","5","281","3965","22065","28","1472","1859","96","795","142","65","27314","1.8","1219","555","1"
"apache-carbondata","607d3ef512430ab3b828ffedebfa3fb6b161977c","2016-04-22 11:05:15","Btree loading feature for new file format (#162)

* Index and min max Reading from the thrift

* WIP-Query execution and Btree loading in new structure

* Coded added for Btree loading based on new structure
Added
1)Reading of thrift file
2) Added Btree creation for both driver and executor
3) Added code for searching in Btree

* Btree Loading With New File Structure
1)Added code to load btree in executor side
2) Added code to load Btree in driver side
3) Added code to search Node in BTree
4) Added code for reading the data chunk from file
4) After Query execution we can remove all the old classes
5) Added test cases

* Fixed Review comments

* Fixed review comments

* Fixed Review Comments
1) Changed the name of the BtreeInterface and its implementation
2)Added Test case

| Btree Builder
		get will return DataRefNode
		| BlockBtreeBuilder
		| BlockletBtreeBuilder
	| DataRefNode
	| BtreeNode

		|BtreeNonLeafNode
		| AbstractLeafNode(Implements, DataRefNodeand BtreenNode)
		| BlockLeafNode
		| BlockletLeafNode
       |DataRefNodeFinder)(BtreNode,) will return DataRefNode

* Fixed review comments
Updated test case
Re factored classes

* added Utility for test classes

* Formatted code with new formatter

* formatted code with new formatter

* Fixed review comments
Formatted codes with new formatter

* Fixed Code formatting and checkstyle issues
","refs/heads/master","kumarvishal.1802@gmail.com","apache-carbondata","607d3ef512430ab3b828ffedebfa3fb6b161977c","52","4","0","5069","545","286","5808","67","8225","1691","676","12","53","6141","0","1","90","298","apache-carbondata","607d3ef512430ab3b828ffedebfa3fb6b161977c","673","17.1","48","92719","50074","10056","4","2372","79","3821","18.1","3762","33","2","5","281","3965","22063","28","1472","1859","96","795","142","65","27314","1.8","1219","555","1"
"apache-carbondata","b424cddc6fcfadfb75d4acb451d577dcb45d379a","2016-04-22 05:48:33","[Issue-153] Support Direct Dictionary for TimeStamp (#154)

1. No dictinary generation for the timeStamp and date type
 2. The timestamp (long) is converted to the int type before writing to the segnment
 3. While reading from the segment the int will be converted to the actual value.
 4. Added UT.","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","b424cddc6fcfadfb75d4acb451d577dcb45d379a","52","4","0","4977","531","285","5566","67","7893","1615","639","12","53","5841","0","0","86","294","apache-carbondata","b424cddc6fcfadfb75d4acb451d577dcb45d379a","632","16.2","48","87218","47743","9621","4","2263","64","3701","18.7","3593","23","1.7","5","280","3844","21024","27","1462","1474","95","795","131","63","26276","1.8","1211","514","1"
"apache-carbondata","9d825b11c023c65b7eceb003da404b27af17dac8","2016-04-22 05:42:55","[Issue-190]dict generation support complex datatype and load csv file without header (#193)

* global dictionary generation support complex data type and  load csv file without header
* read global dictionary from cache during global dictionary generation
","refs/heads/master","QiangCai@users.noreply.github.com","apache-carbondata","9d825b11c023c65b7eceb003da404b27af17dac8","52","4","0","4964","531","284","5548","67","7879","1609","639","12","53","5814","0","0","84","294","apache-carbondata","9d825b11c023c65b7eceb003da404b27af17dac8","627","16.2","46","86740","47536","9582","4","2255","64","3689","18.8","3582","23","1.7","5","278","3830","20944","27","1462","1474","95","755","129","62","26170","1.8","1208","509","1"
"apache-carbondata","c2f0d0896544f62df009f8be2b75bc0311f428c2","2016-04-21 05:14:47","rebase
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","c2f0d0896544f62df009f8be2b75bc0311f428c2","52","4","0","4964","531","284","5548","67","7878","1609","639","12","53","5811","0","0","84","294","apache-carbondata","c2f0d0896544f62df009f8be2b75bc0311f428c2","627","16.2","46","86705","47518","9571","4","2255","64","3688","18.8","3579","23","1.7","5","278","3829","20937","27","1462","1474","95","755","129","62","26168","1.8","1207","509","1"
"apache-carbondata","dd5b7cd13ba098e45e13fc2ff85188793c39aaa6","2016-04-21 05:08:10","rebase continue
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","dd5b7cd13ba098e45e13fc2ff85188793c39aaa6","52","4","0","4964","531","284","5548","67","7878","1609","639","12","53","5811","0","0","84","294","apache-carbondata","dd5b7cd13ba098e45e13fc2ff85188793c39aaa6","627","16.2","46","86706","47519","9571","4","2255","64","3688","18.8","3579","23","1.7","5","278","3829","20937","27","1462","1474","95","755","129","62","26168","1.8","1207","509","1"
"apache-carbondata","819dbdf3b04a2d056f3982c05fe1d5bbf0499386","2016-04-21 04:29:48","rebase
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","819dbdf3b04a2d056f3982c05fe1d5bbf0499386","52","4","0","4960","531","284","5542","67","7838","1602","639","12","53","5791","0","0","84","294","apache-carbondata","819dbdf3b04a2d056f3982c05fe1d5bbf0499386","626","16.1","46","86684","47350","9534","4","2243","64","3676","18.7","3565","23","1.7","5","276","3815","20857","27","1402","1474","93","755","129","62","26077","1.8","1207","509","1"
"apache-carbondata","0bcf6bcbd2b7ca753978b3e6eb6c2c0050522408","2016-04-21 01:52:03","[Issue-198] Not able to load the data in HDFS cluster also removed loading of b-tree after data load complete operation (#200)","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","0bcf6bcbd2b7ca753978b3e6eb6c2c0050522408","52","8","0","4959","531","284","5552","67","7877","1608","639","13","53","5813","0","0","84","294","apache-carbondata","0bcf6bcbd2b7ca753978b3e6eb6c2c0050522408","625","16.2","46","86675","47514","9573","4","2257","66","3690","18.9","3581","25","1.7","5","278","3831","20942","27","1462","1512","95","755","129","62","26217","1.8","1207","507","1"
"apache-carbondata","83fb9eecbe965906dcf6dcfe021cc73b662ac362","2016-04-20 21:37:50","[Issue-102] Reformat Java code based on code style (#192)

* reformat carbon-core

* reformat all java
","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","83fb9eecbe965906dcf6dcfe021cc73b662ac362","52","8","0","4959","531","284","5552","67","7877","1610","639","13","53","5813","0","0","84","294","apache-carbondata","83fb9eecbe965906dcf6dcfe021cc73b662ac362","625","16.2","46","86675","47514","9573","4","2257","66","3690","18.9","3581","25","1.7","5","278","3831","20942","27","1462","1512","95","755","129","62","26217","1.8","1207","507","1"
"apache-carbondata","6ed9348eb26ab1543873c80e9687434ef6bd640c","2016-04-20 07:35:25","[Issue-187] Describe command & describe formatted ddl support (#188)

* Complex Type Support
1) Describe command & describe formatted command is fixed to show primitive and complex data types
2) Changed Children parsing based on new list of child Dimension under parent dimension.
3) Added Number of child dims count as per child count in schema thrift
3) Fixed bug in CarbonTable","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","6ed9348eb26ab1543873c80e9687434ef6bd640c","52","8","0","5722","534","284","5558","67","7877","1604","639","71","70","5806","0","6","84","294","apache-carbondata","6ed9348eb26ab1543873c80e9687434ef6bd640c","625","22.2","46","93664","48965","9577","4","3026","66","4490","18.9","3583","25","1.7","5","278","4631","20947","27","1462","1591","95","755","129","66","30186","2.1","1234","507","1"
"apache-carbondata","f64971f38e00507ba4dd3dfc98312f6ff642bfad","2016-04-20 00:37:25","[ISSUE-100][ISSUE-88] DDL changes for create carbon table (#168)

// DDL Changes for create Cube.
// using the hive parser for create cube DDL.","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","f64971f38e00507ba4dd3dfc98312f6ff642bfad","52","12","0","5722","534","284","5558","67","7874","1604","639","72","70","5806","0","6","84","294","apache-carbondata","f64971f38e00507ba4dd3dfc98312f6ff642bfad","625","22.2","46","93646","48953","9570","4","3026","66","4490","18.9","3582","25","1.7","5","278","4631","20941","27","1462","1591","95","755","129","66","30137","2.1","1234","507","1"
"apache-carbondata","eb978ef01e6f888f1dce1662c7062ee1ade1bd1a","2016-04-19 21:44:14","[Issue-172] Support Global Dictionary Sort Info generation & writting + thrif format (#175)

Preparing the column sort info for global dictionary and write the same in thrift format","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","eb978ef01e6f888f1dce1662c7062ee1ade1bd1a","52","12","0","5720","534","284","5558","67","7873","1604","639","72","70","5804","0","6","84","294","apache-carbondata","eb978ef01e6f888f1dce1662c7062ee1ade1bd1a","625","22.2","46","93623","48950","9569","4","3026","66","4490","18.9","3581","25","1.7","5","278","4631","20940","27","1462","1591","95","755","129","66","30137","2.1","1234","507","1"
"apache-carbondata","db1fa121a5ab54a550b14cd23e76bd563c463a5c","2016-04-19 18:50:23","[Issue 174] change rowgroup to columngroup (#186)

* change rowgroup to columngroup","refs/heads/master","jacky.likun@huawei.com","apache-carbondata","db1fa121a5ab54a550b14cd23e76bd563c463a5c","52","12","0","5706","534","284","5558","67","7866","1602","639","72","67","5801","0","3","84","292","apache-carbondata","db1fa121a5ab54a550b14cd23e76bd563c463a5c","624","22.1","46","93441","48900","9559","4","3024","66","4484","18.9","3573","25","1.7","5","278","4625","20921","27","1462","1591","95","755","129","66","30123","2.1","1230","506","1"
"apache-carbondata","01a824ef07cd2fdd70ed877aab632a760cbf1bb1","2016-04-19 02:26:40","[Issue-93] support new directory structure (#164)","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","01a824ef07cd2fdd70ed877aab632a760cbf1bb1","52","12","0","5706","534","284","5558","67","7866","1602","639","72","67","5801","0","3","84","292","apache-carbondata","01a824ef07cd2fdd70ed877aab632a760cbf1bb1","624","22.1","46","93441","48900","9559","4","3024","66","4484","18.9","3573","25","1.7","5","278","4625","20921","27","1462","1591","95","755","129","66","30123","2.1","1230","506","1"
"apache-carbondata","0d824545cfe5cad29f97b28289515d3f29d852ba","2016-04-18 07:26:47","use global dic and LRU to load data (#167)

Use global dic and LRU to load data","refs/heads/master","zhangshunyu@huawei.com","apache-carbondata","0d824545cfe5cad29f97b28289515d3f29d852ba","52","12","0","5706","535","284","5560","67","7864","1602","639","72","66","5793","0","2","83","292","apache-carbondata","0d824545cfe5cad29f97b28289515d3f29d852ba","624","22.1","46","93442","48909","9559","4","3023","66","4482","18.9","3571","25","1.7","5","278","4623","20923","27","1462","1591","95","755","129","66","30116","2.1","1229","506","1"
"apache-carbondata","9ba82caa468b3b4a3dc5bcdcf9486e48aba292ce","2016-04-18 07:11:00","[Issue-96] support sort index loading in memory and query using sort index (#166)

1. Added code to support dictionary value look up using sort order index and inverted index
2. Added code for loading sort index file in LRU cache ","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","9ba82caa468b3b4a3dc5bcdcf9486e48aba292ce","52","12","0","5721","541","284","5576","67","7907","1607","639","72","66","5818","0","2","84","292","apache-carbondata","9ba82caa468b3b4a3dc5bcdcf9486e48aba292ce","625","22.1","46","93877","49171","9610","4","3036","70","4496","19","3582","27","1.8","5","279","4637","21055","27","1462","1684","95","755","129","66","30296","2.1","1229","507","1"
"apache-carbondata","f568393a649cbe1a08a3cd3dc27204138dceaf0c","2016-04-18 06:11:26","[Issue-93] support new directory structure (#170)

1) Removed schemas folder and store folder(metadata file path will be read from CarbonTablePath & store path will be same as old except hardcoded parent store folder is removed).
2) Changed TableMeta to use CarbonTableIdentifier instead of schemaName and cubeName.
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","f568393a649cbe1a08a3cd3dc27204138dceaf0c","52","12","0","5719","541","284","5564","67","7886","1601","639","72","66","5811","0","2","84","292","apache-carbondata","f568393a649cbe1a08a3cd3dc27204138dceaf0c","625","22","46","93695","49091","9591","4","3036","70","4495","18.9","3573","27","1.8","5","279","4636","21017","27","1462","1684","95","755","129","66","30294","2.1","1228","507","1"
"apache-carbondata","cc1298fa7eeb25495ebed05f2cc1a15623f135ab","2016-04-15 07:09:47","[Issues158] Create and data load failing issue (#159)

* Fixed below issues
1) Datatype mismatch while dropping cube with integer & timestamp - Made Datatype same as Hive in schema thrift & converter object
2) Object serialization fails for carbonLoad model which will be sent from driver to executor - This is because scala set is used instead of java set.

* Changing LeafNode to Blocklet in Carbondata.thrift and CarbonMetadataUtil

* GlobalDictionaryUtilTestCase.scala is fixed to pass denormalized scenario.
Normalized scenario needs to be corrected after preparing new DimensionRelation model.
","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","cc1298fa7eeb25495ebed05f2cc1a15623f135ab","52","12","0","5718","541","284","5564","67","7886","1601","639","72","66","5811","0","2","84","292","apache-carbondata","cc1298fa7eeb25495ebed05f2cc1a15623f135ab","625","22","46","93680","49084","9589","4","3036","70","4495","18.9","3571","27","1.8","5","279","4636","21015","27","1462","1684","95","755","129","66","30294","2.1","1228","507","1"
"apache-carbondata","41b93c968c00d1ea5684ca9ccc368788ac8cfa2e","2016-04-15 01:58:51","[Issue-79]Handle block read in data loading & combine blocks in node level (#134)

* 1.use csvinput to handle file block;2.use newHadoopRDD to get file splits;3.use DummyRDD to combine one node blocks;4.use LoadRDD to handle one node blocks and pass to kettle;5.this is no parition concept,so partition id always one.

* add blockID in dataloadModel.java

* handle big size file to process multiple block by multiple thread

* handle multiple thread in csvinput to process multiple blocks

* remove CarbonLoadRDD and modify CarbonDataLoadRDD

* move CarbonLoadPartition position

* remove the thread name in blockdetails

* use uuid to generate unique block id

* add some describe to class or function,format codes and remove unless codes

* add describe,delete getAllFileWithNoPartition

* fix last inputstream no close issue

* fix bugs in using empty data info in BlockDataHandler
","refs/heads/master","linyixin@huawei.com","apache-carbondata","41b93c968c00d1ea5684ca9ccc368788ac8cfa2e","52","12","0","5718","541","284","5564","67","7886","1601","639","72","66","5811","0","2","84","292","apache-carbondata","41b93c968c00d1ea5684ca9ccc368788ac8cfa2e","625","22","46","93681","49084","9589","4","3036","70","4495","18.9","3571","27","1.8","5","279","4636","21015","27","1462","1684","95","755","129","66","30294","2.1","1228","507","1"
"apache-carbondata","f61349256917aa95d7fdc17282ee05bd9da52347","2016-04-14 21:54:28","[Issue-152] Bug fix Carbon Metadata reading/writing in thrift format (#156)","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","f61349256917aa95d7fdc17282ee05bd9da52347","52","12","0","5707","541","284","5560","67","7876","1599","639","72","66","5807","0","2","84","292","apache-carbondata","f61349256917aa95d7fdc17282ee05bd9da52347","624","22","46","93587","49038","9584","4","3034","70","4492","18.9","3570","27","1.8","5","279","4633","20995","27","1462","1684","95","755","129","66","30279","2.1","1227","506","1"
"apache-carbondata","aa2809ae40505fdc34fb1b6293efbb077e652c40","2016-04-14 11:51:10","[Issue-93] CarbonData Directory & Fileformat (#121)

Carbon Data Sort Index File Merging (one sortIndex for each column in a table)
 Carbon Dictionary SortIndex writer will be used while data loading to write the sortedIndex data for each column of a table
 Carbon Dictionary SortIndex reader will be used while querying to read the sortIndex and sortIndexInverted data for each column of a table.
 The dictionary data sortedIndex and sortedIndexInverted will be stored in the thrift format.

 Dictionary sort Index file Name format
1. If created inside shared directory
columnName_dictionary.sortindex
2. If created inside table metadata folder
tableName_columnName_dictionary.sortindex

Dictionary sort index File Format
Data will be written as list of i32

Modified the read and write interface as per the review comments
removed the sortindex file got checkined by mistake","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","aa2809ae40505fdc34fb1b6293efbb077e652c40","52","12","0","5707","541","284","5564","67","7875","1599","639","72","66","5800","0","2","84","292","apache-carbondata","aa2809ae40505fdc34fb1b6293efbb077e652c40","624","22","46","93586","49037","9583","4","3036","70","4494","18.9","3570","27","1.8","5","279","4635","20995","27","1462","1684","95","755","129","66","30309","2.1","1227","506","1"
"apache-carbondata","5cd85f68fb3af856d2c471b6765df406a1e3e5d7","2016-04-14 09:22:12","[Issue-146] Create cube and load data using thrift object (#149)



Create and drop cube using Thrift Object.
Populated CarbonTable using Thrift Schema and Created CarbonDataLoadSchema Object which will be used in data load Flow.

Open Points
1) Star Schema population should be supported from Load DDL Command
2) Query Flow to be corrected to use New CarbonTable Schema
3) Aggregate Table, Retention & Restructure should be correct using New CarbonTable Schema.","refs/heads/master","prnaresh.naresh@gmail.com","apache-carbondata","5cd85f68fb3af856d2c471b6765df406a1e3e5d7","52","12","0","5695","541","284","5546","67","7866","1590","639","72","66","5797","0","2","80","292","apache-carbondata","5cd85f68fb3af856d2c471b6765df406a1e3e5d7","620","22","46","93088","48852","9553","4","3036","70","4494","19","3553","27","1.8","5","279","4635","20938","27","1462","1684","95","755","127","66","30309","2.1","1227","502","1"
"apache-carbondata","466533f157984166f17b41817450d73fb1eddb35","2016-04-14 02:29:40","Issue - support managed dictionary cache for incremental data loading and query flow (#144)","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","466533f157984166f17b41817450d73fb1eddb35","52","8","0","5674","530","284","5450","67","7779","1578","639","71","66","5772","0","2","80","292","apache-carbondata","466533f157984166f17b41817450d73fb1eddb35","615","22","46","92060","48275","9347","4","3009","70","4467","18.7","3517","27","1.8","5","279","4608","20676","27","1462","1684","95","755","126","66","30098","2.1","1227","499","1"
"apache-carbondata","05bc6bcf6badff312889a578533242360b86601d","2016-04-14 00:15:43","[Issue-76]Configurable dictionary encoding (#133)

[Issue Number #76] 
[Description] NO_DICTIONARY feature in carbon deals with the storage mechanism where for high cardinality data will be stored directly in carbon storage system as part of fact data, This will reduce/save the dictionary conversion cost for high cardinality columns/dimensions in a system.","refs/heads/master","sujithchacko.2010@gmail.com","apache-carbondata","05bc6bcf6badff312889a578533242360b86601d","49","8","0","5561","530","284","5302","67","7659","1574","638","65","66","5794","0","2","70","292","apache-carbondata","05bc6bcf6badff312889a578533242360b86601d","597","21.6","46","90008","47575","9221","4","2979","70","4428","19.2","3422","27","1.9","5","276","4562","20451","22","1367","1684","88","755","124","66","29901","2.1","1219","481","1"
"apache-carbondata","ad502499be4faaa2a5c3d913d125713afde1c90a","2016-04-13 07:09:46","Local file locking change (#145)

Local file locking for single driver as default option","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","ad502499be4faaa2a5c3d913d125713afde1c90a","49","8","0","5556","518","284","5218","67","7616","1544","632","65","66","5785","0","2","70","292","apache-carbondata","ad502499be4faaa2a5c3d913d125713afde1c90a","597","21.6","46","89834","47477","9205","4","2977","72","4421","19.1","3419","29","1.9","5","275","4554","20414","22","1362","1710","87","755","124","66","29884","2.1","1214","481","1"
"apache-carbondata","40065c31c5671a1d1adf92ecfd0ea0bcafc45803","2016-04-13 04:27:16","Merge pull request #137 from gvramana/carbon_path

[Issue-136] support carbon store path handler","refs/heads/master","vimaldas.kammath@gmail.com","apache-carbondata","40065c31c5671a1d1adf92ecfd0ea0bcafc45803","49","8","0","5553","518","284","5222","67","7614","1540","632","65","66","5788","0","2","70","292","apache-carbondata","40065c31c5671a1d1adf92ecfd0ea0bcafc45803","597","21.6","45","89813","47467","9203","4","2976","72","4420","19.1","3419","29","1.9","5","274","4552","20408","22","1362","1710","87","735","124","66","29878","2.1","1214","481","1"
"apache-carbondata","19bd04841b422113c1a5e60fbb21cfdaab37fd39","2016-04-11 03:20:26","support carbon store path handler

All the code should not append paths but should depend on these classes
while accessing store files.
","refs/heads/master","ramana.gollamudi@huawei.com","apache-carbondata","19bd04841b422113c1a5e60fbb21cfdaab37fd39","49","8","0","5508","518","284","5218","67","7551","1528","632","65","64","5753","0","2","68","292","apache-carbondata","19bd04841b422113c1a5e60fbb21cfdaab37fd39","589","21.6","45","88954","47073","9139","4","2956","70","4380","19.3","3393","27","1.9","5","266","4509","20241","22","1272","1661","84","735","124","56","29618","2.1","1209","473","1"
"apache-carbondata","74ee731093d715858ffcc4585aac15573ea6216b","2016-04-12 20:38:01","// handled review comments.
// remove author tag.
// corrected the Enum name.
// corrected test case name.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","74ee731093d715858ffcc4585aac15573ea6216b","49","8","0","5528","518","280","5204","67","7559","1536","632","65","66","5788","0","2","70","292","apache-carbondata","74ee731093d715858ffcc4585aac15573ea6216b","593","21.6","45","89473","47326","9177","4","2974","72","4399","19.2","3393","29","1.9","5","274","4531","20370","22","1362","1710","87","735","123","66","29753","2.1","1195","478","1"
"apache-carbondata","5d9fc8a41bf017e5df22d9e5dbd9a53079c079fa","2016-04-12 12:37:05","// Changes :  Handled review Comments.
// Finding the free port and using that in the test case.
// handling of the unlock method of local file locking.
// moving the zk.create inside the async  call.

// putting code comments.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","5d9fc8a41bf017e5df22d9e5dbd9a53079c079fa","49","8","0","5529","518","280","5204","67","7559","1536","632","65","66","5788","0","2","70","292","apache-carbondata","5d9fc8a41bf017e5df22d9e5dbd9a53079c079fa","593","21.6","45","89481","47326","9177","4","2974","72","4399","19.2","3393","29","1.9","5","274","4531","20370","22","1362","1710","87","735","123","66","29753","2.1","1195","478","1"
"apache-carbondata","2cccb4285d642d8293876b3ad601d0ad198fa557","2016-04-11 03:50:08","// Changes :  corrected test cases.
// in zookeeper using the create znode API for creating node(lock file) for each lock request.
// the nodes will be having name in sequential order. once the unlock happens then that node will be deleted.

// using factory pattern.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","2cccb4285d642d8293876b3ad601d0ad198fa557","49","8","0","5535","518","280","5204","67","7559","1536","632","65","66","5788","0","2","70","292","apache-carbondata","2cccb4285d642d8293876b3ad601d0ad198fa557","593","21.6","45","89430","47312","9175","4","2971","72","4395","19.2","3393","29","1.9","5","273","4527","20367","22","1362","1710","87","735","123","66","29693","2.1","1195","478","1"
"apache-carbondata","86a30d90e6c17e44d9269d9d45ae85fcbfc330be","2016-04-11 02:42:19","// Changes : Using zookeeper for implementation of metadata locks.
// in zookeeper using the create znode API for creating node(lock file) for each lock request.
// the nodes will be having name in sequential order. once the unlock happens then that node will be deleted.

// using factory pattern.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","86a30d90e6c17e44d9269d9d45ae85fcbfc330be","49","8","0","5535","518","280","5204","67","7559","1536","632","65","66","5788","0","2","70","292","apache-carbondata","86a30d90e6c17e44d9269d9d45ae85fcbfc330be","593","21.6","45","89429","47311","9175","4","2972","72","4396","19.2","3393","29","1.9","5","273","4528","20367","22","1362","1710","87","735","123","66","29698","2.1","1195","478","1"
"apache-carbondata","323d8f7f31c3c3c80f39fca53dbb99313b5e55fd","2016-04-07 10:32:28","// Changes : Using zookeeper for implementation of metadata locks.
// in zookeeper using the create znode API for creating node(lock file) for each lock request.
// the nodes will be having name in sequential order. once the unlock happens then that node will be deleted.

// using factory pattern.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","323d8f7f31c3c3c80f39fca53dbb99313b5e55fd","49","8","0","5535","518","280","5204","67","7559","1536","632","65","66","5788","0","2","70","292","apache-carbondata","323d8f7f31c3c3c80f39fca53dbb99313b5e55fd","593","21.6","46","89430","47311","9175","4","2972","72","4396","19.2","3393","29","1.9","5","274","4529","20367","22","1362","1710","87","765","123","66","29698","2.1","1195","478","1"
"apache-carbondata","2c468872a868d038373285477aec940491bb238f","2016-04-07 10:19:23","// Changes : Using zookeeper for implementation of metadata locks.
// in zookeeper using the create znode API for creating node(lock file) for each lock request.
// the nodes will be having name in sequential order. once the unlock happens then that node will be deleted.

// using factory pattern.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","2c468872a868d038373285477aec940491bb238f","49","8","0","5535","518","280","5204","67","7559","1536","632","65","66","5788","0","2","70","292","apache-carbondata","2c468872a868d038373285477aec940491bb238f","593","21.6","46","89430","47311","9175","4","2972","72","4396","19.2","3393","29","1.9","5","274","4529","20367","22","1362","1710","87","765","123","66","29698","2.1","1195","478","1"
"apache-carbondata","b88212a6e2943f1bbefedf98b9ca937b40b8bff0","2016-04-05 09:39:48","// Changes : Using zookeeper for implementation of metadata locks.
// in zookeeper using the create znode API for creating node(lock file) for each lock request.
// the nodes will be having name in sequential order. once the unlock happens then that node will be deleted.
","refs/heads/master","ravikiran.sn042@gmail.com","apache-carbondata","b88212a6e2943f1bbefedf98b9ca937b40b8bff0","49","8","0","5524","519","280","5206","67","7556","1530","632","65","65","5785","0","2","70","292","apache-carbondata","b88212a6e2943f1bbefedf98b9ca937b40b8bff0","589","21.6","46","89322","47312","9164","4","2970","72","4392","19.3","3390","29","1.9","5","274","4526","20370","22","1377","1710","88","765","123","66","29636","2.1","1194","474","1"
"apache-carbondata","54705b3bf32fe64d4569bf1a97c1e845902480f0","2016-04-12 02:22:20","Updated Thrift interface to combine dimensions and measures. And added ValueCompression for each data chunk
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","54705b3bf32fe64d4569bf1a97c1e845902480f0","49","8","0","5513","518","280","5194","67","7552","1532","632","65","65","5778","0","2","70","292","apache-carbondata","54705b3bf32fe64d4569bf1a97c1e845902480f0","589","21.6","45","89128","47194","9145","4","2969","72","4387","19.3","3387","29","1.9","5","269","4519","20331","22","1362","1710","87","735","123","66","29589","2.1","1193","474","1"
"apache-carbondata","7997e992c3d13fe0e385e18b47dc18a897bb0fc6","2016-04-10 21:47:30","Moved converters to util class
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","7997e992c3d13fe0e385e18b47dc18a897bb0fc6","49","8","0","5495","518","280","5194","67","7518","1531","632","65","65","5744","0","2","70","292","apache-carbondata","7997e992c3d13fe0e385e18b47dc18a897bb0fc6","588","21.6","45","88907","47054","9136","4","2966","72","4382","19.3","3382","29","1.9","5","266","4511","20265","22","1272","1710","84","735","123","64","29590","2.1","1193","473","1"
"apache-carbondata","90b6177485db21d6d6b6fced776a3db410fdd40f","2016-04-07 02:31:02","Carbon Metadata reading/writing in thrift format
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","90b6177485db21d6d6b6fced776a3db410fdd40f","49","8","0","5495","518","280","5194","67","7518","1530","632","65","66","5747","0","2","70","292","apache-carbondata","90b6177485db21d6d6b6fced776a3db410fdd40f","587","21.6","45","88896","47052","9136","4","2965","72","4381","19.4","3382","29","1.9","5","266","4510","20265","22","1272","1710","84","735","123","64","29560","2.1","1193","472","1"
"apache-carbondata","571bdb5183c0698fcc5817c34373a7bb940e754a","2016-04-06 09:16:52","use CarbonDictionaryWriter to write file
","refs/heads/master","david.caiq@gmail.com","apache-carbondata","571bdb5183c0698fcc5817c34373a7bb940e754a","49","8","0","5483","518","280","5200","67","7496","1524","632","65","64","5753","0","2","68","292","apache-carbondata","571bdb5183c0698fcc5817c34373a7bb940e754a","585","21.6","45","88614","46932","9113","4","2954","70","4359","19.4","3367","27","1.9","5","266","4488","20203","22","1272","1661","84","735","123","56","29493","2.1","1190","470","1"
"apache-carbondata","bb5a86784dad6abd53c49884fba065d0cd944917","2016-04-07 02:10:10","[Issue-96,65] support dictionary reading from new Thrift format at Executor // added details about method parameters
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","bb5a86784dad6abd53c49884fba065d0cd944917","49","8","0","5483","518","280","5200","67","7496","1524","632","65","64","5753","0","2","68","292","apache-carbondata","bb5a86784dad6abd53c49884fba065d0cd944917","585","21.6","45","88612","46931","9113","4","2954","70","4359","19.4","3367","27","1.9","5","266","4488","20203","22","1272","1661","84","735","123","56","29493","2.1","1190","470","1"
"apache-carbondata","a3e60903ec74c1e652c6b210ea8110eafa2b4b19","2016-04-07 00:12:55","[Issue-96,65] support dictionary reading from new Thrift format at Executor // handled review comments
1. change columnName to columnIdentifier
2. Modify code to simulate truncate scenario from the dictionary writer flow.
3. Remove double check for file existence and call validateDictionaryFileOffsetWithLastSegmentEntryOffset method within the check
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","a3e60903ec74c1e652c6b210ea8110eafa2b4b19","49","8","0","5461","518","280","5200","67","7496","1524","632","65","64","5753","0","2","68","292","apache-carbondata","a3e60903ec74c1e652c6b210ea8110eafa2b4b19","585","21.5","45","88495","46931","9113","4","2954","70","4359","19.4","3367","27","1.9","5","266","4488","20203","22","1272","1661","84","735","123","56","29493","2.1","1190","470","1"
"apache-carbondata","551299a75273b13e577095c4f725a0b0a3e9fd72","2016-04-06 19:53:45","[Issue-65] support index reading from new Thrift format at Executor
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","551299a75273b13e577095c4f725a0b0a3e9fd72","49","8","0","5461","518","280","5200","67","7496","1525","632","65","64","5754","0","2","68","292","apache-carbondata","551299a75273b13e577095c4f725a0b0a3e9fd72","585","21.5","45","88498","46934","9114","4","2954","70","4359","19.4","3367","27","1.9","5","266","4488","20204","22","1272","1661","84","735","123","56","29493","2.1","1190","470","1"
"apache-carbondata","3e45ac4f9630ada6834ee0a3fcce4ffa8428442f","2016-04-06 03:35:29","Merge pull request #104 from mohammadshahidkhan/Dictionary_Loopup_fordimension

[Issue-94] Dictionary lookup for Dimension","refs/heads/master","vimaldas.kammath@gmail.com","apache-carbondata","3e45ac4f9630ada6834ee0a3fcce4ffa8428442f","49","8","0","5443","517","280","5140","67","7455","1517","632","65","64","5748","0","2","68","292","apache-carbondata","3e45ac4f9630ada6834ee0a3fcce4ffa8428442f","583","21.4","45","88018","46723","9082","4","2949","70","4352","19.4","3348","27","1.9","5","266","4481","20123","22","1272","1661","84","735","123","56","29456","2.1","1188","468","1"
"apache-carbondata","258abcc71999ba4afb4dc5ebf8a7b196b617715e","2016-04-05 05:35:55","Dictionary loopup for Dimension
  Previously to get the surrogate/ id of the member a linear search was performed over the actual Member which was a costly operation.
  The binary search can not be performed over the actual member since the members are unsorted.
To address the same below code modification is done.
    sortOrderIndex maintains the sorted surrogate based on the members actual value, so
    the binary search is applied on sortOrderIndex to get the surrogate of the of requested member.
+ Implemented the binary search over 2 D array.
  Added test case considering the scenario of incremental load for more than 10K data.
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","258abcc71999ba4afb4dc5ebf8a7b196b617715e","47","4","0","5367","509","280","4974","67","7279","1488","618","64","64","5701","0","2","66","290","apache-carbondata","258abcc71999ba4afb4dc5ebf8a7b196b617715e","550","21.2","45","84098","45211","8872","4","2929","64","4304","20.3","3258","21","1.9","5","260","4427","19588","18","1172","1556","78","735","111","56","29149","2.1","1164","436","1"
"apache-carbondata","3921944d9c8b90709106f4af51c9e8b40ec4e377","2016-04-06 01:53:46","Merge pull request #111 from manishgupta88/global_dictionary_reader

[Issue #65][WIP] support index reading from new Thrift format at Executor","refs/heads/master","vimaldas.kammath@gmail.com","apache-carbondata","3921944d9c8b90709106f4af51c9e8b40ec4e377","49","8","0","5443","517","280","5138","67","7445","1517","632","65","64","5751","0","2","68","292","apache-carbondata","3921944d9c8b90709106f4af51c9e8b40ec4e377","583","21.4","45","87986","46700","9075","4","2949","70","4352","19.4","3346","27","1.9","5","266","4479","20106","20","1242","1661","82","735","123","56","29456","2.1","1188","468","1"
"apache-carbondata","c3dd3c63207afc425b665a00a5a920d5a437a6b0","2016-04-05 23:49:02","Issue : https://github.com/HuaweiBigData/carbondata/issues/65
Description: support index reading from new Thrift format at Executor
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","c3dd3c63207afc425b665a00a5a920d5a437a6b0","48","8","0","5425","515","280","5060","67","7382","1499","632","65","64","5711","0","2","66","292","apache-carbondata","c3dd3c63207afc425b665a00a5a920d5a437a6b0","576","21.4","45","87012","46216","9002","4","2942","68","4333","19.5","3308","25","1.9","5","262","4457","19894","17","1217","1625","79","735","123","56","29297","2.1","1180","462","1"
"apache-carbondata","5abeef1bff254db310cdd30591a96ff1fe28fd7e","2016-04-05 21:51:47","Support global dictionary writer :- Handled review comments
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","5abeef1bff254db310cdd30591a96ff1fe28fd7e","49","8","0","5430","517","280","5108","67","7440","1512","632","65","64","5751","0","2","68","292","apache-carbondata","5abeef1bff254db310cdd30591a96ff1fe28fd7e","580","21.4","45","87774","46654","9074","4","2949","70","4337","19.5","3340","27","1.9","5","266","4464","20096","20","1242","1661","82","735","123","56","29411","2.1","1173","465","1"
"apache-carbondata","ab41c15576817cdad4f2822eea12fbe566a28c49","2016-04-05 08:02:54","Modified code according to new interface for carbon dictionary writer
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","ab41c15576817cdad4f2822eea12fbe566a28c49","49","8","0","5430","517","280","5106","67","7444","1512","632","65","64","5756","0","2","68","292","apache-carbondata","ab41c15576817cdad4f2822eea12fbe566a28c49","580","21.4","45","87787","46665","9075","4","2949","70","4337","19.5","3341","27","1.9","5","266","4464","20105","20","1242","1661","82","735","123","56","29411","2.1","1173","465","1"
"apache-carbondata","fbbd1c8a04561675f907212ce3f20ba682fc05b7","2016-04-05 02:17:39","deleted file CarbonTypeIdentifier.java. It has been renamed to CarbonTableidentifier.java
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","fbbd1c8a04561675f907212ce3f20ba682fc05b7","49","8","0","5427","517","280","5106","67","7440","1512","632","65","64","5753","0","2","68","292","apache-carbondata","fbbd1c8a04561675f907212ce3f20ba682fc05b7","580","21.4","45","87773","46651","9073","4","2950","70","4337","19.5","3342","27","1.9","5","266","4465","20095","20","1247","1661","83","735","123","56","29411","2.1","1173","465","1"
"apache-carbondata","c25e85dddee4673d7175af6c7310d7300033d45f","2016-04-04 05:16:31","AR-ID: AR-V1R3C00-Datasight-carbon-dataloading-global-dictionary-support global dictionary writer (append to existing dictionary)
Modification Reason: added interface for dictionary writer // modified code and test cases according to design change
Reviewer: NA
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","c25e85dddee4673d7175af6c7310d7300033d45f","49","8","0","5428","517","280","5108","67","7442","1515","632","65","64","5753","0","2","68","292","apache-carbondata","c25e85dddee4673d7175af6c7310d7300033d45f","581","21.4","45","87848","46673","9074","4","2950","70","4337","19.5","3343","27","1.9","5","266","4465","20101","20","1247","1661","83","735","123","56","29411","2.1","1173","466","1"
"apache-carbondata","4dff8933745a9d7258011cc4f7fcf953b64bb317","2016-04-02 01:20:49","AR-ID: AR-V1R3C00-Datasight-carbon-dataloading-global-dictionary-support global dictionary writer (append to existing dictionary)
Modification Reason: modified code for writing dictionary metadata also as thrift file // handled review comments
Reviewer: NA
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","4dff8933745a9d7258011cc4f7fcf953b64bb317","49","8","0","5424","515","280","5086","67","7438","1515","632","65","64","5732","0","2","70","292","apache-carbondata","4dff8933745a9d7258011cc4f7fcf953b64bb317","579","21.4","45","87538","46520","9054","4","2951","68","4333","19.5","3328","25","1.9","5","264","4459","20029","19","1242","1625","81","735","123","56","29383","2.1","1169","464","1"
"apache-carbondata","e062baa618a9a21f32ebee4626dfde0e1349ced3","2016-03-31 05:30:46","AR-ID: AR-V1R3C00-Datasight-carbon-dataloading-global-dictionary-support global dictionary writer (append to existing dictionary)
Modification Reason: for mocking jmock it has to be above junit in classpath and corrected checkstyle issues // handled review commends and added jcarbon -format jar for compilation
Reviewer: NA
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","e062baa618a9a21f32ebee4626dfde0e1349ced3","49","8","0","5429","515","280","5094","67","7451","1522","632","65","64","5744","0","2","67","292","apache-carbondata","e062baa618a9a21f32ebee4626dfde0e1349ced3","581","21.3","45","87747","46632","9060","4","2956","68","4340","19.4","3330","25","1.9","5","267","4466","20072","19","1242","1625","81","735","123","56","29461","2.1","1168","466","1"
"apache-carbondata","35285118ac0e42dea4d1ec4c34be84740283438b","2016-03-31 04:56:41","AR-ID: AR-V1R3C00-Datasight-carbon-dataloading-global-dictionary-support global dictionary writer (append to existing dictionary)
Modification Reason: Added code for global dictionary writing
Reviewer: NA
","refs/heads/master","tomanishgupta18@gmail.com","apache-carbondata","35285118ac0e42dea4d1ec4c34be84740283438b","49","8","0","5434","515","280","5094","67","7451","1522","632","65","64","5744","0","2","67","292","apache-carbondata","35285118ac0e42dea4d1ec4c34be84740283438b","581","21.4","45","87643","46629","9060","4","2957","68","4341","19.4","3330","25","1.9","5","267","4467","20072","19","1242","1625","81","735","123","56","29466","2.1","1168","466","1"
"apache-carbondata","900be9224e5fa82ee380e1570f5e34490f26bb04","2016-04-05 02:49:53","Updated code based on new thrift format
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","900be9224e5fa82ee380e1570f5e34490f26bb04","48","8","0","5412","515","280","5030","67","7377","1494","632","65","64","5711","0","2","66","292","apache-carbondata","900be9224e5fa82ee380e1570f5e34490f26bb04","573","21.4","45","86800","46170","9001","4","2942","68","4318","19.6","3302","25","1.9","5","262","4442","19884","17","1217","1625","79","735","122","56","29252","2.1","1165","459","1"
"apache-carbondata","69dd13041c5af2381777f5dcb7d34efea35046a7","2016-04-05 02:36:37","1) Updated code based on new thrift format
2) Fixed code review comments
3) Updated test cases
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","69dd13041c5af2381777f5dcb7d34efea35046a7","48","8","0","5412","515","280","5030","67","7377","1494","632","65","64","5711","0","2","66","292","apache-carbondata","69dd13041c5af2381777f5dcb7d34efea35046a7","573","21.4","45","86800","46170","9001","4","2942","68","4318","19.6","3302","25","1.9","5","262","4442","19884","17","1217","1625","79","735","122","56","29252","2.1","1165","459","1"
"apache-carbondata","12283f3e39b4d645040e57fdb7398b3ab17e8488","2016-04-05 02:31:05","Dictionary loopup for Dimension
  Previously to get the surrogate/ id of the member a linear search was performed over the actual Member which was a costly operation.
  The binary search can not be performed over the actual member since the members are unsorted.
To address the same below code modification is done.
    sortOrderIndex maintains the sorted surrogate based on the members actual value, so
    the binary search is applied on sortOrderIndex to get the surrogate of the of requested member.
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","12283f3e39b4d645040e57fdb7398b3ab17e8488","48","4","0","5367","509","280","4974","67","7278","1489","618","67","64","5703","0","2","66","290","apache-carbondata","12283f3e39b4d645040e57fdb7398b3ab17e8488","550","21.2","45","84088","45206","8872","4","2930","64","4305","20.3","3257","21","1.9","5","260","4428","19584","18","1172","1556","78","735","111","56","29160","2.2","1164","436","1"
"apache-carbondata","d92892fc37046a366d055d74ed328a13f5950c44","2016-04-03 23:15:44","Removed Aggregator as it is custom  function is not supported
Removed encoder as custom encoder is not supported
Updated other classes based on above changes
Updated test classes
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","d92892fc37046a366d055d74ed328a13f5950c44","48","8","0","5412","515","280","5030","67","7378","1494","632","65","64","5711","0","2","66","292","apache-carbondata","d92892fc37046a366d055d74ed328a13f5950c44","573","21.4","45","86819","46178","9001","4","2942","68","4318","19.6","3302","25","1.9","5","262","4442","19886","17","1217","1625","79","735","122","56","29252","2.1","1165","459","1"
"apache-carbondata","a5d4507a32fac1a72ec3b6561082945e190abba1","2016-04-01 00:20:50","1) Added wrapper classes for CarbonData.thrift and schema.thrift
2) Common interface used by all the developers
3) Added Class to support current design as we are not modifying the some of carbon structure Eg: dimension,measure
4) In future we can removed this classes
5) New mapping of classes:
org.carbondata.core.metadata.CarbonMetadata to org.carbondata.core.carbon.metadata.CarbonMetadata
org.carbondata.core.metadata.CarbonMetadata.Dimension to org.carbondata.core.carbon.metadata.schema.table.column.CarbonDimension
org.carbondata.core.metadata.CarbonMetadata.Measure to org.carbondata.core.carbon.metadata.schema.table.column.CarbonMeasure
Note: old mapping will be deleted when all the dependices are removed.
6) Added test case for new clasess
","refs/heads/master","kumarvishal1802@gmail.com","apache-carbondata","a5d4507a32fac1a72ec3b6561082945e190abba1","48","8","0","5414","515","280","5030","67","7382","1494","630","65","64","5711","0","2","66","292","apache-carbondata","a5d4507a32fac1a72ec3b6561082945e190abba1","577","21.4","45","87021","46227","8998","4","2942","68","4318","19.4","3299","25","1.9","5","262","4442","19893","17","1217","1625","79","735","123","56","29252","2.1","1165","463","1"
"apache-carbondata","711be0ddcb8f77091e0fbf8b536de07fb59c0325","2016-04-01 03:37:59","Minimal Usage of the synchronized block For B+ Tree loading

Below listed are the points for which code modification is done.

1. Minimal usage synchronization  while table B-tree loading. Each query will list the folders which it has to load for fetching the result,
if the folders are already loaded the query will not enter the synchronized block which currently impacts the query performance.
2. After table loading, each query will form a query scope object which will define on which segments/load folders a query has to work on
which is helpful in concurrent scenarios.
3. Each segment cache object will maintain the modification time of segment which will help during retention scenario. Currently
after retention operation, the status of segments modified is marked for update becuase of which those segments were loaded each time the query
was executed. Now the modification time will be matched and the updated segment will be loaded only once.
4. Read write lock implementation has been done to allow concurrrent access of segment cache object list.
5. Added UT + modified some comments
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","711be0ddcb8f77091e0fbf8b536de07fb59c0325","47","4","0","5367","509","280","4972","67","7269","1488","618","64","64","5704","0","2","66","290","apache-carbondata","711be0ddcb8f77091e0fbf8b536de07fb59c0325","550","21.2","45","84066","45188","8865","4","2929","64","4304","20.3","3256","21","1.9","5","260","4425","19571","16","1142","1556","76","735","111","56","29149","2.2","1164","436","1"
"apache-carbondata","756893752825aba9138de17217f73b2e1799b49c","2016-04-01 03:37:59","Minimal Usage of the synchronized block For B+ Tree loading

Below listed are the points for which code modification is done.

1. Minimal usage synchronization  while table B-tree loading. Each query will list the folders which it has to load for fetching the result,
if the folders are already loaded the query will not enter the synchronized block which currently impacts the query performance.
2. After table loading, each query will form a query scope object which will define on which segments/load folders a query has to work on
which is helpful in concurrent scenarios.
3. Each segment cache object will maintain the modification time of segment which will help during retention scenario. Currently
after retention operation, the status of segments modified is marked for update becuase of which those segments were loaded each time the query
was executed. Now the modification time will be matched and the updated segment will be loaded only once.
4. Read write lock implementation has been done to allow concurrrent access of segment cache object list.
","refs/heads/master","mohdshahidkhan1987@gmail.com","apache-carbondata","756893752825aba9138de17217f73b2e1799b49c","47","4","0","5382","509","280","4972","67","7269","1488","618","64","64","5703","0","2","66","290","apache-carbondata","756893752825aba9138de17217f73b2e1799b49c","550","21.2","45","84022","45189","8865","4","2929","64","4304","20.3","3256","21","1.9","5","260","4425","19571","16","1142","1556","76","735","111","56","29149","2.2","1164","436","1"
"apache-carbondata","9f0d6e21d6a5f5f47cad8f86b96ab73bf902b44c","2016-03-27 09:23:10","Added classes back
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","9f0d6e21d6a5f5f47cad8f86b96ab73bf902b44c","47","4","0","5360","507","280","4900","67","7209","1484","618","64","65","5714","0","2","67","290","apache-carbondata","9f0d6e21d6a5f5f47cad8f86b96ab73bf902b44c","548","21.3","45","83669","44961","8827","4","2923","64","4297","20.3","3241","21","1.9","5","260","4418","19478","16","1142","1556","76","735","110","56","29120","2.2","1163","434","1"
"apache-carbondata","78c56ddbc52feffcf00580a5b1bebf7f8e7d2f3f","2016-03-27 08:35:24","Engine/Query code cleaned
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","78c56ddbc52feffcf00580a5b1bebf7f8e7d2f3f","47","4","0","5358","507","280","4900","67","7203","1483","618","64","65","5709","0","2","67","290","apache-carbondata","78c56ddbc52feffcf00580a5b1bebf7f8e7d2f3f","546","21.2","45","83555","44928","8822","4","2921","64","4295","20.4","3236","21","1.9","5","260","4416","19469","16","1142","1556","76","735","109","56","29114","2.2","1163","432","1"
"apache-carbondata","b30586ab335b68098ca46c633e9e288c2ab92b68","2016-03-27 06:01:49","Removed olap and rolap word
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","b30586ab335b68098ca46c633e9e288c2ab92b68","47","4","0","5488","515","280","4906","67","7270","1482","619","64","63","5760","0","0","64","296","apache-carbondata","b30586ab335b68098ca46c633e9e288c2ab92b68","547","23.7","45","86172","45199","8925","4","3280","64","4707","20.6","3254","21","1.8","5","260","4828","19619","16","1142","1556","76","735","109","109","30924","2.3","1163","433","1"
"apache-carbondata","dc6fc0bd84b811ca74c7c10162bdaa8d06e9760b","2016-03-27 05:00:39","Removed Molap word from whole code
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","dc6fc0bd84b811ca74c7c10162bdaa8d06e9760b","47","4","0","5530","515","280","4906","67","7276","1481","619","64","63","5761","0","0","64","296","apache-carbondata","dc6fc0bd84b811ca74c7c10162bdaa8d06e9760b","547","24.2","45","86769","45211","8928","4","3384","64","4814","20.6","3257","21","1.8","5","260","4935","19623","16","1142","1556","76","735","109","112","31444","2.3","1163","433","1"
"apache-carbondata","4d016a079a6b44b44517c38f7422c4d30ef73402","2016-03-27 03:05:39","Renamed all files with Molap to Carbon
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","4d016a079a6b44b44517c38f7422c4d30ef73402","47","4","0","5542","515","280","4904","67","7282","1482","619","64","63","5766","0","0","64","296","apache-carbondata","4d016a079a6b44b44517c38f7422c4d30ef73402","549","24.4","45","87066","45244","8933","4","3400","64","4830","20.5","3262","21","1.8","5","260","4951","19632","16","1142","1556","76","735","110","112","31515","2.3","1163","435","1"
"apache-carbondata","d455244895c9a3e90847142c19e4210dc7c8589f","2016-03-26 05:55:01","Cleaned some code
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","d455244895c9a3e90847142c19e4210dc7c8589f","54","4","0","7485","597","285","5324","102","8814","1719","637","64","86","7103","0","4","80","326","apache-carbondata","d455244895c9a3e90847142c19e4210dc7c8589f","692","34.3","54","114640","52339","10307","5","5742","68","7302","18.1","3719","24","1.4","5","273","7436","22803","17","1192","1622","80","925","133","233","44163","2.8","1171","569","1"
"apache-carbondata","ecffc334c86cd6b6ed86db637dc95ed03a9bd55f","2016-03-26 05:41:23","Reformatted code
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","ecffc334c86cd6b6ed86db637dc95ed03a9bd55f","54","4","0","7525","597","285","5330","102","8830","1720","639","64","87","7104","0","4","80","326","apache-carbondata","ecffc334c86cd6b6ed86db637dc95ed03a9bd55f","693","34.3","54","114846","52452","10336","5","5756","68","7328","18.1","3738","24","1.4","5","273","7462","22836","17","1192","1622","80","925","134","245","44250","2.8","1171","570","1"
"apache-carbondata","c1ccab3d5e95938418f052e07aaadf1f43898c69","2016-03-26 04:55:27","Code restructured as per new module design
","refs/heads/master","ravi.pesala@gmail.com","apache-carbondata","c1ccab3d5e95938418f052e07aaadf1f43898c69","54","4","0","7530","597","285","5330","102","8830","1720","639","64","87","7104","0","4","80","326","apache-carbondata","c1ccab3d5e95938418f052e07aaadf1f43898c69","693","34.8","54","113823","51249","10336","5","5754","68","7326","18.1","3738","24","1.4","5","273","7460","22836","17","1192","1563","80","925","134","245","44210","2.9","1171","570","1"
